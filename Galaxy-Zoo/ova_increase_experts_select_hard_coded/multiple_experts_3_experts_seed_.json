{"batch_size": 64, "alpha": 1.0, "epochs": 150, "patience": 50, "expert_type": "MLPMixer", "n_classes": 2, "k": 0, "n_experts": 2, "lr": 0.001, "weight_decay": 0.0005, "warmup_epochs": 5, "loss_type": "ova", "ckp_dir": "./ova_increase_experts_select_hard_coded", "experiment_name": "multiple_experts"}