{"cells":[{"cell_type":"markdown","metadata":{"id":"CpsD1qyeqZzb"},"source":["### Mount and set the working directory"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W5G0AGpcpZOd","executionInfo":{"status":"ok","timestamp":1669748028674,"user_tz":-60,"elapsed":1977,"user":{"displayName":"DANIEL BARREJON MORENO","userId":"10128168494914338380"}},"outputId":"4b729793-a31d-44e9-ab15-96d518e86654"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NreoEtN8qKcL"},"outputs":[],"source":["import os"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_NTu0S9GqL1s","colab":{"base_uri":"https://localhost:8080/","height":187},"executionInfo":{"status":"error","timestamp":1669748045144,"user_tz":-60,"elapsed":1004,"user":{"displayName":"DANIEL BARREJON MORENO","userId":"10128168494914338380"}},"outputId":"4ec42a44-d26a-479a-df36-5a599896c01e"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-da7f6a20d775>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Hatespeech/Hatespeech/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Hatespeech/Hatespeech/'"]}],"source":["os.chdir('/content/drive/MyDrive/Hatespeech/Hatespeech/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NUVu9ObDpuNE"},"outputs":[],"source":["!ls\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L4xHfzi3qjix"},"outputs":[],"source":["import sys\n","sys.path.append(\"/content/drive/MyDrive/Hatespeech/Hatespeech/\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bxI4Cx4grlTb"},"outputs":[],"source":["sys.path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"THll1esbrMAZ"},"outputs":[],"source":["# test imports\n","# from utils import *"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mhYhYGa2swhi"},"outputs":[],"source":["! pip install pickle5"]},{"cell_type":"markdown","metadata":{"id":"k7Rn6ONbqkaW"},"source":["### Training script\n","We have ``main_increase_experts.py`` but we re-write it here for ease of working and modifying things"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bMcP8Doiqp5j"},"outputs":[],"source":["import math\n","import random\n","import argparse\n","import shutil\n","import time\n","import torch.optim\n","import torch.utils.data\n","from torch.autograd import Variable\n","import json\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import copy\n","import os\n","import pickle5 as pickle\n","\n","from utils import *\n","from data_utils import *\n","from models.surrogate_CNN import *\n","from models.experts import *\n","from losses.losses import *\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device,  flush=True)\n","\n","\n","def set_seed(seed):\n","\t\trandom.seed(seed)\n","\t\tnp.random.seed(seed)\n","\t\ttorch.manual_seed(seed)\n","\t\tif torch.cuda.is_available():\n","\t\t\ttorch.cuda.manual_seed(seed)\n","\t\t\ttorch.cuda.manual_seed_all(seed)\n","\n","\n","def evaluate(model,\n","\t\t\t expert_fns,\n","\t\t\t loss_fn,\n","\t\t\t n_classes,\n","\t\t\t data_loader,\n","\t\t\t config):\n","\t'''\n","\tComputes metrics for deferal\n","\t-----\n","\tArguments:\n","\tnet: model\n","\texpert_fn: expert model\n","\tn_classes: number of classes\n","\tloader: data loader\n","\t'''\n","\tcorrect = 0\n","\tcorrect_sys = 0\n","\texp = 0\n","\texp_total = 0\n","\ttotal = 0\n","\treal_total = 0\n","\talone_correct = 0\n","\t#  === Individual Expert Accuracies === #\n","\texpert_correct_dic = {k: 0 for k in range(len(expert_fns))}\n","\texpert_total_dic = {k: 0 for k in range(len(expert_fns))}\n","\t#  === Individual  Expert Accuracies === #\n","\talpha = config[\"alpha\"]\n","\tlosses = []\n","\twith torch.no_grad():\n","\t\tfor data in data_loader:\n","\t\t\timages, labels, hpred = data\n","\t\t\timages, labels, hpred = images.to(device), labels.to(device), hpred\n","\t\t\toutputs = model(images)\n","\t\t\tif config[\"loss_type\"] == \"softmax\":\n","\t\t\t\toutputs = F.softmax(outputs, dim=1)\n","\t\t\tif config[\"loss_type\"] == \"ova\":\n","\t\t\t\touputs = F.sigmoid(outputs)\n","\n","\t\t\t_, predicted = torch.max(outputs.data, 1)\n","\t\t\tbatch_size = outputs.size()[0]  # batch_size\n","\n","\t\t\texpert_predictions = []\n","\t\t\tcollection_Ms = []  # a collection of 3-tuple\n","\t\t\tfor i, fn in enumerate(expert_fns, 0):\n","\t\t\t\texp_prediction1 = fn(images, labels, hpred)\n","\t\t\t\tm = [0] * batch_size\n","\t\t\t\tm2 = [0] * batch_size\n","\t\t\t\tfor j in range(0, batch_size):\n","\t\t\t\t\tif exp_prediction1[j] == labels[j].item():\n","\t\t\t\t\t\tm[j] = 1\n","\t\t\t\t\t\tm2[j] = alpha\n","\t\t\t\t\telse:\n","\t\t\t\t\t\tm[j] = 0\n","\t\t\t\t\t\tm2[j] = 1\n","\n","\t\t\t\tm = torch.tensor(m)\n","\t\t\t\tm2 = torch.tensor(m2)\n","\t\t\t\tm = m.to(device)\n","\t\t\t\tm2 = m2.to(device)\n","\t\t\t\tcollection_Ms.append((m, m2))\n","\t\t\t\texpert_predictions.append(exp_prediction1)\n","\n","\t\t\tloss = loss_fn(outputs, labels, collection_Ms, n_classes)\n","\t\t\tlosses.append(loss.item())\n","\n","\t\t\tfor i in range(0, batch_size):\n","\t\t\t\tr = (predicted[i].item() >= n_classes - len(expert_fns))\n","\t\t\t\tprediction = predicted[i]\n","\t\t\t\tif predicted[i] >= n_classes - len(expert_fns):\n","\t\t\t\t\tmax_idx = 0\n","\t\t\t\t\t# get second max\n","\t\t\t\t\tfor j in range(0, n_classes - len(expert_fns)):\n","\t\t\t\t\t\tif outputs.data[i][j] >= outputs.data[i][max_idx]:\n","\t\t\t\t\t\t\tmax_idx = j\n","\t\t\t\t\tprediction = max_idx\n","\t\t\t\telse:\n","\t\t\t\t\tprediction = predicted[i]\n","\t\t\t\talone_correct += (prediction == labels[i]).item()\n","\t\t\t\tif r == 0:\n","\t\t\t\t\ttotal += 1\n","\t\t\t\t\tcorrect += (predicted[i] == labels[i]).item()\n","\t\t\t\t\tcorrect_sys += (predicted[i] == labels[i]).item()\n","\t\t\t\tif r == 1:\n","\t\t\t\t\tdeferred_exp = (predicted[i] - (n_classes - len(expert_fns))).item()\n","\t\t\t\t\t#cdeferred_exp = ((n_classes - 1) - predicted[i]).item()  # reverse order, as in loss function\n","\t\t\t\t\texp_prediction = expert_predictions[deferred_exp][i]\n","\t\t\t\t\t#\n","\t\t\t\t\t# Deferral accuracy: No matter expert ===\n","\t\t\t\t\texp += (exp_prediction == labels[i].item())\n","\t\t\t\t\texp_total += 1\n","\t\t\t\t\t# Individual Expert Accuracy ===\n","\t\t\t\t\texpert_correct_dic[deferred_exp] += (exp_prediction == labels[i].item())\n","\t\t\t\t\texpert_total_dic[deferred_exp] += 1\n","\t\t\t\t\t#\n","\t\t\t\t\tcorrect_sys += (exp_prediction == labels[i].item())\n","\t\t\t\treal_total += 1\n","\tcov = str(total) + str(\" out of\") + str(real_total)\n","\n","\t#  === Individual Expert Accuracies === #\n","\texpert_accuracies = {\"expert_{}\".format(str(k)): 100 * expert_correct_dic[k] / (expert_total_dic[k] + 0.0002) for k\n","\t\t\t\t\t\t in range(len(expert_fns))}\n","\t# Add expert accuracies dict\n","\tto_print = {\"coverage\": cov, \"system_accuracy\": 100 * correct_sys / real_total,\n","\t\t\t\t\"expert_accuracy\": 100 * exp / (exp_total + 0.0002),\n","\t\t\t\t\"classifier_accuracy\": 100 * correct / (total + 0.0001),\n","\t\t\t\t\"alone_classifier\": 100 * alone_correct / real_total,\n","\t\t\t\t\"validation_loss\": np.average(losses),\n","\t\t\t\t\"n_experts\": len(expert_fns),\n","\t\t\t\t**expert_accuracies}\n","\tprint(to_print, flush=True)\n","\treturn to_print\n","\n","\n","\n","def train_epoch(iters,\n","\t\t\t\twarmup_iters,\n","\t\t\t\tlrate,\n","\t\t\t\ttrain_loader,\n","\t\t\t\tmodel,\n","\t\t\t\toptimizer,\n","\t\t\t\tscheduler,\n","\t\t\t\tepoch,\n","\t\t\t\texpert_fns,\n","\t\t\t\tloss_fn,\n","\t\t\t\tn_classes,\n","\t\t\t\talpha,\n","\t\t\t\tconfig):\n","\t\"\"\" Train for one epoch \"\"\"\n","\n","\tbatch_time = AverageMeter()\n","\tlosses = AverageMeter()\n","\ttop1 = AverageMeter()\n","\n","\tmodel.train()\n","\tend = time.time()\n","\n","\tepoch_train_loss = []\n","\n","\tfor i, (input, target, hpred) in enumerate(train_loader):\n","\t\tif iters < warmup_iters:\n","\t\t\tlr = lrate * float(iters) / warmup_iters\n","\t\t\tprint(iters, lr)\n","\t\t\tfor param_group in optimizer.param_groups:\n","\t\t\t\tparam_group['lr'] = lr\n","\n","\t\ttarget = target.to(device)\n","\t\tinput = input.to(device)\n","\t\thpred = hpred\n","\n","\t\t# compute output\n","\t\toutput = model(input)\n","\n","\t\tif config[\"loss_type\"] == \"softmax\":\n","\t\t\toutput = F.softmax(output, dim=1)\n","\n","\t\t# get expert  predictions and costs\n","\t\tbatch_size = output.size()[0]  # batch_size\n","\t\tcollection_Ms = []\n","\t\t# We only support \\alpha=1\n","\t\tfor _, fn in enumerate(expert_fns):\n","\t\t\t# We assume each expert function has access to the extra metadata, even if they don't use it.\n","\t\t\tm = fn(input, target, hpred)\n","\t\t\tm2 = [0] * batch_size\n","\t\t\tfor j in range(0, batch_size):\n","\t\t\t\tif m[j] == target[j].item():\n","\t\t\t\t\tm[j] = 1\n","\t\t\t\t\tm2[j] = alpha\n","\t\t\t\telse:\n","\t\t\t\t\tm[j] = 0\n","\t\t\t\t\tm2[j] = 1\n","\t\t\tm = torch.tensor(m)\n","\t\t\tm2 = torch.tensor(m2)\n","\t\t\tm = m.to(device)\n","\t\t\tm2 = m2.to(device)\n","\t\t\tcollection_Ms.append((m, m2))\n","\n","\t\t# compute loss\n","\t\tloss = loss_fn(output, target, collection_Ms, n_classes)\n","\t\tepoch_train_loss.append(loss.item())\n","\n","\t\t# measure accuracy and record loss\n","\t\tprec1 = accuracy(output.data, target, topk=(1,))[0]\n","\t\tlosses.update(loss.data.item(), input.size(0))\n","\t\ttop1.update(prec1.item(), input.size(0))\n","\n","\t\t# compute gradient and do SGD step\n","\t\toptimizer.zero_grad()\n","\t\tloss.backward()\n","\t\toptimizer.step()\n","\n","\t\tif not iters < warmup_iters:\n","\t\t\tscheduler.step()\n","\n","\t\t# measure elapsed time\n","\t\tbatch_time.update(time.time() - end)\n","\t\tend = time.time()\n","\t\titers += 1\n","\n","\t\tif i % 10 == 0:\n","\t\t\tprint('Epoch: [{0}][{1}/{2}]\\t'\n","\t\t\t\t  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n","\t\t\t\t  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n","\t\t\t\t  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n","\t\t\t\tepoch, i, len(train_loader), batch_time=batch_time,\n","\t\t\t\tloss=losses, top1=top1), flush=True)\n","\n","\treturn iters, np.average(epoch_train_loss)\n","\n","\n","\n","def train(model,\n","\t\t  train_dataset,\n","\t\t  validation_dataset,\n","\t\t  expert_fns,\n","\t\t  config,\n","\t\t  seed=\"\"):\n","\tn_classes = config[\"n_classes\"] + len(expert_fns)\n","\tkwargs = {'num_workers': 0, 'pin_memory': True}\n","\n","\ttrain_loader = torch.utils.data.DataLoader(train_dataset,\n","\t\t\t\t\t\t\t\t\t\t\t   batch_size=config[\"batch_size\"], shuffle=True, drop_last=True, **kwargs)\n","\tvalid_loader = torch.utils.data.DataLoader(validation_dataset,\n","\t\t\t\t\t\t\t\t\t\t\t   batch_size=config[\"batch_size\"], shuffle=True, drop_last=True, **kwargs)\n","\tmodel = model.to(device)\n","\tcudnn.benchmark = True\n","\toptimizer = torch.optim.Adam(model.parameters(), config[\"lr\"],\n","\t\t\t\t\t\t\t\tweight_decay=config[\"weight_decay\"])\n","\tcriterion = Criterion()\n","\tloss_fn = getattr(criterion, config[\"loss_type\"])\n","\tscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, len(train_loader) * config[\"epochs\"])\n","\tbest_validation_loss = np.inf\n","\tpatience = 0\n","\titers = 0\n","\twarmup_iters = config[\"warmup_epochs\"] * len(train_loader)\n","\tlrate = config[\"lr\"]\n","\n","\tfor epoch in range(0, config[\"epochs\"]):\n","\t\titers, train_loss = train_epoch(iters,\n","\t\t\t\t\t\t\t\t\t\twarmup_iters,\n","\t\t\t\t\t\t\t\t\t\tlrate,\n","\t\t\t\t\t\t\t\t\t\ttrain_loader,\n","\t\t\t\t\t\t\t\t\t\tmodel,\n","\t\t\t\t\t\t\t\t\t\toptimizer,\n","\t\t\t\t\t\t\t\t\t\tscheduler,\n","\t\t\t\t\t\t\t\t\t\tepoch,\n","\t\t\t\t\t\t\t\t\t\texpert_fns,\n","\t\t\t\t\t\t\t\t\t\tloss_fn,\n","\t\t\t\t\t\t\t\t\t\tn_classes,\n","\t\t\t\t\t\t\t\t\t\tconfig[\"alpha\"],\n","\t\t\t\t\t\t\t\t\t\tconfig)\n","\t\tmetrics = evaluate(model,\n","\t\t\t\t\t\t   expert_fns,\n","\t\t\t\t\t\t   loss_fn,\n","\t\t\t\t\t\t   n_classes,\n","\t\t\t\t\t\t   valid_loader,\n","\t\t\t\t\t\t   config)\n","\n","\t\tvalidation_loss = metrics[\"validation_loss\"]\n","\n","\t\tif validation_loss < best_validation_loss:\n","\t\t\tbest_validation_loss = validation_loss\n","\t\t\tprint(\"Saving the model with classifier accuracy {}\".format(metrics['classifier_accuracy']), flush=True)\n","\t\t\tsave_path = os.path.join(config[\"ckp_dir\"],\n","\t\t\t\t\t\t\t\t\t config[\"experiment_name\"] + '_' + str(len(expert_fns)) + '_experts' + '_seed_' + str(seed))\n","\t\t\ttorch.save(model.state_dict(), save_path + '.pt')\n","\t\t\t# Additionally save the whole config dict\n","\t\t\twith open(save_path + '.json', \"w\") as f:\n","\t\t\t\tjson.dump(config, f)\n","\t\t\tpatience = 0\n","\t\telse:\n","\t\t\tpatience += 1\n","\n","\t\tif patience >= config[\"patience\"]:\n","\t\t\tprint(\"Early Exiting Training.\", flush=True)\n","\t\t\tbreak\n","\n","\n","# === Experiment 1 === #\n","expert1 = synth_expert(flip_prob=0.75, p_in=0.10)\n","expert2 = synth_expert(flip_prob=0.50, p_in=0.50)\n","expert3 = synth_expert(flip_prob=0.30, p_in=0.75)\n","expert4 = synth_expert(flip_prob=0.20, p_in=0.85)\n","available_experts = [expert1, expert2, expert3, expert4]\n","available_expert_fns = ['FlipHuman', 'predict_prob', 'predict_random']\n","def increase_experts(config):\n","\tconfig[\"ckp_dir\"] = \"./\" + config[\"loss_type\"] + \"_increase_experts\"\n","\tos.makedirs(config[\"ckp_dir\"], exist_ok=True)\n","\n","\texperiment_experts = [1,2,3,4,5,6,7,8,9,10]\n","\t\n","\tfor seed in ['']:\n","\t\tprint(\"run for seed {}\".format(seed))\n","\t\tif seed != '':\n","\t\t\tset_seed(seed)\n","\t\tlog = {'selected_experts' : [], 'selected_expert_fns' : []}\n","\t\texpert_fns = []\n","\t\tfor i,n in enumerate(experiment_experts):\n","\t\t\tprint(\"n is {}\".format(n))\n","\t\t\tnum_experts = n\n","\t\t\tselected_expert = random.choices(available_experts,k=1)\n","\t\t\tif i < 7:\n","\t\t\t\tselected_expert_fn = random.choices(available_expert_fns, k=1)\n","\t\t\telse: \n","\t\t\t\tselected_expert_fn = 'HumanExpert'\n","\t\t\tprint(\"selected experts {}\".format(selected_expert))\n","\t\t\tprint(\"selected experts fn. {}\".format(selected_expert_fn))\n","\n","\t\t\tlog['selected_expert'].append(selected_expert)\n","\t\t\tlog['selected_expert_fn'].append(selected_expert_fn)\n","\t\t\texpert_fn = getattr(selected_expert, selected_expert_fn)\n","\t\t\texpert_fns.append(expert_fn)\n","\n","\t\t\tmodel = surrogate_CNN(embedding_dim=100, vocab_size=100, n_filters=300, filter_sizes=[3,4,5], dropout=0.5, output_dim=int(config[\"n_classes\"])+num_experts) \n","\t\t\ttrainD = HatespeechDataset()\n","\t\t\tvalD = HatespeechDataset(split='val')\n","\t\t\ttrain(model, trainD, valD, expert_fns, config, seed=seed)\n","\n","\t\tpth = os.path.join(config['ckp_dir'], config['experiment_name'] + '_log_' + '_seed_' + str(seed))\n","\t\twith open(pth + '.json', 'w') as f:\n","\t\t\tjson.dump(log, f)\n","\n","\n","\n","\n","# if __name__ == \"__main__\":"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JjVQPdmOsltI"},"outputs":[],"source":["parser = argparse.ArgumentParser()\n","\n","parser.add_argument(\"--batch_size\", type=int, default=128)\n","parser.add_argument(\"--alpha\", type=float, default=1.0,\n","          help=\"scaling parameter for the loss function, default=1.0.\")\n","parser.add_argument(\"--epochs\", type=int, default=150)\n","parser.add_argument(\"--patience\", type=int, default=50,\n","          help=\"number of patience steps for early stopping the training.\")\n","parser.add_argument(\"--expert_type\", type=str, default=\"predict_prob\",\n","          help=\"specify the expert type. For the type of experts available, see-> models -> experts. defualt=predict.\")\n","parser.add_argument(\"--n_classes\", type=int, default=2,\n","          help=\"K for K class classification.\")\n","parser.add_argument(\"--k\", type=int, default=0)\n","# Dani experiments =====\n","parser.add_argument(\"--n_experts\", type=int, default=2)\n","# Dani experiments =====\n","parser.add_argument(\"--lr\", type=float, default=0.001,\n","          help=\"learning rate.\")\n","parser.add_argument(\"--weight_decay\", type=float, default=5e-4)\n","parser.add_argument(\"--warmup_epochs\", type=int, default=5)\n","parser.add_argument(\"--loss_type\", type=str, default=\"softmax\",\n","          help=\"surrogate loss type for learning to defer.\")\n","parser.add_argument(\"--ckp_dir\", type=str, default=\"./Models\",\n","          help=\"directory name to save the checkpoints.\")\n","parser.add_argument(\"--experiment_name\", type=str, default=\"multiple_experts\",\n","          help=\"specify the experiment name. Checkpoints will be saved with this name.\")\n","\n","config = parser.parse_args(args=[]).__dict__\n","\n","# print(config)\n","# increase_experts(config)"]},{"cell_type":"markdown","metadata":{"id":"LT7qB_PjVVVH"},"source":["### Hemmer MoE Baseline"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1669734190085,"user":{"displayName":"Rajeev Verma","userId":"08402565592776020942"},"user_tz":-330},"id":"CcDMBNTlVZH3","outputId":"4b33007a-f76c-4db1-fdc0-6dd1be7375ef"},"outputs":[{"name":"stdout","output_type":"stream","text":["cpu\n"]}],"source":["import math\n","import random\n","import argparse\n","import shutil\n","import time\n","import torch.optim\n","import torch.utils.data\n","from torch.autograd import Variable\n","import json\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import copy\n","import os\n","import pickle5 as pickle\n","\n","from utils import *\n","from data_utils import *\n","from models.surrogate_CNN import *\n","from models.baseline import *\n","from models.experts import *\n","from losses.losses import *\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device,  flush=True)\n","\n","\n","def set_seed(seed):\n","        random.seed(seed)\n","        np.random.seed(seed)\n","        torch.manual_seed(seed)\n","        if torch.cuda.is_available():\n","            torch.cuda.manual_seed(seed)\n","            torch.cuda.manual_seed_all(seed)\n","\n","\n","def Hemmer_utils(input, target, hpred, allocation, clf_output, expert_fns, config):\n","    batch_size = clf_output.size()[0]  # batch_size\n","    exps_pred = []\n","    # We only support \\alpha=1\n","    expert_predictions = []\n","    for idx, fn in enumerate(expert_fns):\n","        # We assume each expert function has access to the extra metadata, even if they don't use it.\n","        m = fn(input, target, hpred)\n","        expert_predictions.append(m)\n","        exp_pred = torch.zeros((batch_size, config[\"n_classes\"]))\n","        for j in range(0, batch_size):\n","            exp_pred[j][int(m[j])] = 1\n","        exps_pred.append(exp_pred)\n","\n","    exps_pred.append(clf_output)\n","\n","    exps_pred = torch.stack(exps_pred).transpose(0,1)\n","    allocation = allocation.unsqueeze(-1)\n","    p_team = torch.sum(allocation * exps_pred, dim=1)\n","    log_p_team = torch.log(p_team + 1e-7)\n","    return log_p_team, expert_predictions\n","\n","def evaluate(model,\n","             expert_fns,\n","             loss_fn,\n","             n_classes,\n","             data_loader,\n","             config):\n","    '''\n","    Computes metrics for deferal\n","    -----\n","    Arguments:\n","    net: model\n","    expert_fn: expert model\n","    n_classes: number of classes\n","    loader: data loader\n","    '''\n","    correct = 0\n","    correct_sys = 0\n","    exp = 0\n","    exp_total = 0\n","    total = 0\n","    real_total = 0\n","    alone_correct = 0\n","    #  === Individual Expert Accuracies === #\n","    expert_correct_dic = {k: 0 for k in range(len(expert_fns))}\n","    expert_total_dic = {k: 0 for k in range(len(expert_fns))}\n","    #  === Individual  Expert Accuracies === #\n","    alpha = config[\"alpha\"]\n","    losses = []\n","    allocator, classifier = model[0], model[1]\n","    allocator.eval()\n","    classifier.eval()\n","    with torch.no_grad():\n","        for data in data_loader:\n","            images, labels, hpred = data\n","            images, labels, hpred = images.to(device), labels.to(device), hpred\n","            allocation = allocator(images)\n","            clf_pred = classifier(images)\n","            # outputs = model(images)\n","\n","            _, clf_predictions = torch.max(clf_pred.data, 1)\n","            _, who_predicts = torch.max(allocation.data, 1)\n","            batch_size = clf_pred.size()[0]  # batch_size\n","\n","            log_p_team, expert_predictions = Hemmer_utils(images, labels, hpred, allocation, clf_pred, expert_fns, config)\n","\n","            #print(\"len expert predictions {}\".format(len(expert_predictions)))\n","\n","            loss = loss_fn(log_p_team, labels)\n","            losses.append(loss.item())\n","\n","            for i in range(0, batch_size):\n","                r = (who_predicts[i].item() != len(expert_fns)) # r is true when non-ai expert has the maximum weight\n","                clf_prediction = clf_predictions[i]\n","                alone_correct += (clf_prediction == labels[i]).item()\n","                if r == 0: # the max is on the classifier \n","                    total += 1\n","                    correct += (clf_prediction == labels[i]).item()\n","                    correct_sys += (clf_prediction == labels[i]).item()\n","                if r == 1:\n","                    \n","                    deferred_exp = (who_predicts[i]).item()\n","\n","                    #print(len(expert_predictions), deferred_exp, batch_size)\n","                    exp_prediction = expert_predictions[deferred_exp][i]\n","                    #\n","                    # Deferral accuracy: No matter expert ===\n","                    exp += (exp_prediction == labels[i].item())\n","                    exp_total += 1\n","                    # Individual Expert Accuracy ===\n","                    expert_correct_dic[deferred_exp] += (exp_prediction == labels[i].item())\n","                    expert_total_dic[deferred_exp] += 1\n","                    #\n","                    correct_sys += (exp_prediction == labels[i].item())\n","                real_total += 1\n","    cov = str(total) + str(\" out of\") + str(real_total)\n","\n","    #  === Individual Expert Accuracies === #\n","    expert_accuracies = {\"expert_{}\".format(str(k)): 100 * expert_correct_dic[k] / (expert_total_dic[k] + 0.0002) for k\n","                         in range(len(expert_fns))}\n","    # Add expert accuracies dict\n","    to_print = {\"coverage\": cov, \"system_accuracy\": 100 * correct_sys / real_total,\n","                \"expert_accuracy\": 100 * exp / (exp_total + 0.0002),\n","                \"classifier_accuracy\": 100 * correct / (total + 0.0001),\n","                \"alone_classifier\": 100 * alone_correct / real_total,\n","                \"validation_loss\": np.average(losses),\n","                \"n_experts\": len(expert_fns),\n","                **expert_accuracies}\n","    print(to_print, flush=True)\n","    return to_print\n","\n","\n","\n","def train_epoch(iters,\n","                warmup_iters,\n","                lrate,\n","                train_loader,\n","                model,\n","                optimizer,\n","                scheduler,\n","                epoch,\n","                expert_fns,\n","                loss_fn,\n","                n_classes,\n","                alpha,\n","                config):\n","    \"\"\" Train for one epoch \"\"\"\n","\n","    batch_time = AverageMeter()\n","    losses = AverageMeter()\n","    top1 = AverageMeter()\n","\n","    allocator, classifier = model[0], model[1]\n","    allocator.train()\n","    classifier.train()\n","\n","    end = time.time()\n","\n","    epoch_train_loss = []\n","\n","    for i, (input, target, hpred) in enumerate(train_loader):\n","        if iters < warmup_iters:\n","            lr = lrate * float(iters) / warmup_iters\n","            print(iters, lr)\n","            for param_group in optimizer.param_groups:\n","                param_group['lr'] = lr\n","\n","        target = target.to(device)\n","        input = input.to(device)\n","        hpred = hpred\n","\n","        # compute output\n","        allocation = allocator(input) # allocation w_j j in {1, ..., num_experts + 1} (from the paper)\n","        clf_output = classifier(input) # c_i i in {1, K} (from the paper)\n","\n","        # get expert  predictions and costs\n","        batch_size = clf_output.size()[0]  # batch_size\n","        exps_pred = []\n","        # We only support \\alpha=1\n","\n","        log_p_team, _ = Hemmer_utils(input, target, hpred, allocation, clf_output, expert_fns, config)\n","\n","        loss = loss_fn(log_p_team, target)\n","\n","        epoch_train_loss.append(loss.item())\n","\n","        # measure accuracy and record loss\n","        prec1 = accuracy(log_p_team, target, topk=(1,))[0]\n","        losses.update(loss.data.item(), input.size(0))\n","        top1.update(prec1.item(), input.size(0))\n","\n","        # compute gradient and do SGD step\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if not iters < warmup_iters:\n","            scheduler.step()\n","\n","        # measure elapsed time\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","        iters += 1\n","\n","        if i % 10 == 0:\n","            print('Epoch: [{0}][{1}/{2}]\\t'\n","                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n","                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n","                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n","                epoch, i, len(train_loader), batch_time=batch_time,\n","                loss=losses, top1=top1), flush=True)\n","\n","    return iters, np.average(epoch_train_loss)\n","\n","\n","def train(model,\n","          train_dataset,\n","          validation_dataset,\n","          expert_fns,\n","          config,\n","          seed=\"\"):\n","  \n","    n_classes = config[\"n_classes\"] + len(expert_fns)\n","    kwargs = {'num_workers': 0, 'pin_memory': True}\n","\n","    train_loader = torch.utils.data.DataLoader(train_dataset,\n","                                               batch_size=config[\"batch_size\"], shuffle=True, drop_last=True, **kwargs)\n","    valid_loader = torch.utils.data.DataLoader(validation_dataset,\n","                                               batch_size=config[\"batch_size\"], shuffle=True, drop_last=True, **kwargs)\n","  \n","    model = (model[0].to(device), model[1].to(device))\n","    #cudnn.benchmark = True\n","    optimizer = torch.optim.Adam(list(model[0].parameters()) + list(model[1].parameters()), config[\"lr\"],\n","                                weight_decay=config[\"weight_decay\"])\n"," \n","    criterion = Criterion()\n"," \n","    loss_fn = nn.NLLLoss() #getattr(criterion, config[\"loss_type\"])\n","    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, len(train_loader) * config[\"epochs\"])\n","    best_validation_loss = np.inf\n","    patience = 0\n","    iters = 0\n","    warmup_iters = config[\"warmup_epochs\"] * len(train_loader)\n","    lrate = config[\"lr\"]\n","\n","    for epoch in range(0, config[\"epochs\"]):\n","        iters, train_loss = train_epoch(iters,\n","                                        warmup_iters,\n","                                        lrate,\n","                                        train_loader,\n","                                        model,\n","                                        optimizer,\n","                                        scheduler,\n","                                        epoch,\n","                                        expert_fns,\n","                                        loss_fn,\n","                                        n_classes,\n","                                        config[\"alpha\"],\n","                                        config)\n","        metrics = evaluate(model,\n","                           expert_fns,\n","                           loss_fn,\n","                           n_classes,\n","                           valid_loader,\n","                           config)\n","\n","        validation_loss = metrics[\"validation_loss\"]\n","\n","        if validation_loss < best_validation_loss:\n","            best_validation_loss = validation_loss\n","            print(\"Saving the model with classifier accuracy {}\".format(metrics['classifier_accuracy']), flush=True)\n","            save_path = os.path.join(config[\"ckp_dir\"],\n","                                     config[\"experiment_name\"] + '_' + str(len(expert_fns)) + '_experts' + '_seed_' + str(seed))\n","            torch.save({'allocator_state_dict' : model[0].state_dict(), \n","                        'classifier_state_dict' : model[1].state_dict}, save_path + '.pt')\n","            # Additionally save the whole config dict\n","            with open(save_path + '.json', \"w\") as f:\n","                json.dump(config, f)\n","            patience = 0\n","        else:\n","            patience += 1\n","\n","        if patience >= config[\"patience\"]:\n","            print(\"Early Exiting Training.\", flush=True)\n","            break\n","\n","\n","# === Experiment 1 === #\n","expert1 = synth_expert(flip_prob=0.75, p_in=0.10)\n","expert2 = synth_expert(flip_prob=0.50, p_in=0.50)\n","expert3 = synth_expert(flip_prob=0.30, p_in=0.75)\n","expert4 = synth_expert(flip_prob=0.20, p_in=0.85)\n","available_experts = [expert1, expert2, expert3, expert4]\n","available_expert_fns = ['FlipHuman', 'predict_prob', 'predict_random']\n","def increase_experts(config):\n","    config[\"ckp_dir\"] = \"./\" + config[\"loss_type\"] + \"_increase_experts\"\n","    os.makedirs(config[\"ckp_dir\"], exist_ok=True)\n","\n","    experiment_experts = [1,2,3,4,5,6,7,8,9,10]\n","    \n","    for seed in ['']:\n","        print(\"run for seed {}\".format(seed))\n","        if seed != '':\n","            set_seed(seed)\n","        log = {'selected_experts' : [], 'selected_expert_fns' : []}\n","        expert_fns = []\n","        for i,n in enumerate(experiment_experts):\n","            print(\"Number of Experts: n is {}\".format(n))\n","            num_experts = n\n","            selected_expert = random.choices(available_experts,k=1)[0]\n","            if i < 7:\n","                selected_expert_fn = random.choices(available_expert_fns, k=1)[0]\n","            else: \n","                selected_expert_fn = 'HumanExpert'\n","            print(\"selected experts {}\".format(selected_expert))\n","            print(\"selected experts fn. {}\".format(selected_expert_fn))\n","\n","            log['selected_experts'].append(selected_expert)\n","            log['selected_expert_fns'].append(selected_expert_fn)\n","            expert_fn = getattr(selected_expert, selected_expert_fn)\n","            expert_fns.append(expert_fn)\n","\n","            print(len(expert_fns))\n","            classifier = baseline_classifier(embedding_dim=100, vocab_size=100, n_filters=300, filter_sizes=[3,4,5], dropout=0.5, output_dim=int(config[\"n_classes\"]))\n","            allocator = baseline_allocator(embedding_dim=100, vocab_size=100, n_filters=300, filter_sizes=[3,4,5], dropout=0.5, output_dim=len(expert_fns)+1) \n","            model = (allocator, classifier)\n","            trainD = HatespeechDataset()\n","            valD = HatespeechDataset(split='val')\n","            train(model, trainD, valD, expert_fns, config, seed=seed)\n","\n","        pth = os.path.join(config['ckp_dir'], config['experiment_name'] + '_log_' + '_seed_' + str(seed))\n","        with open(pth + '.json', 'w') as f:\n","            json.dump(log, f)\n","\n","\n","\n","\n","# if __name__ == \"__main__\":"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7IO8bSQ3aQgY"},"outputs":[],"source":["parser = argparse.ArgumentParser()\n","\n","parser.add_argument(\"--batch_size\", type=int, default=256)\n","parser.add_argument(\"--alpha\", type=float, default=1.0,\n","          help=\"scaling parameter for the loss function, default=1.0.\")\n","parser.add_argument(\"--epochs\", type=int, default=100)\n","parser.add_argument(\"--patience\", type=int, default=20,\n","          help=\"number of patience steps for early stopping the training.\")\n","parser.add_argument(\"--expert_type\", type=str, default=\"predict_prob\",\n","          help=\"specify the expert type. For the type of experts available, see-> models -> experts. defualt=predict.\")\n","parser.add_argument(\"--n_classes\", type=int, default=3,\n","          help=\"K for K class classification.\")\n","parser.add_argument(\"--k\", type=int, default=0)\n","# Dani experiments =====\n","parser.add_argument(\"--n_experts\", type=int, default=2)\n","# Dani experiments =====\n","parser.add_argument(\"--lr\", type=float, default=0.001,\n","          help=\"learning rate.\")\n","parser.add_argument(\"--weight_decay\", type=float, default=5e-4)\n","parser.add_argument(\"--warmup_epochs\", type=int, default=0)\n","parser.add_argument(\"--loss_type\", type=str, default=\"hemmer\",\n","          help=\"surrogate loss type for learning to defer.\")\n","parser.add_argument(\"--ckp_dir\", type=str, default=\"./Models\",\n","          help=\"directory name to save the checkpoints.\")\n","parser.add_argument(\"--experiment_name\", type=str, default=\"multiple_experts\",\n","          help=\"specify the experiment name. Checkpoints will be saved with this name.\")\n","\n","config = parser.parse_args(args=[]).__dict__\n","\n","# print(config)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":3750310,"status":"error","timestamp":1669737940389,"user":{"displayName":"Rajeev Verma","userId":"08402565592776020942"},"user_tz":-330},"id":"-0R22P0kb3KG","outputId":"c37efdb4-0c8f-491b-8ea7-50a89cc01196"},"outputs":[{"name":"stdout","output_type":"stream","text":["run for seed \n","Number of Experts: n is 1\n","selected experts <models.experts.synth_expert object at 0x7f4e7913ef50>\n","selected experts fn. predict_prob\n","1\n","dict_keys(['X', 'Y', 'c', 'hpred', 'hloss', 'hprob'])\n","dict_keys(['X', 'Y', 'c', 'hpred', 'hloss', 'hprob'])\n","Epoch: [0][0/48]\tTime 0.616 (0.616)\tLoss 0.6347 (0.6347)\tPrec@1 82.422 (82.422)\n","Epoch: [0][10/48]\tTime 1.039 (0.777)\tLoss 0.5975 (0.5400)\tPrec@1 82.422 (81.534)\n","Epoch: [0][20/48]\tTime 0.649 (0.871)\tLoss 0.5880 (0.5415)\tPrec@1 82.422 (81.250)\n","Epoch: [0][30/48]\tTime 0.568 (0.786)\tLoss 0.4546 (0.5377)\tPrec@1 81.250 (81.111)\n","Epoch: [0][40/48]\tTime 0.574 (0.748)\tLoss 0.4754 (0.5262)\tPrec@1 83.594 (81.031)\n","{'coverage': '4096 out of4096', 'system_accuracy': 77.63671875, 'expert_accuracy': 0.0, 'classifier_accuracy': 77.63671685457234, 'alone_classifier': 77.63671875, 'validation_loss': 0.4457107186317444, 'n_experts': 1, 'expert_0': 0.0}\n","Saving the model with classifier accuracy 77.63671685457234\n","Epoch: [1][0/48]\tTime 0.710 (0.710)\tLoss 0.5312 (0.5312)\tPrec@1 80.859 (80.859)\n","Epoch: [1][10/48]\tTime 0.701 (0.645)\tLoss 0.4971 (0.4809)\tPrec@1 80.469 (82.351)\n","Epoch: [1][20/48]\tTime 0.561 (0.621)\tLoss 0.4811 (0.4742)\tPrec@1 80.078 (82.161)\n","Epoch: [1][30/48]\tTime 0.575 (0.610)\tLoss 0.4685 (0.4659)\tPrec@1 80.859 (82.674)\n","Epoch: [1][40/48]\tTime 0.576 (0.616)\tLoss 0.4104 (0.4599)\tPrec@1 85.938 (82.793)\n","{'coverage': '2524 out of4096', 'system_accuracy': 83.1787109375, 'expert_accuracy': 82.50635082616402, 'classifier_accuracy': 83.59746103021152, 'alone_classifier': 77.3681640625, 'validation_loss': 0.4114221427589655, 'n_experts': 1, 'expert_0': 82.50635082616402}\n","Saving the model with classifier accuracy 83.59746103021152\n","Epoch: [2][0/48]\tTime 0.683 (0.683)\tLoss 0.4945 (0.4945)\tPrec@1 80.859 (80.859)\n","Epoch: [2][10/48]\tTime 0.693 (0.658)\tLoss 0.4802 (0.4505)\tPrec@1 78.125 (81.996)\n","Epoch: [2][20/48]\tTime 0.557 (0.645)\tLoss 0.3551 (0.4366)\tPrec@1 85.938 (82.757)\n","Epoch: [2][30/48]\tTime 0.914 (0.652)\tLoss 0.5270 (0.4372)\tPrec@1 81.250 (82.649)\n","Epoch: [2][40/48]\tTime 0.558 (0.653)\tLoss 0.5087 (0.4400)\tPrec@1 82.422 (82.793)\n","{'coverage': '236 out of4096', 'system_accuracy': 84.1552734375, 'expert_accuracy': 83.75647234422424, 'classifier_accuracy': 90.6779276788442, 'alone_classifier': 78.22265625, 'validation_loss': 0.38685497641563416, 'n_experts': 1, 'expert_0': 83.75647234422424}\n","Saving the model with classifier accuracy 90.6779276788442\n","Epoch: [3][0/48]\tTime 0.684 (0.684)\tLoss 0.4301 (0.4301)\tPrec@1 82.422 (82.422)\n","Epoch: [3][10/48]\tTime 0.566 (0.664)\tLoss 0.4069 (0.4416)\tPrec@1 81.641 (82.884)\n","Epoch: [3][20/48]\tTime 0.671 (0.647)\tLoss 0.3607 (0.4332)\tPrec@1 86.719 (82.887)\n","Epoch: [3][30/48]\tTime 0.576 (0.647)\tLoss 0.4963 (0.4315)\tPrec@1 81.250 (83.178)\n","Epoch: [3][40/48]\tTime 0.577 (0.643)\tLoss 0.4502 (0.4298)\tPrec@1 84.766 (83.232)\n","{'coverage': '1978 out of4096', 'system_accuracy': 84.5703125, 'expert_accuracy': 83.14446806945533, 'classifier_accuracy': 86.09706339246394, 'alone_classifier': 77.3681640625, 'validation_loss': 0.4226273950189352, 'n_experts': 1, 'expert_0': 83.14446806945533}\n","Epoch: [4][0/48]\tTime 0.655 (0.655)\tLoss 0.4175 (0.4175)\tPrec@1 82.812 (82.812)\n","Epoch: [4][10/48]\tTime 0.568 (0.592)\tLoss 0.3897 (0.4322)\tPrec@1 87.500 (84.233)\n","Epoch: [4][20/48]\tTime 0.697 (0.643)\tLoss 0.3928 (0.4299)\tPrec@1 83.203 (83.910)\n","Epoch: [4][30/48]\tTime 0.696 (0.639)\tLoss 0.4259 (0.4308)\tPrec@1 82.812 (83.682)\n","Epoch: [4][40/48]\tTime 0.704 (0.649)\tLoss 0.3999 (0.4309)\tPrec@1 85.156 (83.498)\n","{'coverage': '0 out of4096', 'system_accuracy': 83.1298828125, 'expert_accuracy': 83.12987875342388, 'classifier_accuracy': 0.0, 'alone_classifier': 77.6123046875, 'validation_loss': 0.4216621294617653, 'n_experts': 1, 'expert_0': 83.12987875342388}\n","Epoch: [5][0/48]\tTime 0.696 (0.696)\tLoss 0.3961 (0.3961)\tPrec@1 82.812 (82.812)\n","Epoch: [5][10/48]\tTime 0.731 (0.791)\tLoss 0.3957 (0.4303)\tPrec@1 85.547 (83.381)\n","Epoch: [5][20/48]\tTime 0.552 (0.694)\tLoss 0.4687 (0.4251)\tPrec@1 82.031 (83.464)\n","Epoch: [5][30/48]\tTime 0.575 (0.671)\tLoss 0.3166 (0.4157)\tPrec@1 88.281 (84.047)\n","Epoch: [5][40/48]\tTime 0.687 (0.663)\tLoss 0.4027 (0.4154)\tPrec@1 82.812 (84.051)\n","{'coverage': '636 out of4096', 'system_accuracy': 84.423828125, 'expert_accuracy': 83.26589114069994, 'classifier_accuracy': 90.72325617558866, 'alone_classifier': 77.63671875, 'validation_loss': 0.391190554946661, 'n_experts': 1, 'expert_0': 83.26589114069994}\n","Epoch: [6][0/48]\tTime 0.574 (0.574)\tLoss 0.3541 (0.3541)\tPrec@1 87.500 (87.500)\n","Epoch: [6][10/48]\tTime 0.561 (0.602)\tLoss 0.3974 (0.4087)\tPrec@1 84.375 (84.837)\n","Epoch: [6][20/48]\tTime 0.686 (0.608)\tLoss 0.4619 (0.4186)\tPrec@1 85.156 (84.449)\n","Epoch: [6][30/48]\tTime 0.675 (0.611)\tLoss 0.3941 (0.4145)\tPrec@1 87.109 (84.249)\n","Epoch: [6][40/48]\tTime 0.586 (0.624)\tLoss 0.3588 (0.4139)\tPrec@1 88.281 (84.251)\n","{'coverage': '3278 out of4096', 'system_accuracy': 83.984375, 'expert_accuracy': 78.9730858256514, 'classifier_accuracy': 85.23489672864866, 'alone_classifier': 79.6630859375, 'validation_loss': 0.38382894545793533, 'n_experts': 1, 'expert_0': 78.9730858256514}\n","Saving the model with classifier accuracy 85.23489672864866\n","Epoch: [7][0/48]\tTime 0.570 (0.570)\tLoss 0.4239 (0.4239)\tPrec@1 83.594 (83.594)\n","Epoch: [7][10/48]\tTime 0.688 (0.630)\tLoss 0.4179 (0.4115)\tPrec@1 85.938 (83.949)\n","Epoch: [7][20/48]\tTime 0.576 (0.624)\tLoss 0.4228 (0.4094)\tPrec@1 85.156 (84.282)\n","Epoch: [7][30/48]\tTime 0.680 (0.621)\tLoss 0.4254 (0.4191)\tPrec@1 84.375 (83.821)\n","Epoch: [7][40/48]\tTime 0.696 (0.638)\tLoss 0.4366 (0.4169)\tPrec@1 84.375 (83.937)\n","{'coverage': '3917 out of4096', 'system_accuracy': 80.224609375, 'expert_accuracy': 81.56415467692214, 'classifier_accuracy': 80.16338830320683, 'alone_classifier': 79.1748046875, 'validation_loss': 0.3880290910601616, 'n_experts': 1, 'expert_0': 81.56415467692214}\n","Epoch: [8][0/48]\tTime 0.815 (0.815)\tLoss 0.3411 (0.3411)\tPrec@1 85.156 (85.156)\n","Epoch: [8][10/48]\tTime 0.554 (0.604)\tLoss 0.4519 (0.4306)\tPrec@1 82.422 (83.558)\n","Epoch: [8][20/48]\tTime 0.553 (0.594)\tLoss 0.4099 (0.4148)\tPrec@1 84.375 (84.282)\n","Epoch: [8][30/48]\tTime 0.556 (0.600)\tLoss 0.3908 (0.4091)\tPrec@1 83.984 (84.539)\n","Epoch: [8][40/48]\tTime 0.556 (0.589)\tLoss 0.4095 (0.4078)\tPrec@1 83.594 (84.566)\n","{'coverage': '2240 out of4096', 'system_accuracy': 85.3759765625, 'expert_accuracy': 82.00430150815717, 'classifier_accuracy': 88.16963892099825, 'alone_classifier': 78.61328125, 'validation_loss': 0.38416277430951595, 'n_experts': 1, 'expert_0': 82.00430150815717}\n","Epoch: [9][0/48]\tTime 0.639 (0.639)\tLoss 0.3861 (0.3861)\tPrec@1 84.766 (84.766)\n","Epoch: [9][10/48]\tTime 0.655 (0.625)\tLoss 0.3331 (0.3996)\tPrec@1 87.891 (84.339)\n","Epoch: [9][20/48]\tTime 0.566 (0.637)\tLoss 0.4303 (0.3895)\tPrec@1 82.422 (84.580)\n","Epoch: [9][30/48]\tTime 0.693 (0.628)\tLoss 0.3666 (0.3874)\tPrec@1 85.547 (84.677)\n","Epoch: [9][40/48]\tTime 0.662 (0.619)\tLoss 0.3576 (0.3973)\tPrec@1 87.109 (84.613)\n","{'coverage': '3362 out of4096', 'system_accuracy': 84.1064453125, 'expert_accuracy': 81.33512770160009, 'classifier_accuracy': 84.71147874147891, 'alone_classifier': 79.541015625, 'validation_loss': 0.37338283099234104, 'n_experts': 1, 'expert_0': 81.33512770160009}\n","Saving the model with classifier accuracy 84.71147874147891\n","Epoch: [10][0/48]\tTime 0.575 (0.575)\tLoss 0.3303 (0.3303)\tPrec@1 87.109 (87.109)\n","Epoch: [10][10/48]\tTime 0.707 (0.666)\tLoss 0.3821 (0.3874)\tPrec@1 84.766 (84.411)\n","Epoch: [10][20/48]\tTime 0.564 (0.661)\tLoss 0.4451 (0.4020)\tPrec@1 80.859 (84.115)\n","Epoch: [10][30/48]\tTime 0.585 (0.652)\tLoss 0.3324 (0.4070)\tPrec@1 85.938 (83.884)\n","Epoch: [10][40/48]\tTime 0.562 (0.635)\tLoss 0.3554 (0.4056)\tPrec@1 87.500 (84.261)\n","{'coverage': '2468 out of4096', 'system_accuracy': 84.9365234375, 'expert_accuracy': 81.38819638965647, 'classifier_accuracy': 87.27714395149334, 'alone_classifier': 78.564453125, 'validation_loss': 0.3868637140840292, 'n_experts': 1, 'expert_0': 81.38819638965647}\n","Epoch: [11][0/48]\tTime 0.576 (0.576)\tLoss 0.3730 (0.3730)\tPrec@1 85.547 (85.547)\n","Epoch: [11][10/48]\tTime 0.659 (0.670)\tLoss 0.3412 (0.3976)\tPrec@1 87.891 (85.156)\n","Epoch: [11][20/48]\tTime 0.576 (0.632)\tLoss 0.4671 (0.4034)\tPrec@1 83.203 (84.952)\n","Epoch: [11][30/48]\tTime 0.550 (0.617)\tLoss 0.3591 (0.4052)\tPrec@1 86.328 (84.652)\n","Epoch: [11][40/48]\tTime 0.554 (0.615)\tLoss 0.3947 (0.4043)\tPrec@1 85.156 (84.889)\n","{'coverage': '383 out of4096', 'system_accuracy': 84.1552734375, 'expert_accuracy': 83.51736689914533, 'classifier_accuracy': 90.33940200015614, 'alone_classifier': 79.78515625, 'validation_loss': 0.3765590004622936, 'n_experts': 1, 'expert_0': 83.51736689914533}\n","Epoch: [12][0/48]\tTime 0.712 (0.712)\tLoss 0.3532 (0.3532)\tPrec@1 86.328 (86.328)\n","Epoch: [12][10/48]\tTime 0.563 (0.653)\tLoss 0.3417 (0.4081)\tPrec@1 87.500 (83.842)\n","Epoch: [12][20/48]\tTime 0.680 (0.630)\tLoss 0.4453 (0.4049)\tPrec@1 83.984 (83.929)\n","Epoch: [12][30/48]\tTime 0.560 (0.609)\tLoss 0.3966 (0.3974)\tPrec@1 85.156 (84.047)\n","Epoch: [12][40/48]\tTime 0.691 (0.612)\tLoss 0.4364 (0.3936)\tPrec@1 83.594 (84.308)\n","{'coverage': '1538 out of4096', 'system_accuracy': 85.0830078125, 'expert_accuracy': 82.56449706297911, 'classifier_accuracy': 89.27177573005359, 'alone_classifier': 79.8583984375, 'validation_loss': 0.3763879854232073, 'n_experts': 1, 'expert_0': 82.56449706297911}\n","Epoch: [13][0/48]\tTime 0.577 (0.577)\tLoss 0.3744 (0.3744)\tPrec@1 82.422 (82.422)\n","Epoch: [13][10/48]\tTime 0.710 (0.600)\tLoss 0.3845 (0.3934)\tPrec@1 84.375 (84.411)\n","Epoch: [13][20/48]\tTime 0.678 (0.601)\tLoss 0.4081 (0.3941)\tPrec@1 83.203 (84.524)\n","Epoch: [13][30/48]\tTime 0.698 (0.635)\tLoss 0.4329 (0.3924)\tPrec@1 84.766 (84.640)\n","Epoch: [13][40/48]\tTime 0.692 (0.633)\tLoss 0.4331 (0.3931)\tPrec@1 78.906 (84.423)\n","{'coverage': '4065 out of4096', 'system_accuracy': 79.5654296875, 'expert_accuracy': 93.54778356268669, 'classifier_accuracy': 79.45879263324002, 'alone_classifier': 79.19921875, 'validation_loss': 0.3717097323387861, 'n_experts': 1, 'expert_0': 93.54778356268669}\n","Saving the model with classifier accuracy 79.45879263324002\n","Epoch: [14][0/48]\tTime 0.574 (0.574)\tLoss 0.3319 (0.3319)\tPrec@1 86.719 (86.719)\n","Epoch: [14][10/48]\tTime 0.567 (0.628)\tLoss 0.3976 (0.4055)\tPrec@1 84.766 (84.482)\n","Epoch: [14][20/48]\tTime 0.561 (0.608)\tLoss 0.3719 (0.4036)\tPrec@1 87.109 (84.524)\n","Epoch: [14][30/48]\tTime 0.722 (0.619)\tLoss 0.3816 (0.4012)\tPrec@1 85.938 (84.652)\n","Epoch: [14][40/48]\tTime 0.564 (0.623)\tLoss 0.3194 (0.3936)\tPrec@1 87.891 (85.071)\n","{'coverage': '3412 out of4096', 'system_accuracy': 84.1064453125, 'expert_accuracy': 80.26313442598409, 'classifier_accuracy': 84.87690255343192, 'alone_classifier': 80.1513671875, 'validation_loss': 0.37238447554409504, 'n_experts': 1, 'expert_0': 80.26313442598409}\n","Epoch: [15][0/48]\tTime 0.708 (0.708)\tLoss 0.3672 (0.3672)\tPrec@1 83.984 (83.984)\n","Epoch: [15][10/48]\tTime 0.559 (0.619)\tLoss 0.3994 (0.3868)\tPrec@1 85.547 (85.156)\n","Epoch: [15][20/48]\tTime 0.681 (0.632)\tLoss 0.4150 (0.3919)\tPrec@1 81.250 (84.356)\n","Epoch: [15][30/48]\tTime 0.628 (0.633)\tLoss 0.5601 (0.3947)\tPrec@1 80.078 (84.388)\n","Epoch: [15][40/48]\tTime 0.574 (0.635)\tLoss 0.4172 (0.3944)\tPrec@1 83.984 (84.404)\n","{'coverage': '2990 out of4096', 'system_accuracy': 85.44921875, 'expert_accuracy': 81.28389126873576, 'classifier_accuracy': 86.98996364582061, 'alone_classifier': 80.56640625, 'validation_loss': 0.3749048002064228, 'n_experts': 1, 'expert_0': 81.28389126873576}\n","Epoch: [16][0/48]\tTime 0.579 (0.579)\tLoss 0.4278 (0.4278)\tPrec@1 85.156 (85.156)\n","Epoch: [16][10/48]\tTime 0.577 (0.624)\tLoss 0.3567 (0.4044)\tPrec@1 83.984 (84.624)\n","Epoch: [16][20/48]\tTime 0.558 (0.601)\tLoss 0.5120 (0.4032)\tPrec@1 83.984 (84.524)\n","Epoch: [16][30/48]\tTime 0.657 (0.619)\tLoss 0.4941 (0.4014)\tPrec@1 81.641 (84.602)\n","Epoch: [16][40/48]\tTime 0.631 (0.620)\tLoss 0.3439 (0.3954)\tPrec@1 87.500 (84.718)\n","{'coverage': '3683 out of4096', 'system_accuracy': 82.7880859375, 'expert_accuracy': 82.56654597261696, 'classifier_accuracy': 82.81292199802003, 'alone_classifier': 80.56640625, 'validation_loss': 0.3780694827437401, 'n_experts': 1, 'expert_0': 82.56654597261696}\n","Epoch: [17][0/48]\tTime 0.625 (0.625)\tLoss 0.3702 (0.3702)\tPrec@1 89.453 (89.453)\n","Epoch: [17][10/48]\tTime 0.557 (0.611)\tLoss 0.4483 (0.3979)\tPrec@1 83.594 (85.440)\n","Epoch: [17][20/48]\tTime 0.559 (0.597)\tLoss 0.3835 (0.3910)\tPrec@1 82.812 (85.565)\n","Epoch: [17][30/48]\tTime 0.703 (0.596)\tLoss 0.3854 (0.3839)\tPrec@1 83.203 (85.333)\n","Epoch: [17][40/48]\tTime 0.641 (0.614)\tLoss 0.3440 (0.3907)\tPrec@1 83.984 (85.128)\n","{'coverage': '3532 out of4096', 'system_accuracy': 83.447265625, 'expert_accuracy': 80.31912045421261, 'classifier_accuracy': 83.94676999018205, 'alone_classifier': 79.4677734375, 'validation_loss': 0.37777319736778736, 'n_experts': 1, 'expert_0': 80.31912045421261}\n","Epoch: [18][0/48]\tTime 0.566 (0.566)\tLoss 0.4357 (0.4357)\tPrec@1 85.156 (85.156)\n","Epoch: [18][10/48]\tTime 0.562 (0.585)\tLoss 0.3622 (0.3932)\tPrec@1 84.375 (85.192)\n","Epoch: [18][20/48]\tTime 0.688 (0.603)\tLoss 0.3898 (0.3889)\tPrec@1 86.719 (85.882)\n","Epoch: [18][30/48]\tTime 0.567 (0.605)\tLoss 0.3527 (0.3899)\tPrec@1 86.328 (85.774)\n","Epoch: [18][40/48]\tTime 0.552 (0.594)\tLoss 0.4830 (0.3907)\tPrec@1 82.422 (85.394)\n","{'coverage': '3221 out of4096', 'system_accuracy': 84.716796875, 'expert_accuracy': 80.91426721959607, 'classifier_accuracy': 85.74976449084866, 'alone_classifier': 78.9306640625, 'validation_loss': 0.3834145274013281, 'n_experts': 1, 'expert_0': 80.91426721959607}\n","Epoch: [19][0/48]\tTime 0.712 (0.712)\tLoss 0.3369 (0.3369)\tPrec@1 87.109 (87.109)\n","Epoch: [19][10/48]\tTime 0.603 (0.627)\tLoss 0.3780 (0.3798)\tPrec@1 86.328 (85.653)\n","Epoch: [19][20/48]\tTime 0.711 (0.636)\tLoss 0.4348 (0.3881)\tPrec@1 80.859 (85.082)\n","Epoch: [19][30/48]\tTime 0.727 (0.640)\tLoss 0.3459 (0.3883)\tPrec@1 87.109 (85.144)\n","Epoch: [19][40/48]\tTime 0.653 (0.645)\tLoss 0.4077 (0.3877)\tPrec@1 85.156 (85.137)\n","{'coverage': '3250 out of4096', 'system_accuracy': 84.27734375, 'expert_accuracy': 79.43260533508149, 'classifier_accuracy': 85.53845890650895, 'alone_classifier': 79.5654296875, 'validation_loss': 0.38157278671860695, 'n_experts': 1, 'expert_0': 79.43260533508149}\n","Epoch: [20][0/48]\tTime 0.581 (0.581)\tLoss 0.4186 (0.4186)\tPrec@1 85.547 (85.547)\n","Epoch: [20][10/48]\tTime 0.619 (0.650)\tLoss 0.3615 (0.4034)\tPrec@1 82.031 (84.268)\n","Epoch: [20][20/48]\tTime 0.665 (0.643)\tLoss 0.3996 (0.3971)\tPrec@1 84.766 (84.877)\n","Epoch: [20][30/48]\tTime 0.564 (0.649)\tLoss 0.3568 (0.3911)\tPrec@1 85.547 (85.055)\n","Epoch: [20][40/48]\tTime 0.581 (0.644)\tLoss 0.4661 (0.3907)\tPrec@1 79.688 (85.099)\n","{'coverage': '592 out of4096', 'system_accuracy': 83.935546875, 'expert_accuracy': 82.67693592026622, 'classifier_accuracy': 91.38511969845952, 'alone_classifier': 80.712890625, 'validation_loss': 0.38247952423989773, 'n_experts': 1, 'expert_0': 82.67693592026622}\n","Epoch: [21][0/48]\tTime 0.579 (0.579)\tLoss 0.4335 (0.4335)\tPrec@1 82.422 (82.422)\n","Epoch: [21][10/48]\tTime 0.565 (0.589)\tLoss 0.4620 (0.3931)\tPrec@1 83.594 (85.334)\n","Epoch: [21][20/48]\tTime 0.568 (0.606)\tLoss 0.3342 (0.3808)\tPrec@1 87.500 (85.305)\n","Epoch: [21][30/48]\tTime 0.564 (0.600)\tLoss 0.3549 (0.3872)\tPrec@1 83.984 (85.219)\n","Epoch: [21][40/48]\tTime 0.843 (0.658)\tLoss 0.4596 (0.3912)\tPrec@1 83.594 (85.013)\n","{'coverage': '2981 out of4096', 'system_accuracy': 85.546875, 'expert_accuracy': 81.52464905387461, 'classifier_accuracy': 87.05132213849976, 'alone_classifier': 80.322265625, 'validation_loss': 0.36787700466811657, 'n_experts': 1, 'expert_0': 81.52464905387461}\n","Saving the model with classifier accuracy 87.05132213849976\n","Epoch: [22][0/48]\tTime 0.576 (0.576)\tLoss 0.4188 (0.4188)\tPrec@1 85.547 (85.547)\n","Epoch: [22][10/48]\tTime 0.693 (0.625)\tLoss 0.3330 (0.4051)\tPrec@1 87.109 (84.411)\n","Epoch: [22][20/48]\tTime 0.682 (0.651)\tLoss 0.3972 (0.4083)\tPrec@1 84.766 (84.301)\n","Epoch: [22][30/48]\tTime 0.703 (0.627)\tLoss 0.4460 (0.4012)\tPrec@1 83.984 (84.627)\n","Epoch: [22][40/48]\tTime 0.651 (0.616)\tLoss 0.3084 (0.4036)\tPrec@1 86.719 (85.071)\n","{'coverage': '2868 out of4096', 'system_accuracy': 85.107421875, 'expert_accuracy': 81.4332114929623, 'classifier_accuracy': 86.68061064572487, 'alone_classifier': 80.0048828125, 'validation_loss': 0.3631727211177349, 'n_experts': 1, 'expert_0': 81.4332114929623}\n","Saving the model with classifier accuracy 86.68061064572487\n","Epoch: [23][0/48]\tTime 0.716 (0.716)\tLoss 0.3257 (0.3257)\tPrec@1 87.891 (87.891)\n","Epoch: [23][10/48]\tTime 0.562 (0.724)\tLoss 0.3862 (0.3727)\tPrec@1 88.281 (86.612)\n","Epoch: [23][20/48]\tTime 0.566 (0.658)\tLoss 0.4021 (0.3763)\tPrec@1 86.328 (86.012)\n","Epoch: [23][30/48]\tTime 0.570 (0.647)\tLoss 0.4681 (0.3863)\tPrec@1 82.031 (85.547)\n","Epoch: [23][40/48]\tTime 0.560 (0.646)\tLoss 0.3989 (0.3864)\tPrec@1 85.156 (85.604)\n","{'coverage': '2417 out of4096', 'system_accuracy': 85.009765625, 'expert_accuracy': 80.94102668957395, 'classifier_accuracy': 87.83615689548378, 'alone_classifier': 79.5654296875, 'validation_loss': 0.3839848656207323, 'n_experts': 1, 'expert_0': 80.94102668957395}\n","Epoch: [24][0/48]\tTime 0.561 (0.561)\tLoss 0.2919 (0.2919)\tPrec@1 90.234 (90.234)\n","Epoch: [24][10/48]\tTime 0.693 (0.669)\tLoss 0.3181 (0.3709)\tPrec@1 87.109 (85.866)\n","Epoch: [24][20/48]\tTime 0.692 (0.636)\tLoss 0.4130 (0.3751)\tPrec@1 83.594 (85.454)\n","Epoch: [24][30/48]\tTime 0.704 (0.635)\tLoss 0.3644 (0.3756)\tPrec@1 86.328 (85.774)\n","Epoch: [24][40/48]\tTime 0.564 (0.639)\tLoss 0.3903 (0.3806)\tPrec@1 83.594 (85.604)\n","{'coverage': '3120 out of4096', 'system_accuracy': 85.4248046875, 'expert_accuracy': 82.27457330439071, 'classifier_accuracy': 86.410253640697, 'alone_classifier': 79.931640625, 'validation_loss': 0.36308999732136726, 'n_experts': 1, 'expert_0': 82.27457330439071}\n","Saving the model with classifier accuracy 86.410253640697\n","Epoch: [25][0/48]\tTime 0.600 (0.600)\tLoss 0.3700 (0.3700)\tPrec@1 85.547 (85.547)\n","Epoch: [25][10/48]\tTime 0.563 (0.672)\tLoss 0.3499 (0.3667)\tPrec@1 87.500 (85.902)\n","Epoch: [25][20/48]\tTime 0.578 (0.679)\tLoss 0.4230 (0.3766)\tPrec@1 83.203 (85.565)\n","Epoch: [25][30/48]\tTime 0.689 (0.667)\tLoss 0.4661 (0.3858)\tPrec@1 81.250 (84.967)\n","Epoch: [25][40/48]\tTime 0.556 (0.657)\tLoss 0.3841 (0.3879)\tPrec@1 83.203 (85.204)\n","{'coverage': '2960 out of4096', 'system_accuracy': 84.8876953125, 'expert_accuracy': 79.84153523916633, 'classifier_accuracy': 86.82432139107021, 'alone_classifier': 79.5654296875, 'validation_loss': 0.3846211899071932, 'n_experts': 1, 'expert_0': 79.84153523916633}\n","Epoch: [26][0/48]\tTime 0.570 (0.570)\tLoss 0.4977 (0.4977)\tPrec@1 84.375 (84.375)\n","Epoch: [26][10/48]\tTime 0.563 (0.601)\tLoss 0.3062 (0.3751)\tPrec@1 88.281 (85.795)\n","Epoch: [26][20/48]\tTime 0.565 (0.582)\tLoss 0.3981 (0.3819)\tPrec@1 87.891 (85.844)\n","Epoch: [26][30/48]\tTime 0.706 (0.601)\tLoss 0.4006 (0.3901)\tPrec@1 82.812 (85.232)\n","Epoch: [26][40/48]\tTime 0.696 (0.606)\tLoss 0.3776 (0.3915)\tPrec@1 85.547 (85.232)\n","{'coverage': '1546 out of4096', 'system_accuracy': 84.8388671875, 'expert_accuracy': 81.88234651903164, 'classifier_accuracy': 89.7153887635583, 'alone_classifier': 80.0537109375, 'validation_loss': 0.3801624197512865, 'n_experts': 1, 'expert_0': 81.88234651903164}\n","Epoch: [27][0/48]\tTime 0.685 (0.685)\tLoss 0.3814 (0.3814)\tPrec@1 86.328 (86.328)\n","Epoch: [27][10/48]\tTime 0.671 (0.625)\tLoss 0.4651 (0.4028)\tPrec@1 83.203 (84.943)\n","Epoch: [27][20/48]\tTime 0.649 (0.624)\tLoss 0.4182 (0.3886)\tPrec@1 85.156 (85.714)\n","Epoch: [27][30/48]\tTime 0.560 (0.610)\tLoss 0.3961 (0.3894)\tPrec@1 84.766 (85.585)\n","Epoch: [27][40/48]\tTime 0.556 (0.613)\tLoss 0.4203 (0.3901)\tPrec@1 83.203 (85.480)\n","{'coverage': '2154 out of4096', 'system_accuracy': 85.791015625, 'expert_accuracy': 81.92584120228206, 'classifier_accuracy': 89.27576187206304, 'alone_classifier': 79.833984375, 'validation_loss': 0.37281994707882404, 'n_experts': 1, 'expert_0': 81.92584120228206}\n","Epoch: [28][0/48]\tTime 0.697 (0.697)\tLoss 0.4303 (0.4303)\tPrec@1 83.203 (83.203)\n","Epoch: [28][10/48]\tTime 0.657 (0.646)\tLoss 0.4074 (0.4023)\tPrec@1 83.984 (84.766)\n","Epoch: [28][20/48]\tTime 0.544 (0.611)\tLoss 0.3738 (0.3988)\tPrec@1 85.547 (84.654)\n","Epoch: [28][30/48]\tTime 0.673 (0.610)\tLoss 0.4204 (0.3963)\tPrec@1 81.641 (84.627)\n","Epoch: [28][40/48]\tTime 0.558 (0.602)\tLoss 0.3734 (0.3913)\tPrec@1 87.109 (84.918)\n","{'coverage': '2840 out of4096', 'system_accuracy': 85.498046875, 'expert_accuracy': 80.73247122094408, 'classifier_accuracy': 87.60563071811158, 'alone_classifier': 80.17578125, 'validation_loss': 0.36612972617149353, 'n_experts': 1, 'expert_0': 80.73247122094408}\n","Epoch: [29][0/48]\tTime 0.561 (0.561)\tLoss 0.3318 (0.3318)\tPrec@1 89.844 (89.844)\n","Epoch: [29][10/48]\tTime 0.676 (0.579)\tLoss 0.3795 (0.3965)\tPrec@1 87.109 (85.085)\n","Epoch: [29][20/48]\tTime 0.681 (0.607)\tLoss 0.3886 (0.3951)\tPrec@1 83.984 (84.710)\n","Epoch: [29][30/48]\tTime 0.680 (0.609)\tLoss 0.3200 (0.3934)\tPrec@1 89.062 (85.106)\n","Epoch: [29][40/48]\tTime 0.544 (0.606)\tLoss 0.2701 (0.3826)\tPrec@1 87.500 (85.375)\n","{'coverage': '3521 out of4096', 'system_accuracy': 83.6669921875, 'expert_accuracy': 81.21736305483024, 'classifier_accuracy': 84.06702402536142, 'alone_classifier': 80.1025390625, 'validation_loss': 0.371654637157917, 'n_experts': 1, 'expert_0': 81.21736305483024}\n","Epoch: [30][0/48]\tTime 0.678 (0.678)\tLoss 0.4435 (0.4435)\tPrec@1 83.594 (83.594)\n","Epoch: [30][10/48]\tTime 0.552 (0.621)\tLoss 0.3749 (0.3939)\tPrec@1 84.766 (85.405)\n","Epoch: [30][20/48]\tTime 0.545 (0.587)\tLoss 0.4358 (0.3857)\tPrec@1 85.547 (85.603)\n","Epoch: [30][30/48]\tTime 0.548 (0.582)\tLoss 0.4078 (0.3870)\tPrec@1 85.156 (85.635)\n","Epoch: [30][40/48]\tTime 0.542 (0.590)\tLoss 0.3928 (0.3853)\tPrec@1 87.500 (85.509)\n","{'coverage': '2944 out of4096', 'system_accuracy': 85.546875, 'expert_accuracy': 80.90276373215907, 'classifier_accuracy': 87.3641274672511, 'alone_classifier': 80.9326171875, 'validation_loss': 0.3684716112911701, 'n_experts': 1, 'expert_0': 80.90276373215907}\n","Epoch: [31][0/48]\tTime 0.621 (0.621)\tLoss 0.4244 (0.4244)\tPrec@1 85.938 (85.938)\n","Epoch: [31][10/48]\tTime 0.697 (0.607)\tLoss 0.3618 (0.3998)\tPrec@1 87.891 (85.440)\n","Epoch: [31][20/48]\tTime 0.689 (0.602)\tLoss 0.4130 (0.3901)\tPrec@1 82.812 (85.621)\n","Epoch: [31][30/48]\tTime 0.547 (0.599)\tLoss 0.3102 (0.3900)\tPrec@1 83.594 (85.723)\n","Epoch: [31][40/48]\tTime 0.719 (0.597)\tLoss 0.3826 (0.3862)\tPrec@1 85.547 (85.537)\n","{'coverage': '2064 out of4096', 'system_accuracy': 85.7666015625, 'expert_accuracy': 81.98818090667511, 'classifier_accuracy': 89.48642977294429, 'alone_classifier': 80.810546875, 'validation_loss': 0.37087039090692997, 'n_experts': 1, 'expert_0': 81.98818090667511}\n","Epoch: [32][0/48]\tTime 0.692 (0.692)\tLoss 0.3399 (0.3399)\tPrec@1 86.328 (86.328)\n","Epoch: [32][10/48]\tTime 0.696 (0.624)\tLoss 0.3421 (0.3747)\tPrec@1 85.156 (85.085)\n","Epoch: [32][20/48]\tTime 0.694 (0.643)\tLoss 0.4256 (0.3880)\tPrec@1 84.766 (85.268)\n","Epoch: [32][30/48]\tTime 0.567 (0.626)\tLoss 0.4252 (0.3870)\tPrec@1 84.375 (85.459)\n","Epoch: [32][40/48]\tTime 0.563 (0.624)\tLoss 0.3573 (0.3817)\tPrec@1 86.719 (85.604)\n","{'coverage': '3541 out of4096', 'system_accuracy': 83.544921875, 'expert_accuracy': 77.83780978817666, 'classifier_accuracy': 84.43942150693528, 'alone_classifier': 80.419921875, 'validation_loss': 0.37466965429484844, 'n_experts': 1, 'expert_0': 77.83780978817666}\n","Epoch: [33][0/48]\tTime 0.555 (0.555)\tLoss 0.2884 (0.2884)\tPrec@1 91.797 (91.797)\n","Epoch: [33][10/48]\tTime 0.555 (0.593)\tLoss 0.3586 (0.3695)\tPrec@1 84.766 (86.435)\n","Epoch: [33][20/48]\tTime 0.546 (0.575)\tLoss 0.3649 (0.3881)\tPrec@1 87.891 (85.603)\n","Epoch: [33][30/48]\tTime 0.666 (0.580)\tLoss 0.3799 (0.3792)\tPrec@1 86.328 (85.849)\n","Epoch: [33][40/48]\tTime 0.552 (0.598)\tLoss 0.4602 (0.3843)\tPrec@1 80.469 (85.461)\n","{'coverage': '4014 out of4096', 'system_accuracy': 80.5908203125, 'expert_accuracy': 80.48760856680836, 'classifier_accuracy': 80.59292275553257, 'alone_classifier': 80.0048828125, 'validation_loss': 0.37412705086171627, 'n_experts': 1, 'expert_0': 80.48760856680836}\n","Epoch: [34][0/48]\tTime 0.578 (0.578)\tLoss 0.4822 (0.4822)\tPrec@1 82.422 (82.422)\n","Epoch: [34][10/48]\tTime 0.604 (0.623)\tLoss 0.3776 (0.4193)\tPrec@1 85.938 (83.558)\n","Epoch: [34][20/48]\tTime 0.556 (0.600)\tLoss 0.3402 (0.4112)\tPrec@1 85.547 (84.245)\n","Epoch: [34][30/48]\tTime 0.565 (0.602)\tLoss 0.4309 (0.4027)\tPrec@1 80.469 (84.451)\n","Epoch: [34][40/48]\tTime 0.561 (0.602)\tLoss 0.3777 (0.3931)\tPrec@1 85.938 (84.880)\n","{'coverage': '3038 out of4096', 'system_accuracy': 85.05859375, 'expert_accuracy': 80.90735710635973, 'classifier_accuracy': 86.50427628359854, 'alone_classifier': 80.46875, 'validation_loss': 0.371518038213253, 'n_experts': 1, 'expert_0': 80.90735710635973}\n","Epoch: [35][0/48]\tTime 0.698 (0.698)\tLoss 0.3653 (0.3653)\tPrec@1 85.156 (85.156)\n","Epoch: [35][10/48]\tTime 0.553 (0.651)\tLoss 0.3837 (0.3915)\tPrec@1 85.156 (85.192)\n","Epoch: [35][20/48]\tTime 0.559 (0.617)\tLoss 0.3945 (0.3913)\tPrec@1 86.719 (85.045)\n","Epoch: [35][30/48]\tTime 0.930 (0.642)\tLoss 0.4258 (0.3874)\tPrec@1 84.766 (85.232)\n","Epoch: [35][40/48]\tTime 0.691 (0.678)\tLoss 0.4541 (0.3880)\tPrec@1 84.766 (85.204)\n","{'coverage': '3473 out of4096', 'system_accuracy': 84.130859375, 'expert_accuracy': 81.21987761801682, 'classifier_accuracy': 84.65303528208939, 'alone_classifier': 79.98046875, 'validation_loss': 0.37021481432020664, 'n_experts': 1, 'expert_0': 81.21987761801682}\n","Epoch: [36][0/48]\tTime 0.684 (0.684)\tLoss 0.4498 (0.4498)\tPrec@1 82.812 (82.812)\n","Epoch: [36][10/48]\tTime 0.665 (0.669)\tLoss 0.4375 (0.3864)\tPrec@1 83.594 (85.902)\n","Epoch: [36][20/48]\tTime 0.620 (0.649)\tLoss 0.3442 (0.3899)\tPrec@1 90.625 (85.733)\n","Epoch: [36][30/48]\tTime 0.558 (0.638)\tLoss 0.3907 (0.3854)\tPrec@1 84.375 (85.383)\n","Epoch: [36][40/48]\tTime 0.688 (0.625)\tLoss 0.3685 (0.3796)\tPrec@1 85.938 (85.842)\n","{'coverage': '1991 out of4096', 'system_accuracy': 85.5224609375, 'expert_accuracy': 81.94773568192535, 'classifier_accuracy': 89.30185387735541, 'alone_classifier': 80.859375, 'validation_loss': 0.3722016680985689, 'n_experts': 1, 'expert_0': 81.94773568192535}\n","Epoch: [37][0/48]\tTime 0.687 (0.687)\tLoss 0.4116 (0.4116)\tPrec@1 81.641 (81.641)\n","Epoch: [37][10/48]\tTime 0.692 (0.692)\tLoss 0.3861 (0.4071)\tPrec@1 84.766 (84.588)\n","Epoch: [37][20/48]\tTime 0.558 (0.665)\tLoss 0.4183 (0.3960)\tPrec@1 82.422 (85.063)\n","Epoch: [37][30/48]\tTime 0.703 (0.669)\tLoss 0.4276 (0.3888)\tPrec@1 83.984 (85.169)\n","Epoch: [37][40/48]\tTime 0.556 (0.654)\tLoss 0.4672 (0.3890)\tPrec@1 83.984 (85.337)\n","{'coverage': '3313 out of4096', 'system_accuracy': 84.7412109375, 'expert_accuracy': 80.45974956328236, 'classifier_accuracy': 85.75309128424112, 'alone_classifier': 80.126953125, 'validation_loss': 0.36699990928173065, 'n_experts': 1, 'expert_0': 80.45974956328236}\n","Epoch: [38][0/48]\tTime 0.608 (0.608)\tLoss 0.3319 (0.3319)\tPrec@1 87.109 (87.109)\n","Epoch: [38][10/48]\tTime 0.656 (0.612)\tLoss 0.3842 (0.3675)\tPrec@1 85.938 (85.511)\n","Epoch: [38][20/48]\tTime 0.675 (0.605)\tLoss 0.3154 (0.3739)\tPrec@1 87.891 (85.510)\n","Epoch: [38][30/48]\tTime 0.636 (0.615)\tLoss 0.3733 (0.3760)\tPrec@1 85.938 (85.585)\n","Epoch: [38][40/48]\tTime 0.557 (0.615)\tLoss 0.3062 (0.3707)\tPrec@1 90.625 (86.071)\n","{'coverage': '3373 out of4096', 'system_accuracy': 84.7412109375, 'expert_accuracy': 80.77452813982624, 'classifier_accuracy': 85.59145906933118, 'alone_classifier': 80.6884765625, 'validation_loss': 0.3695682920515537, 'n_experts': 1, 'expert_0': 80.77452813982624}\n","Epoch: [39][0/48]\tTime 0.571 (0.571)\tLoss 0.4230 (0.4230)\tPrec@1 83.984 (83.984)\n","Epoch: [39][10/48]\tTime 0.586 (0.577)\tLoss 0.4253 (0.4023)\tPrec@1 81.641 (85.298)\n","Epoch: [39][20/48]\tTime 0.685 (0.608)\tLoss 0.3615 (0.4030)\tPrec@1 83.984 (84.673)\n","Epoch: [39][30/48]\tTime 0.553 (0.607)\tLoss 0.3768 (0.3958)\tPrec@1 85.156 (85.005)\n","Epoch: [39][40/48]\tTime 0.677 (0.597)\tLoss 0.3487 (0.3855)\tPrec@1 87.891 (85.413)\n","{'coverage': '2905 out of4096', 'system_accuracy': 85.7177734375, 'expert_accuracy': 81.36018784883495, 'classifier_accuracy': 87.50429991379346, 'alone_classifier': 79.931640625, 'validation_loss': 0.36399405263364315, 'n_experts': 1, 'expert_0': 81.36018784883495}\n","Epoch: [40][0/48]\tTime 0.577 (0.577)\tLoss 0.3704 (0.3704)\tPrec@1 85.938 (85.938)\n","Epoch: [40][10/48]\tTime 0.686 (0.653)\tLoss 0.3745 (0.3874)\tPrec@1 87.109 (85.405)\n","Epoch: [40][20/48]\tTime 0.698 (0.636)\tLoss 0.4049 (0.3795)\tPrec@1 85.156 (86.086)\n","Epoch: [40][30/48]\tTime 0.555 (0.635)\tLoss 0.4055 (0.3758)\tPrec@1 85.156 (86.164)\n","Epoch: [40][40/48]\tTime 0.686 (0.633)\tLoss 0.4268 (0.3770)\tPrec@1 81.250 (85.938)\n","{'coverage': '3114 out of4096', 'system_accuracy': 85.009765625, 'expert_accuracy': 80.44804878858477, 'classifier_accuracy': 86.44829523287426, 'alone_classifier': 80.517578125, 'validation_loss': 0.37567942403256893, 'n_experts': 1, 'expert_0': 80.44804878858477}\n","Epoch: [41][0/48]\tTime 0.692 (0.692)\tLoss 0.3635 (0.3635)\tPrec@1 85.547 (85.547)\n","Epoch: [41][10/48]\tTime 0.567 (0.613)\tLoss 0.3765 (0.3801)\tPrec@1 87.500 (86.115)\n","Epoch: [41][20/48]\tTime 0.556 (0.615)\tLoss 0.3858 (0.3776)\tPrec@1 85.547 (85.565)\n","Epoch: [41][30/48]\tTime 0.602 (0.609)\tLoss 0.3811 (0.3848)\tPrec@1 87.109 (85.509)\n","Epoch: [41][40/48]\tTime 0.548 (0.601)\tLoss 0.4624 (0.3772)\tPrec@1 85.156 (85.614)\n","{'coverage': '2994 out of4096', 'system_accuracy': 85.9619140625, 'expert_accuracy': 82.75860566994453, 'classifier_accuracy': 87.14094565327503, 'alone_classifier': 79.931640625, 'validation_loss': 0.36332936957478523, 'n_experts': 1, 'expert_0': 82.75860566994453}\n","Epoch: [42][0/48]\tTime 0.687 (0.687)\tLoss 0.3972 (0.3972)\tPrec@1 85.156 (85.156)\n","Epoch: [42][10/48]\tTime 0.650 (0.619)\tLoss 0.4045 (0.3677)\tPrec@1 84.766 (86.577)\n","Epoch: [42][20/48]\tTime 0.560 (0.611)\tLoss 0.3563 (0.3792)\tPrec@1 86.328 (86.068)\n","Epoch: [42][30/48]\tTime 0.614 (0.610)\tLoss 0.3318 (0.3743)\tPrec@1 85.938 (85.963)\n","Epoch: [42][40/48]\tTime 0.582 (0.616)\tLoss 0.3806 (0.3737)\tPrec@1 86.719 (85.899)\n","{'coverage': '3089 out of4096', 'system_accuracy': 85.7421875, 'expert_accuracy': 82.52232720509888, 'classifier_accuracy': 86.79183921036454, 'alone_classifier': 80.9326171875, 'validation_loss': 0.36840929836034775, 'n_experts': 1, 'expert_0': 82.52232720509888}\n","Epoch: [43][0/48]\tTime 0.584 (0.584)\tLoss 0.3488 (0.3488)\tPrec@1 88.281 (88.281)\n","Epoch: [43][10/48]\tTime 0.542 (0.639)\tLoss 0.3375 (0.3612)\tPrec@1 90.625 (86.754)\n","Epoch: [43][20/48]\tTime 0.673 (0.628)\tLoss 0.5202 (0.3766)\tPrec@1 82.031 (86.049)\n","Epoch: [43][30/48]\tTime 0.678 (0.636)\tLoss 0.4367 (0.3786)\tPrec@1 85.156 (85.988)\n","Epoch: [43][40/48]\tTime 0.664 (0.624)\tLoss 0.4540 (0.3809)\tPrec@1 82.812 (85.833)\n","{'coverage': '3314 out of4096', 'system_accuracy': 84.5947265625, 'expert_accuracy': 80.05113042170578, 'classifier_accuracy': 85.66686524843496, 'alone_classifier': 80.908203125, 'validation_loss': 0.3635915666818619, 'n_experts': 1, 'expert_0': 80.05113042170578}\n","Epoch: [44][0/48]\tTime 0.635 (0.635)\tLoss 0.4065 (0.4065)\tPrec@1 84.375 (84.375)\n","Epoch: [44][10/48]\tTime 0.704 (0.649)\tLoss 0.4976 (0.3843)\tPrec@1 82.031 (85.582)\n","Epoch: [44][20/48]\tTime 0.605 (0.615)\tLoss 0.3848 (0.3781)\tPrec@1 86.328 (85.900)\n","Epoch: [44][30/48]\tTime 0.688 (0.631)\tLoss 0.3484 (0.3779)\tPrec@1 83.594 (85.610)\n","Epoch: [44][40/48]\tTime 0.704 (0.635)\tLoss 0.4685 (0.3798)\tPrec@1 84.766 (85.737)\n","{'coverage': '2544 out of4096', 'system_accuracy': 85.302734375, 'expert_accuracy': 80.798958659928, 'classifier_accuracy': 88.05031100431167, 'alone_classifier': 80.7373046875, 'validation_loss': 0.3793775774538517, 'n_experts': 1, 'expert_0': 80.798958659928}\n","Early Exiting Training.\n","Number of Experts: n is 2\n","selected experts <models.experts.synth_expert object at 0x7f4e7913ea90>\n","selected experts fn. FlipHuman\n","2\n","dict_keys(['X', 'Y', 'c', 'hpred', 'hloss', 'hprob'])\n","dict_keys(['X', 'Y', 'c', 'hpred', 'hloss', 'hprob'])\n","Epoch: [0][0/48]\tTime 0.781 (0.781)\tLoss 1.0004 (1.0004)\tPrec@1 48.438 (48.438)\n","Epoch: [0][10/48]\tTime 0.571 (0.673)\tLoss 0.7514 (0.6033)\tPrec@1 82.031 (79.332)\n","Epoch: [0][20/48]\tTime 0.563 (0.656)\tLoss 0.5330 (0.6034)\tPrec@1 81.250 (80.246)\n","Epoch: [0][30/48]\tTime 0.598 (0.638)\tLoss 0.5532 (0.5828)\tPrec@1 82.422 (80.658)\n","Epoch: [0][40/48]\tTime 0.724 (0.639)\tLoss 0.4879 (0.5675)\tPrec@1 83.203 (80.945)\n","{'coverage': '3869 out of4096', 'system_accuracy': 79.2236328125, 'expert_accuracy': 82.81931029135657, 'classifier_accuracy': 79.01266272906015, 'alone_classifier': 77.34375, 'validation_loss': 0.4211075510829687, 'n_experts': 2, 'expert_0': 82.81931029135657, 'expert_1': 0.0}\n","Saving the model with classifier accuracy 79.01266272906015\n","Epoch: [1][0/48]\tTime 0.574 (0.574)\tLoss 0.5442 (0.5442)\tPrec@1 78.906 (78.906)\n","Epoch: [1][10/48]\tTime 0.686 (0.633)\tLoss 0.4607 (0.4878)\tPrec@1 80.469 (81.889)\n","Epoch: [1][20/48]\tTime 0.606 (0.640)\tLoss 0.5228 (0.4909)\tPrec@1 81.250 (81.641)\n","Epoch: [1][30/48]\tTime 0.552 (0.641)\tLoss 0.4579 (0.4929)\tPrec@1 85.938 (81.741)\n","Epoch: [1][40/48]\tTime 0.695 (0.633)\tLoss 0.3142 (0.4769)\tPrec@1 86.719 (82.165)\n","{'coverage': '718 out of4096', 'system_accuracy': 84.619140625, 'expert_accuracy': 83.39253502708496, 'classifier_accuracy': 90.38995955571595, 'alone_classifier': 77.34375, 'validation_loss': 0.41263567842543125, 'n_experts': 2, 'expert_0': 83.39253502708496, 'expert_1': 0.0}\n","Saving the model with classifier accuracy 90.38995955571595\n","Epoch: [2][0/48]\tTime 0.567 (0.567)\tLoss 0.3446 (0.3446)\tPrec@1 87.500 (87.500)\n","Epoch: [2][10/48]\tTime 0.581 (0.606)\tLoss 0.4335 (0.4330)\tPrec@1 82.031 (83.487)\n","Epoch: [2][20/48]\tTime 0.647 (0.634)\tLoss 0.4899 (0.4390)\tPrec@1 77.734 (83.445)\n","Epoch: [2][30/48]\tTime 0.608 (0.635)\tLoss 0.4582 (0.4414)\tPrec@1 81.641 (83.291)\n","Epoch: [2][40/48]\tTime 0.564 (0.624)\tLoss 0.4785 (0.4514)\tPrec@1 81.250 (82.812)\n","{'coverage': '2006 out of4096', 'system_accuracy': 84.5703125, 'expert_accuracy': 81.57893956182397, 'classifier_accuracy': 87.6869348112196, 'alone_classifier': 78.564453125, 'validation_loss': 0.4107994753867388, 'n_experts': 2, 'expert_0': 81.57893956182397, 'expert_1': 0.0}\n","Saving the model with classifier accuracy 87.6869348112196\n","Epoch: [3][0/48]\tTime 0.636 (0.636)\tLoss 0.4308 (0.4308)\tPrec@1 84.766 (84.766)\n","Epoch: [3][10/48]\tTime 0.684 (0.671)\tLoss 0.4459 (0.4481)\tPrec@1 82.031 (83.700)\n","Epoch: [3][20/48]\tTime 0.564 (0.631)\tLoss 0.5047 (0.4407)\tPrec@1 83.203 (83.501)\n","Epoch: [3][30/48]\tTime 0.562 (0.622)\tLoss 0.5091 (0.4333)\tPrec@1 80.078 (83.606)\n","Epoch: [3][40/48]\tTime 0.583 (0.621)\tLoss 0.5086 (0.4366)\tPrec@1 82.031 (83.565)\n","{'coverage': '270 out of4096', 'system_accuracy': 83.59375, 'expert_accuracy': 83.08938405178337, 'classifier_accuracy': 90.74070713307144, 'alone_classifier': 77.9052734375, 'validation_loss': 0.4180113337934017, 'n_experts': 2, 'expert_0': 83.08938405178337, 'expert_1': 0.0}\n","Epoch: [4][0/48]\tTime 0.580 (0.580)\tLoss 0.5371 (0.5371)\tPrec@1 78.516 (78.516)\n","Epoch: [4][10/48]\tTime 0.557 (0.585)\tLoss 0.3839 (0.4158)\tPrec@1 87.500 (84.411)\n","Epoch: [4][20/48]\tTime 0.681 (0.613)\tLoss 0.4474 (0.4086)\tPrec@1 85.938 (84.487)\n","Epoch: [4][30/48]\tTime 0.687 (0.601)\tLoss 0.4676 (0.4161)\tPrec@1 80.078 (84.173)\n","Epoch: [4][40/48]\tTime 0.684 (0.617)\tLoss 0.3825 (0.4198)\tPrec@1 83.203 (84.127)\n","{'coverage': '1660 out of4096', 'system_accuracy': 84.423828125, 'expert_accuracy': 82.2249521982798, 'classifier_accuracy': 87.65059712948211, 'alone_classifier': 78.0029296875, 'validation_loss': 0.40358604304492474, 'n_experts': 2, 'expert_0': 82.2249521982798, 'expert_1': 0.0}\n","Saving the model with classifier accuracy 87.65059712948211\n","Epoch: [5][0/48]\tTime 0.572 (0.572)\tLoss 0.3493 (0.3493)\tPrec@1 85.156 (85.156)\n","Epoch: [5][10/48]\tTime 0.562 (0.566)\tLoss 0.3899 (0.4246)\tPrec@1 83.594 (84.339)\n","Epoch: [5][20/48]\tTime 0.588 (0.574)\tLoss 0.3941 (0.4187)\tPrec@1 84.375 (84.580)\n","Epoch: [5][30/48]\tTime 0.574 (0.583)\tLoss 0.4825 (0.4166)\tPrec@1 84.375 (84.299)\n","Epoch: [5][40/48]\tTime 0.561 (0.581)\tLoss 0.4399 (0.4152)\tPrec@1 86.719 (84.327)\n","{'coverage': '386 out of4096', 'system_accuracy': 83.544921875, 'expert_accuracy': 82.80323003756172, 'classifier_accuracy': 90.67355163897626, 'alone_classifier': 79.0283203125, 'validation_loss': 0.4027061592787504, 'n_experts': 2, 'expert_0': 82.80323003756172, 'expert_1': 0.0}\n","Saving the model with classifier accuracy 90.67355163897626\n","Epoch: [6][0/48]\tTime 0.643 (0.643)\tLoss 0.4493 (0.4493)\tPrec@1 85.156 (85.156)\n","Epoch: [6][10/48]\tTime 0.628 (0.609)\tLoss 0.4918 (0.4563)\tPrec@1 81.250 (83.381)\n","Epoch: [6][20/48]\tTime 0.632 (0.616)\tLoss 0.4301 (0.4268)\tPrec@1 82.031 (83.631)\n","Epoch: [6][30/48]\tTime 0.688 (0.629)\tLoss 0.4755 (0.4300)\tPrec@1 81.641 (83.606)\n","Epoch: [6][40/48]\tTime 0.562 (0.633)\tLoss 0.3740 (0.4233)\tPrec@1 86.719 (83.841)\n","{'coverage': '4059 out of4096', 'system_accuracy': 78.173828125, 'expert_accuracy': 91.89139518164767, 'classifier_accuracy': 78.04877856494755, 'alone_classifier': 77.8564453125, 'validation_loss': 0.3877422120422125, 'n_experts': 2, 'expert_0': 91.89139518164767, 'expert_1': 0.0}\n","Saving the model with classifier accuracy 78.04877856494755\n","Epoch: [7][0/48]\tTime 0.692 (0.692)\tLoss 0.4796 (0.4796)\tPrec@1 83.984 (83.984)\n","Epoch: [7][10/48]\tTime 0.593 (0.681)\tLoss 0.4034 (0.4043)\tPrec@1 83.984 (84.517)\n","Epoch: [7][20/48]\tTime 0.721 (0.660)\tLoss 0.4267 (0.3986)\tPrec@1 82.812 (85.138)\n","Epoch: [7][30/48]\tTime 0.695 (0.649)\tLoss 0.4168 (0.4062)\tPrec@1 85.156 (84.791)\n","Epoch: [7][40/48]\tTime 0.643 (0.654)\tLoss 0.3824 (0.4078)\tPrec@1 83.984 (84.508)\n","{'coverage': '3090 out of4096', 'system_accuracy': 85.5224609375, 'expert_accuracy': 82.50495377635114, 'classifier_accuracy': 86.50485156942227, 'alone_classifier': 79.9072265625, 'validation_loss': 0.37462238036096096, 'n_experts': 2, 'expert_0': 82.50495377635114, 'expert_1': 0.0}\n","Saving the model with classifier accuracy 86.50485156942227\n","Epoch: [8][0/48]\tTime 0.564 (0.564)\tLoss 0.4071 (0.4071)\tPrec@1 83.984 (83.984)\n","Epoch: [8][10/48]\tTime 0.603 (0.624)\tLoss 0.3895 (0.4193)\tPrec@1 85.547 (82.990)\n","Epoch: [8][20/48]\tTime 0.648 (0.619)\tLoss 0.4067 (0.4046)\tPrec@1 84.375 (83.910)\n","Epoch: [8][30/48]\tTime 0.688 (0.629)\tLoss 0.5153 (0.4009)\tPrec@1 81.641 (84.375)\n","Epoch: [8][40/48]\tTime 0.627 (0.637)\tLoss 0.4827 (0.4046)\tPrec@1 83.984 (84.375)\n","{'coverage': '2134 out of4096', 'system_accuracy': 85.83984375, 'expert_accuracy': 82.56879892265047, 'classifier_accuracy': 88.84723107557492, 'alone_classifier': 80.1513671875, 'validation_loss': 0.37652306258678436, 'n_experts': 2, 'expert_0': 82.56879892265047, 'expert_1': 0.0}\n","Epoch: [9][0/48]\tTime 0.570 (0.570)\tLoss 0.4076 (0.4076)\tPrec@1 84.375 (84.375)\n","Epoch: [9][10/48]\tTime 0.564 (0.614)\tLoss 0.3693 (0.4079)\tPrec@1 84.766 (84.943)\n","Epoch: [9][20/48]\tTime 0.567 (0.608)\tLoss 0.3924 (0.4077)\tPrec@1 85.547 (84.710)\n","Epoch: [9][30/48]\tTime 0.722 (0.625)\tLoss 0.4021 (0.4058)\tPrec@1 82.812 (84.589)\n","Epoch: [9][40/48]\tTime 0.705 (0.624)\tLoss 0.5112 (0.4049)\tPrec@1 79.297 (84.499)\n","{'coverage': '848 out of4096', 'system_accuracy': 84.5458984375, 'expert_accuracy': 82.69703924279315, 'classifier_accuracy': 91.62734768545428, 'alone_classifier': 78.41796875, 'validation_loss': 0.3883301019668579, 'n_experts': 2, 'expert_0': 82.69703924279315, 'expert_1': 0.0}\n","Epoch: [10][0/48]\tTime 0.574 (0.574)\tLoss 0.4918 (0.4918)\tPrec@1 83.203 (83.203)\n","Epoch: [10][10/48]\tTime 0.681 (0.638)\tLoss 0.3858 (0.3996)\tPrec@1 83.984 (84.055)\n","Epoch: [10][20/48]\tTime 0.686 (0.641)\tLoss 0.5334 (0.4068)\tPrec@1 83.594 (84.226)\n","Epoch: [10][30/48]\tTime 0.573 (0.643)\tLoss 0.4354 (0.4078)\tPrec@1 80.859 (84.199)\n","Epoch: [10][40/48]\tTime 0.569 (0.638)\tLoss 0.3675 (0.4023)\tPrec@1 84.375 (84.537)\n","{'coverage': '2493 out of4096', 'system_accuracy': 85.83984375, 'expert_accuracy': 81.659378457969, 'classifier_accuracy': 88.52787450750603, 'alone_classifier': 79.78515625, 'validation_loss': 0.37768242321908474, 'n_experts': 2, 'expert_0': 81.659378457969, 'expert_1': 0.0}\n","Epoch: [11][0/48]\tTime 0.583 (0.583)\tLoss 0.4525 (0.4525)\tPrec@1 82.422 (82.422)\n","Epoch: [11][10/48]\tTime 0.694 (0.607)\tLoss 0.4440 (0.3686)\tPrec@1 83.203 (85.476)\n","Epoch: [11][20/48]\tTime 0.555 (0.621)\tLoss 0.4751 (0.3831)\tPrec@1 82.422 (85.231)\n","Epoch: [11][30/48]\tTime 0.697 (0.620)\tLoss 0.4105 (0.3900)\tPrec@1 81.641 (84.992)\n","Epoch: [11][40/48]\tTime 0.705 (0.624)\tLoss 0.4017 (0.3946)\tPrec@1 84.375 (84.804)\n","{'coverage': '3002 out of4096', 'system_accuracy': 84.86328125, 'expert_accuracy': 80.3473344886043, 'classifier_accuracy': 86.50899112228544, 'alone_classifier': 79.6142578125, 'validation_loss': 0.3731681890785694, 'n_experts': 2, 'expert_0': 80.3473344886043, 'expert_1': 0.0}\n","Saving the model with classifier accuracy 86.50899112228544\n","Epoch: [12][0/48]\tTime 0.586 (0.586)\tLoss 0.4237 (0.4237)\tPrec@1 82.812 (82.812)\n","Epoch: [12][10/48]\tTime 0.719 (0.681)\tLoss 0.4034 (0.3895)\tPrec@1 86.719 (85.263)\n","Epoch: [12][20/48]\tTime 0.666 (0.671)\tLoss 0.4942 (0.4005)\tPrec@1 82.422 (84.635)\n","Epoch: [12][30/48]\tTime 0.575 (0.659)\tLoss 0.3523 (0.3985)\tPrec@1 86.328 (84.551)\n","Epoch: [12][40/48]\tTime 0.635 (0.647)\tLoss 0.3596 (0.3944)\tPrec@1 85.156 (84.823)\n","{'coverage': '3582 out of4096', 'system_accuracy': 83.3984375, 'expert_accuracy': 81.3229255552819, 'classifier_accuracy': 83.69625673656458, 'alone_classifier': 79.4677734375, 'validation_loss': 0.3795395102351904, 'n_experts': 2, 'expert_0': 81.3229255552819, 'expert_1': 0.0}\n","Epoch: [13][0/48]\tTime 0.708 (0.708)\tLoss 0.4425 (0.4425)\tPrec@1 80.078 (80.078)\n","Epoch: [13][10/48]\tTime 0.562 (0.659)\tLoss 0.4099 (0.3984)\tPrec@1 84.375 (84.553)\n","Epoch: [13][20/48]\tTime 0.696 (0.665)\tLoss 0.4180 (0.3971)\tPrec@1 84.766 (84.673)\n","Epoch: [13][30/48]\tTime 0.586 (0.643)\tLoss 0.4527 (0.4026)\tPrec@1 82.422 (84.614)\n","Epoch: [13][40/48]\tTime 0.562 (0.637)\tLoss 0.4256 (0.3990)\tPrec@1 85.547 (84.870)\n","{'coverage': '908 out of4096', 'system_accuracy': 85.205078125, 'expert_accuracy': 83.62609262069682, 'classifier_accuracy': 90.7488886840431, 'alone_classifier': 79.8828125, 'validation_loss': 0.3713831752538681, 'n_experts': 2, 'expert_0': 83.62609262069682, 'expert_1': 0.0}\n","Saving the model with classifier accuracy 90.7488886840431\n","Epoch: [14][0/48]\tTime 0.581 (0.581)\tLoss 0.3800 (0.3800)\tPrec@1 85.156 (85.156)\n","Epoch: [14][10/48]\tTime 0.691 (0.651)\tLoss 0.4441 (0.4112)\tPrec@1 82.812 (84.091)\n","Epoch: [14][20/48]\tTime 0.663 (0.650)\tLoss 0.4170 (0.4118)\tPrec@1 78.516 (83.854)\n","Epoch: [14][30/48]\tTime 0.566 (0.635)\tLoss 0.3706 (0.4035)\tPrec@1 84.766 (84.236)\n","Epoch: [14][40/48]\tTime 0.565 (0.631)\tLoss 0.3153 (0.4014)\tPrec@1 86.719 (84.537)\n","{'coverage': '4095 out of4096', 'system_accuracy': 78.9306640625, 'expert_accuracy': 0.0, 'classifier_accuracy': 78.94993702197955, 'alone_classifier': 78.955078125, 'validation_loss': 0.3903634026646614, 'n_experts': 2, 'expert_0': 0.0, 'expert_1': 0.0}\n","Epoch: [15][0/48]\tTime 0.687 (0.687)\tLoss 0.4551 (0.4551)\tPrec@1 80.078 (80.078)\n","Epoch: [15][10/48]\tTime 0.686 (0.625)\tLoss 0.3703 (0.4040)\tPrec@1 87.109 (84.553)\n","Epoch: [15][20/48]\tTime 0.680 (0.635)\tLoss 0.4097 (0.4020)\tPrec@1 83.594 (84.412)\n","Epoch: [15][30/48]\tTime 0.634 (0.630)\tLoss 0.3573 (0.3955)\tPrec@1 89.062 (84.551)\n","Epoch: [15][40/48]\tTime 0.700 (0.635)\tLoss 0.4070 (0.3924)\tPrec@1 82.422 (84.832)\n","{'coverage': '3634 out of4096', 'system_accuracy': 82.8369140625, 'expert_accuracy': 79.22074492608445, 'classifier_accuracy': 83.29664052568407, 'alone_classifier': 79.736328125, 'validation_loss': 0.3798925206065178, 'n_experts': 2, 'expert_0': 79.22074492608445, 'expert_1': 0.0}\n","Epoch: [16][0/48]\tTime 0.690 (0.690)\tLoss 0.3679 (0.3679)\tPrec@1 86.719 (86.719)\n","Epoch: [16][10/48]\tTime 0.694 (0.649)\tLoss 0.4493 (0.4008)\tPrec@1 83.594 (84.588)\n","Epoch: [16][20/48]\tTime 0.692 (0.635)\tLoss 0.4564 (0.4043)\tPrec@1 81.250 (84.673)\n","Epoch: [16][30/48]\tTime 0.597 (0.644)\tLoss 0.3877 (0.3950)\tPrec@1 83.594 (84.992)\n","Epoch: [16][40/48]\tTime 0.574 (0.639)\tLoss 0.4433 (0.3953)\tPrec@1 84.375 (84.775)\n","{'coverage': '2148 out of4096', 'system_accuracy': 86.2060546875, 'expert_accuracy': 82.5461927570644, 'classifier_accuracy': 89.52513549696761, 'alone_classifier': 79.0771484375, 'validation_loss': 0.38634259812533855, 'n_experts': 2, 'expert_0': 82.5461927570644, 'expert_1': 0.0}\n","Epoch: [17][0/48]\tTime 0.977 (0.977)\tLoss 0.3328 (0.3328)\tPrec@1 86.719 (86.719)\n","Epoch: [17][10/48]\tTime 0.573 (0.697)\tLoss 0.3028 (0.3997)\tPrec@1 88.281 (83.842)\n","Epoch: [17][20/48]\tTime 0.552 (0.659)\tLoss 0.4065 (0.3914)\tPrec@1 81.250 (84.468)\n","Epoch: [17][30/48]\tTime 0.657 (0.634)\tLoss 0.3116 (0.3975)\tPrec@1 89.453 (84.627)\n","Epoch: [17][40/48]\tTime 0.558 (0.626)\tLoss 0.3036 (0.3929)\tPrec@1 88.672 (84.737)\n","{'coverage': '2280 out of4096', 'system_accuracy': 86.0107421875, 'expert_accuracy': 82.04844911360694, 'classifier_accuracy': 89.16666275584812, 'alone_classifier': 80.4443359375, 'validation_loss': 0.36957644298672676, 'n_experts': 2, 'expert_0': 82.04844911360694, 'expert_1': 0.0}\n","Saving the model with classifier accuracy 89.16666275584812\n","Epoch: [18][0/48]\tTime 0.572 (0.572)\tLoss 0.3820 (0.3820)\tPrec@1 84.375 (84.375)\n","Epoch: [18][10/48]\tTime 0.657 (0.619)\tLoss 0.3253 (0.3871)\tPrec@1 89.844 (85.334)\n","Epoch: [18][20/48]\tTime 0.566 (0.612)\tLoss 0.3686 (0.3799)\tPrec@1 85.156 (85.528)\n","Epoch: [18][30/48]\tTime 0.562 (0.636)\tLoss 0.3830 (0.3883)\tPrec@1 85.938 (85.270)\n","Epoch: [18][40/48]\tTime 0.692 (0.631)\tLoss 0.3787 (0.3933)\tPrec@1 83.984 (84.623)\n","{'coverage': '252 out of4096', 'system_accuracy': 83.59375, 'expert_accuracy': 82.98646810684349, 'classifier_accuracy': 92.85710600908492, 'alone_classifier': 80.4931640625, 'validation_loss': 0.3888853173702955, 'n_experts': 2, 'expert_0': 82.98646810684349, 'expert_1': 0.0}\n","Epoch: [19][0/48]\tTime 0.908 (0.908)\tLoss 0.3647 (0.3647)\tPrec@1 85.547 (85.547)\n","Epoch: [19][10/48]\tTime 0.559 (0.751)\tLoss 0.3383 (0.3703)\tPrec@1 87.500 (85.582)\n","Epoch: [19][20/48]\tTime 0.691 (0.698)\tLoss 0.3520 (0.3753)\tPrec@1 87.500 (85.063)\n","Epoch: [19][30/48]\tTime 0.695 (0.692)\tLoss 0.3624 (0.3838)\tPrec@1 85.547 (84.980)\n","Epoch: [19][40/48]\tTime 0.693 (0.676)\tLoss 0.4215 (0.3855)\tPrec@1 84.375 (84.994)\n","{'coverage': '1780 out of4096', 'system_accuracy': 85.986328125, 'expert_accuracy': 82.5561241315955, 'classifier_accuracy': 90.44943312081837, 'alone_classifier': 79.9072265625, 'validation_loss': 0.3722743783146143, 'n_experts': 2, 'expert_0': 82.5561241315955, 'expert_1': 0.0}\n","Epoch: [20][0/48]\tTime 0.605 (0.605)\tLoss 0.4329 (0.4329)\tPrec@1 83.203 (83.203)\n","Epoch: [20][10/48]\tTime 0.564 (0.641)\tLoss 0.3674 (0.3906)\tPrec@1 85.938 (85.405)\n","Epoch: [20][20/48]\tTime 0.647 (0.651)\tLoss 0.4591 (0.3873)\tPrec@1 83.203 (85.510)\n","Epoch: [20][30/48]\tTime 0.694 (0.656)\tLoss 0.3868 (0.3952)\tPrec@1 86.328 (85.459)\n","Epoch: [20][40/48]\tTime 0.598 (0.639)\tLoss 0.4135 (0.3910)\tPrec@1 85.938 (85.585)\n","{'coverage': '2283 out of4096', 'system_accuracy': 86.328125, 'expert_accuracy': 83.34251700578963, 'classifier_accuracy': 88.69907627248898, 'alone_classifier': 79.8095703125, 'validation_loss': 0.3674592897295952, 'n_experts': 2, 'expert_0': 83.34251700578963, 'expert_1': 0.0}\n","Saving the model with classifier accuracy 88.69907627248898\n","Epoch: [21][0/48]\tTime 0.714 (0.714)\tLoss 0.3387 (0.3387)\tPrec@1 85.938 (85.938)\n","Epoch: [21][10/48]\tTime 0.569 (0.662)\tLoss 0.3222 (0.3977)\tPrec@1 89.062 (85.263)\n","Epoch: [21][20/48]\tTime 0.700 (0.643)\tLoss 0.3239 (0.3755)\tPrec@1 86.328 (85.956)\n","Epoch: [21][30/48]\tTime 0.562 (0.635)\tLoss 0.4254 (0.3919)\tPrec@1 85.938 (85.496)\n","Epoch: [21][40/48]\tTime 0.581 (0.634)\tLoss 0.3630 (0.3948)\tPrec@1 85.938 (85.261)\n","{'coverage': '3382 out of4096', 'system_accuracy': 84.375, 'expert_accuracy': 79.83191041122959, 'classifier_accuracy': 85.33411929822238, 'alone_classifier': 79.931640625, 'validation_loss': 0.37797073647379875, 'n_experts': 2, 'expert_0': 79.83191041122959, 'expert_1': 0.0}\n","Epoch: [22][0/48]\tTime 0.671 (0.671)\tLoss 0.3491 (0.3491)\tPrec@1 87.500 (87.500)\n","Epoch: [22][10/48]\tTime 0.714 (0.645)\tLoss 0.3728 (0.3641)\tPrec@1 85.156 (85.263)\n","Epoch: [22][20/48]\tTime 0.576 (0.642)\tLoss 0.4694 (0.3810)\tPrec@1 80.078 (85.417)\n","Epoch: [22][30/48]\tTime 0.699 (0.651)\tLoss 0.4328 (0.3816)\tPrec@1 82.422 (85.244)\n","Epoch: [22][40/48]\tTime 0.559 (0.645)\tLoss 0.3813 (0.3800)\tPrec@1 85.938 (85.366)\n","{'coverage': '3764 out of4096', 'system_accuracy': 81.34765625, 'expert_accuracy': 77.10838728410404, 'classifier_accuracy': 81.72157062376273, 'alone_classifier': 79.248046875, 'validation_loss': 0.3828824535012245, 'n_experts': 2, 'expert_0': 77.10838728410404, 'expert_1': 0.0}\n","Epoch: [23][0/48]\tTime 0.702 (0.702)\tLoss 0.3813 (0.3813)\tPrec@1 85.938 (85.938)\n","Epoch: [23][10/48]\tTime 0.703 (0.659)\tLoss 0.3485 (0.4031)\tPrec@1 85.547 (84.908)\n","Epoch: [23][20/48]\tTime 0.706 (0.635)\tLoss 0.4575 (0.3985)\tPrec@1 85.938 (85.249)\n","Epoch: [23][30/48]\tTime 0.644 (0.642)\tLoss 0.4413 (0.3926)\tPrec@1 82.422 (85.433)\n","Epoch: [23][40/48]\tTime 0.660 (0.634)\tLoss 0.3778 (0.3855)\tPrec@1 86.328 (85.652)\n","{'coverage': '3674 out of4096', 'system_accuracy': 83.10546875, 'expert_accuracy': 79.85778205792319, 'classifier_accuracy': 83.47849527821188, 'alone_classifier': 80.0048828125, 'validation_loss': 0.37200817465782166, 'n_experts': 2, 'expert_0': 79.85778205792319, 'expert_1': 0.0}\n","Epoch: [24][0/48]\tTime 0.580 (0.580)\tLoss 0.4695 (0.4695)\tPrec@1 82.031 (82.031)\n","Epoch: [24][10/48]\tTime 0.563 (0.604)\tLoss 0.4339 (0.3988)\tPrec@1 82.422 (84.943)\n","Epoch: [24][20/48]\tTime 0.688 (0.606)\tLoss 0.3590 (0.3949)\tPrec@1 85.547 (85.007)\n","Epoch: [24][30/48]\tTime 0.703 (0.625)\tLoss 0.4165 (0.3923)\tPrec@1 83.594 (85.370)\n","Epoch: [24][40/48]\tTime 0.574 (0.629)\tLoss 0.4129 (0.3861)\tPrec@1 85.938 (85.394)\n","{'coverage': '3995 out of4096', 'system_accuracy': 80.6396484375, 'expert_accuracy': 80.19786099433466, 'classifier_accuracy': 80.65081149810234, 'alone_classifier': 79.58984375, 'validation_loss': 0.3761338535696268, 'n_experts': 2, 'expert_0': 80.19786099433466, 'expert_1': 0.0}\n","Epoch: [25][0/48]\tTime 0.714 (0.714)\tLoss 0.3629 (0.3629)\tPrec@1 86.719 (86.719)\n","Epoch: [25][10/48]\tTime 0.693 (0.677)\tLoss 0.3512 (0.4009)\tPrec@1 86.719 (84.517)\n","Epoch: [25][20/48]\tTime 0.629 (0.666)\tLoss 0.4173 (0.3950)\tPrec@1 84.766 (84.747)\n","Epoch: [25][30/48]\tTime 0.578 (0.649)\tLoss 0.3138 (0.3824)\tPrec@1 87.109 (85.257)\n","Epoch: [25][40/48]\tTime 0.650 (0.641)\tLoss 0.4610 (0.3857)\tPrec@1 82.031 (84.889)\n","{'coverage': '4009 out of4096', 'system_accuracy': 80.76171875, 'expert_accuracy': 72.41362663534106, 'classifier_accuracy': 80.94287650429342, 'alone_classifier': 80.1025390625, 'validation_loss': 0.37294651195406914, 'n_experts': 2, 'expert_0': 72.41362663534106, 'expert_1': 0.0}\n","Epoch: [26][0/48]\tTime 0.733 (0.733)\tLoss 0.3890 (0.3890)\tPrec@1 82.031 (82.031)\n","Epoch: [26][10/48]\tTime 0.568 (0.676)\tLoss 0.2881 (0.3772)\tPrec@1 86.328 (85.689)\n","Epoch: [26][20/48]\tTime 0.578 (0.655)\tLoss 0.3044 (0.3812)\tPrec@1 89.453 (85.844)\n","Epoch: [26][30/48]\tTime 0.713 (0.660)\tLoss 0.3489 (0.3945)\tPrec@1 86.719 (85.081)\n","Epoch: [26][40/48]\tTime 0.688 (0.661)\tLoss 0.4130 (0.3913)\tPrec@1 83.203 (85.137)\n","{'coverage': '3782 out of4096', 'system_accuracy': 82.32421875, 'expert_accuracy': 80.25472595240385, 'classifier_accuracy': 82.49603166324611, 'alone_classifier': 79.8828125, 'validation_loss': 0.3820278812199831, 'n_experts': 2, 'expert_0': 80.25472595240385, 'expert_1': 0.0}\n","Epoch: [27][0/48]\tTime 0.592 (0.592)\tLoss 0.3939 (0.3939)\tPrec@1 84.766 (84.766)\n","Epoch: [27][10/48]\tTime 0.590 (0.596)\tLoss 0.3503 (0.3773)\tPrec@1 86.719 (85.938)\n","Epoch: [27][20/48]\tTime 0.618 (0.594)\tLoss 0.3776 (0.3827)\tPrec@1 86.719 (86.570)\n","Epoch: [27][30/48]\tTime 0.586 (0.607)\tLoss 0.4767 (0.3941)\tPrec@1 84.375 (85.799)\n","Epoch: [27][40/48]\tTime 0.568 (0.602)\tLoss 0.3143 (0.3906)\tPrec@1 87.500 (85.756)\n","{'coverage': '3906 out of4096', 'system_accuracy': 81.6650390625, 'expert_accuracy': 81.57886149593527, 'classifier_accuracy': 81.66922473965118, 'alone_classifier': 80.029296875, 'validation_loss': 0.36876753717660904, 'n_experts': 2, 'expert_0': 81.57886149593527, 'expert_1': 0.0}\n","Epoch: [28][0/48]\tTime 0.575 (0.575)\tLoss 0.3078 (0.3078)\tPrec@1 89.062 (89.062)\n","Epoch: [28][10/48]\tTime 0.558 (0.622)\tLoss 0.3155 (0.3757)\tPrec@1 87.891 (85.689)\n","Epoch: [28][20/48]\tTime 0.561 (0.624)\tLoss 0.4449 (0.3893)\tPrec@1 83.984 (85.361)\n","Epoch: [28][30/48]\tTime 0.657 (0.629)\tLoss 0.3519 (0.3784)\tPrec@1 84.375 (85.761)\n","Epoch: [28][40/48]\tTime 0.654 (0.631)\tLoss 0.3702 (0.3802)\tPrec@1 87.500 (85.747)\n","{'coverage': '1931 out of4096', 'system_accuracy': 85.8642578125, 'expert_accuracy': 81.57043126370151, 'classifier_accuracy': 90.67840027558776, 'alone_classifier': 79.9072265625, 'validation_loss': 0.3807592373341322, 'n_experts': 2, 'expert_0': 81.57043126370151, 'expert_1': 0.0}\n","Epoch: [29][0/48]\tTime 0.574 (0.574)\tLoss 0.4397 (0.4397)\tPrec@1 83.594 (83.594)\n","Epoch: [29][10/48]\tTime 0.557 (0.638)\tLoss 0.4614 (0.4014)\tPrec@1 82.422 (83.487)\n","Epoch: [29][20/48]\tTime 0.565 (0.633)\tLoss 0.4057 (0.3825)\tPrec@1 83.594 (84.877)\n","Epoch: [29][30/48]\tTime 0.576 (0.625)\tLoss 0.4125 (0.3958)\tPrec@1 84.766 (84.677)\n","Epoch: [29][40/48]\tTime 0.587 (0.633)\tLoss 0.3242 (0.3888)\tPrec@1 89.453 (84.985)\n","{'coverage': '2102 out of4096', 'system_accuracy': 86.3037109375, 'expert_accuracy': 81.69507706167732, 'classifier_accuracy': 90.67554278422726, 'alone_classifier': 79.638671875, 'validation_loss': 0.37783993780612946, 'n_experts': 2, 'expert_0': 81.69507706167732, 'expert_1': 0.0}\n","Epoch: [30][0/48]\tTime 0.581 (0.581)\tLoss 0.3480 (0.3480)\tPrec@1 84.375 (84.375)\n","Epoch: [30][10/48]\tTime 0.587 (0.601)\tLoss 0.3401 (0.3877)\tPrec@1 85.547 (85.227)\n","Epoch: [30][20/48]\tTime 0.683 (0.615)\tLoss 0.4301 (0.3940)\tPrec@1 83.203 (85.361)\n","Epoch: [30][30/48]\tTime 0.692 (0.616)\tLoss 0.3966 (0.3870)\tPrec@1 86.719 (85.572)\n","Epoch: [30][40/48]\tTime 0.681 (0.628)\tLoss 0.4048 (0.3841)\tPrec@1 86.328 (85.699)\n","{'coverage': '3609 out of4096', 'system_accuracy': 83.5693359375, 'expert_accuracy': 79.05540901215235, 'classifier_accuracy': 84.17844044947519, 'alone_classifier': 80.76171875, 'validation_loss': 0.3726835064589977, 'n_experts': 2, 'expert_0': 79.05540901215235, 'expert_1': 0.0}\n","Epoch: [31][0/48]\tTime 0.651 (0.651)\tLoss 0.3377 (0.3377)\tPrec@1 86.719 (86.719)\n","Epoch: [31][10/48]\tTime 0.574 (0.634)\tLoss 0.4150 (0.3665)\tPrec@1 83.594 (86.506)\n","Epoch: [31][20/48]\tTime 0.557 (0.637)\tLoss 0.4299 (0.3848)\tPrec@1 80.859 (85.789)\n","Epoch: [31][30/48]\tTime 0.565 (0.633)\tLoss 0.3710 (0.3914)\tPrec@1 85.156 (85.660)\n","Epoch: [31][40/48]\tTime 0.565 (0.626)\tLoss 0.4185 (0.3898)\tPrec@1 83.203 (85.433)\n","{'coverage': '4095 out of4096', 'system_accuracy': 78.7353515625, 'expert_accuracy': 99.98000399920016, 'classifier_accuracy': 78.73015680756637, 'alone_classifier': 78.7353515625, 'validation_loss': 0.3869063537567854, 'n_experts': 2, 'expert_0': 99.98000399920016, 'expert_1': 0.0}\n","Epoch: [32][0/48]\tTime 0.618 (0.618)\tLoss 0.3724 (0.3724)\tPrec@1 87.891 (87.891)\n","Epoch: [32][10/48]\tTime 0.571 (0.635)\tLoss 0.4201 (0.3928)\tPrec@1 80.859 (84.979)\n","Epoch: [32][20/48]\tTime 0.557 (0.620)\tLoss 0.3561 (0.3876)\tPrec@1 84.766 (84.970)\n","Epoch: [32][30/48]\tTime 0.692 (0.623)\tLoss 0.3477 (0.3873)\tPrec@1 86.328 (85.030)\n","Epoch: [32][40/48]\tTime 0.607 (0.621)\tLoss 0.4307 (0.3861)\tPrec@1 84.766 (85.061)\n","{'coverage': '1371 out of4096', 'system_accuracy': 85.400390625, 'expert_accuracy': 82.27522331924966, 'classifier_accuracy': 91.6119553893541, 'alone_classifier': 78.955078125, 'validation_loss': 0.38956042006611824, 'n_experts': 2, 'expert_0': 82.27522331924966, 'expert_1': 0.0}\n","Epoch: [33][0/48]\tTime 0.667 (0.667)\tLoss 0.4065 (0.4065)\tPrec@1 84.766 (84.766)\n","Epoch: [33][10/48]\tTime 0.560 (0.773)\tLoss 0.3459 (0.3697)\tPrec@1 83.203 (85.582)\n","Epoch: [33][20/48]\tTime 0.693 (0.724)\tLoss 0.3318 (0.3736)\tPrec@1 89.062 (85.844)\n","Epoch: [33][30/48]\tTime 0.570 (0.695)\tLoss 0.2592 (0.3649)\tPrec@1 91.797 (86.290)\n","Epoch: [33][40/48]\tTime 0.564 (0.677)\tLoss 0.3695 (0.3738)\tPrec@1 87.500 (85.899)\n","{'coverage': '2756 out of4096', 'system_accuracy': 85.7666015625, 'expert_accuracy': 81.34327144130278, 'classifier_accuracy': 87.91726821780594, 'alone_classifier': 80.4931640625, 'validation_loss': 0.3745205793529749, 'n_experts': 2, 'expert_0': 81.34327144130278, 'expert_1': 0.0}\n","Epoch: [34][0/48]\tTime 0.701 (0.701)\tLoss 0.4469 (0.4469)\tPrec@1 82.812 (82.812)\n","Epoch: [34][10/48]\tTime 0.573 (0.650)\tLoss 0.4509 (0.3801)\tPrec@1 83.203 (84.979)\n","Epoch: [34][20/48]\tTime 0.699 (0.631)\tLoss 0.4555 (0.3956)\tPrec@1 83.594 (85.138)\n","Epoch: [34][30/48]\tTime 0.574 (0.629)\tLoss 0.3722 (0.3878)\tPrec@1 85.547 (85.270)\n","Epoch: [34][40/48]\tTime 0.571 (0.623)\tLoss 0.4503 (0.3859)\tPrec@1 83.203 (85.290)\n","{'coverage': '3659 out of4096', 'system_accuracy': 83.4228515625, 'expert_accuracy': 79.40499798398261, 'classifier_accuracy': 83.9027033642333, 'alone_classifier': 80.37109375, 'validation_loss': 0.37234981544315815, 'n_experts': 2, 'expert_0': 79.40499798398261, 'expert_1': 0.0}\n","Epoch: [35][0/48]\tTime 0.652 (0.652)\tLoss 0.4029 (0.4029)\tPrec@1 85.547 (85.547)\n","Epoch: [35][10/48]\tTime 0.558 (0.580)\tLoss 0.3455 (0.3661)\tPrec@1 87.891 (85.795)\n","Epoch: [35][20/48]\tTime 0.559 (0.592)\tLoss 0.4470 (0.3799)\tPrec@1 84.375 (85.603)\n","Epoch: [35][30/48]\tTime 0.555 (0.595)\tLoss 0.3987 (0.3790)\tPrec@1 85.547 (85.761)\n","Epoch: [35][40/48]\tTime 0.681 (0.601)\tLoss 0.3399 (0.3821)\tPrec@1 85.547 (85.871)\n","{'coverage': '2601 out of4096', 'system_accuracy': 85.83984375, 'expert_accuracy': 81.00333364503898, 'classifier_accuracy': 88.61975822300045, 'alone_classifier': 80.7861328125, 'validation_loss': 0.37535693123936653, 'n_experts': 2, 'expert_0': 81.00333364503898, 'expert_1': 0.0}\n","Epoch: [36][0/48]\tTime 0.706 (0.706)\tLoss 0.4420 (0.4420)\tPrec@1 82.812 (82.812)\n","Epoch: [36][10/48]\tTime 0.557 (0.597)\tLoss 0.3990 (0.3939)\tPrec@1 83.203 (85.689)\n","Epoch: [36][20/48]\tTime 0.661 (0.596)\tLoss 0.4810 (0.3831)\tPrec@1 81.641 (86.012)\n","Epoch: [36][30/48]\tTime 0.553 (0.613)\tLoss 0.3444 (0.3849)\tPrec@1 87.109 (85.912)\n","Epoch: [36][40/48]\tTime 0.707 (0.609)\tLoss 0.4137 (0.3849)\tPrec@1 83.594 (85.661)\n","{'coverage': '3664 out of4096', 'system_accuracy': 83.349609375, 'expert_accuracy': 78.47218589250653, 'classifier_accuracy': 83.9246701985625, 'alone_classifier': 80.5419921875, 'validation_loss': 0.36086572520434856, 'n_experts': 2, 'expert_0': 78.47218589250653, 'expert_1': 0.0}\n","Saving the model with classifier accuracy 83.9246701985625\n","Epoch: [37][0/48]\tTime 0.571 (0.571)\tLoss 0.4125 (0.4125)\tPrec@1 83.594 (83.594)\n","Epoch: [37][10/48]\tTime 0.560 (0.622)\tLoss 0.3424 (0.3874)\tPrec@1 84.766 (85.050)\n","Epoch: [37][20/48]\tTime 0.624 (0.636)\tLoss 0.4685 (0.3814)\tPrec@1 83.594 (85.677)\n","Epoch: [37][30/48]\tTime 0.648 (0.634)\tLoss 0.4006 (0.3829)\tPrec@1 85.938 (85.622)\n","Epoch: [37][40/48]\tTime 0.555 (0.624)\tLoss 0.4743 (0.3855)\tPrec@1 82.031 (85.699)\n","{'coverage': '3694 out of4096', 'system_accuracy': 83.2275390625, 'expert_accuracy': 78.85568216135216, 'classifier_accuracy': 83.7033003870249, 'alone_classifier': 80.3955078125, 'validation_loss': 0.36772393621504307, 'n_experts': 2, 'expert_0': 78.85568216135216, 'expert_1': 0.0}\n","Epoch: [38][0/48]\tTime 0.566 (0.566)\tLoss 0.4166 (0.4166)\tPrec@1 83.984 (83.984)\n","Epoch: [38][10/48]\tTime 0.673 (0.591)\tLoss 0.4402 (0.3837)\tPrec@1 85.547 (86.612)\n","Epoch: [38][20/48]\tTime 0.704 (0.630)\tLoss 0.3688 (0.3806)\tPrec@1 90.625 (86.365)\n","Epoch: [38][30/48]\tTime 0.557 (0.627)\tLoss 0.3966 (0.3829)\tPrec@1 85.156 (86.366)\n","Epoch: [38][40/48]\tTime 0.699 (0.627)\tLoss 0.4398 (0.3856)\tPrec@1 85.156 (86.195)\n","{'coverage': '2846 out of4096', 'system_accuracy': 85.5224609375, 'expert_accuracy': 80.63998709760207, 'classifier_accuracy': 87.66689783320808, 'alone_classifier': 80.908203125, 'validation_loss': 0.371816398575902, 'n_experts': 2, 'expert_0': 80.63998709760207, 'expert_1': 0.0}\n","Epoch: [39][0/48]\tTime 0.623 (0.623)\tLoss 0.4380 (0.4380)\tPrec@1 84.766 (84.766)\n","Epoch: [39][10/48]\tTime 0.568 (0.622)\tLoss 0.2931 (0.3857)\tPrec@1 91.016 (85.369)\n","Epoch: [39][20/48]\tTime 0.609 (0.616)\tLoss 0.3029 (0.3823)\tPrec@1 87.500 (85.249)\n","Epoch: [39][30/48]\tTime 0.577 (0.630)\tLoss 0.3537 (0.3842)\tPrec@1 89.453 (85.685)\n","Epoch: [39][40/48]\tTime 0.560 (0.624)\tLoss 0.3740 (0.3831)\tPrec@1 87.109 (85.671)\n","{'coverage': '2469 out of4096', 'system_accuracy': 86.2548828125, 'expert_accuracy': 81.56114547496675, 'classifier_accuracy': 89.34791051648803, 'alone_classifier': 80.6640625, 'validation_loss': 0.36542525328695774, 'n_experts': 2, 'expert_0': 81.56114547496675, 'expert_1': 0.0}\n","Epoch: [40][0/48]\tTime 0.587 (0.587)\tLoss 0.3462 (0.3462)\tPrec@1 87.891 (87.891)\n","Epoch: [40][10/48]\tTime 0.560 (0.581)\tLoss 0.4104 (0.3858)\tPrec@1 87.500 (86.044)\n","Epoch: [40][20/48]\tTime 0.696 (0.624)\tLoss 0.3787 (0.3869)\tPrec@1 87.891 (86.161)\n","Epoch: [40][30/48]\tTime 0.561 (0.624)\tLoss 0.4545 (0.3945)\tPrec@1 83.203 (85.522)\n","Epoch: [40][40/48]\tTime 0.685 (0.623)\tLoss 0.4207 (0.3935)\tPrec@1 83.594 (85.604)\n","{'coverage': '2884 out of4096', 'system_accuracy': 85.6689453125, 'expert_accuracy': 80.94058070287447, 'classifier_accuracy': 87.65603024771046, 'alone_classifier': 79.78515625, 'validation_loss': 0.37043491937220097, 'n_experts': 2, 'expert_0': 80.94058070287447, 'expert_1': 0.0}\n","Epoch: [41][0/48]\tTime 0.583 (0.583)\tLoss 0.3871 (0.3871)\tPrec@1 85.156 (85.156)\n","Epoch: [41][10/48]\tTime 0.703 (0.658)\tLoss 0.3548 (0.3622)\tPrec@1 86.328 (86.044)\n","Epoch: [41][20/48]\tTime 0.580 (0.663)\tLoss 0.3544 (0.3767)\tPrec@1 89.062 (85.956)\n","Epoch: [41][30/48]\tTime 0.582 (0.632)\tLoss 0.4886 (0.3785)\tPrec@1 80.859 (85.572)\n","Epoch: [41][40/48]\tTime 0.618 (0.634)\tLoss 0.4165 (0.3846)\tPrec@1 85.938 (85.518)\n","{'coverage': '3757 out of4096', 'system_accuracy': 82.568359375, 'expert_accuracy': 79.3509856336368, 'classifier_accuracy': 82.85866162207448, 'alone_classifier': 80.029296875, 'validation_loss': 0.37427240423858166, 'n_experts': 2, 'expert_0': 79.3509856336368, 'expert_1': 0.0}\n","Epoch: [42][0/48]\tTime 0.598 (0.598)\tLoss 0.4851 (0.4851)\tPrec@1 83.203 (83.203)\n","Epoch: [42][10/48]\tTime 0.671 (0.579)\tLoss 0.4361 (0.4001)\tPrec@1 84.375 (85.653)\n","Epoch: [42][20/48]\tTime 0.645 (0.584)\tLoss 0.3009 (0.3785)\tPrec@1 87.109 (86.086)\n","Epoch: [42][30/48]\tTime 0.696 (0.603)\tLoss 0.3594 (0.3768)\tPrec@1 88.672 (86.328)\n","Epoch: [42][40/48]\tTime 0.689 (0.619)\tLoss 0.4077 (0.3777)\tPrec@1 82.812 (85.947)\n","{'coverage': '3400 out of4096', 'system_accuracy': 84.1064453125, 'expert_accuracy': 80.31606887469286, 'classifier_accuracy': 84.88235044463674, 'alone_classifier': 79.7607421875, 'validation_loss': 0.38102161325514317, 'n_experts': 2, 'expert_0': 80.31606887469286, 'expert_1': 0.0}\n","Epoch: [43][0/48]\tTime 0.561 (0.561)\tLoss 0.3063 (0.3063)\tPrec@1 90.625 (90.625)\n","Epoch: [43][10/48]\tTime 0.661 (0.588)\tLoss 0.4089 (0.3799)\tPrec@1 83.984 (86.115)\n","Epoch: [43][20/48]\tTime 0.686 (0.624)\tLoss 0.3456 (0.3753)\tPrec@1 85.938 (85.751)\n","Epoch: [43][30/48]\tTime 0.680 (0.631)\tLoss 0.3606 (0.3730)\tPrec@1 87.109 (86.177)\n","Epoch: [43][40/48]\tTime 0.560 (0.618)\tLoss 0.3978 (0.3785)\tPrec@1 85.547 (86.061)\n","{'coverage': '3952 out of4096', 'system_accuracy': 81.4697265625, 'expert_accuracy': 83.33321759275334, 'classifier_accuracy': 81.40181980258552, 'alone_classifier': 80.078125, 'validation_loss': 0.368398804217577, 'n_experts': 2, 'expert_0': 83.33321759275334, 'expert_1': 0.0}\n","Epoch: [44][0/48]\tTime 0.692 (0.692)\tLoss 0.3268 (0.3268)\tPrec@1 88.281 (88.281)\n","Epoch: [44][10/48]\tTime 0.556 (0.638)\tLoss 0.3960 (0.3865)\tPrec@1 83.594 (86.080)\n","Epoch: [44][20/48]\tTime 0.592 (0.629)\tLoss 0.4374 (0.3863)\tPrec@1 80.469 (85.826)\n","Epoch: [44][30/48]\tTime 0.681 (0.613)\tLoss 0.4149 (0.3835)\tPrec@1 85.156 (85.711)\n","Epoch: [44][40/48]\tTime 0.555 (0.616)\tLoss 0.3152 (0.3767)\tPrec@1 88.672 (85.985)\n","{'coverage': '2570 out of4096', 'system_accuracy': 86.0595703125, 'expert_accuracy': 80.60287279123554, 'classifier_accuracy': 89.29960742024873, 'alone_classifier': 80.37109375, 'validation_loss': 0.3632817417383194, 'n_experts': 2, 'expert_0': 80.60287279123554, 'expert_1': 0.0}\n","Epoch: [45][0/48]\tTime 0.677 (0.677)\tLoss 0.3887 (0.3887)\tPrec@1 83.984 (83.984)\n","Epoch: [45][10/48]\tTime 0.689 (0.653)\tLoss 0.4063 (0.3757)\tPrec@1 84.375 (85.866)\n","Epoch: [45][20/48]\tTime 0.699 (0.672)\tLoss 0.4715 (0.3834)\tPrec@1 84.766 (85.751)\n","Epoch: [45][30/48]\tTime 0.711 (0.666)\tLoss 0.4466 (0.3844)\tPrec@1 80.469 (85.484)\n","Epoch: [45][40/48]\tTime 0.594 (0.656)\tLoss 0.4210 (0.3832)\tPrec@1 84.766 (85.661)\n","{'coverage': '3250 out of4096', 'system_accuracy': 84.9365234375, 'expert_accuracy': 80.85104471606509, 'classifier_accuracy': 85.99999735384623, 'alone_classifier': 80.7861328125, 'validation_loss': 0.3676711283624172, 'n_experts': 2, 'expert_0': 80.85104471606509, 'expert_1': 0.0}\n","Epoch: [46][0/48]\tTime 0.700 (0.700)\tLoss 0.3744 (0.3744)\tPrec@1 84.766 (84.766)\n","Epoch: [46][10/48]\tTime 0.701 (0.676)\tLoss 0.4279 (0.4143)\tPrec@1 84.766 (84.375)\n","Epoch: [46][20/48]\tTime 0.690 (0.652)\tLoss 0.3539 (0.3803)\tPrec@1 87.891 (85.919)\n","Epoch: [46][30/48]\tTime 0.693 (0.652)\tLoss 0.3742 (0.3834)\tPrec@1 87.500 (85.887)\n","Epoch: [46][40/48]\tTime 0.698 (0.646)\tLoss 0.3614 (0.3807)\tPrec@1 87.109 (85.976)\n","{'coverage': '2810 out of4096', 'system_accuracy': 85.9130859375, 'expert_accuracy': 80.87090499674883, 'classifier_accuracy': 88.22063742987055, 'alone_classifier': 80.029296875, 'validation_loss': 0.3734308332204819, 'n_experts': 2, 'expert_0': 80.87090499674883, 'expert_1': 0.0}\n","Epoch: [47][0/48]\tTime 0.944 (0.944)\tLoss 0.3564 (0.3564)\tPrec@1 87.109 (87.109)\n","Epoch: [47][10/48]\tTime 0.691 (0.746)\tLoss 0.3880 (0.3696)\tPrec@1 87.109 (86.719)\n","Epoch: [47][20/48]\tTime 0.563 (0.683)\tLoss 0.3041 (0.3767)\tPrec@1 89.453 (86.328)\n","Epoch: [47][30/48]\tTime 0.690 (0.651)\tLoss 0.3956 (0.3709)\tPrec@1 86.328 (86.316)\n","Epoch: [47][40/48]\tTime 0.699 (0.645)\tLoss 0.3739 (0.3755)\tPrec@1 87.891 (86.138)\n","{'coverage': '3501 out of4096', 'system_accuracy': 84.2529296875, 'expert_accuracy': 81.17644330203588, 'classifier_accuracy': 84.77577592756995, 'alone_classifier': 80.4443359375, 'validation_loss': 0.3673850167542696, 'n_experts': 2, 'expert_0': 81.17644330203588, 'expert_1': 0.0}\n","Epoch: [48][0/48]\tTime 0.692 (0.692)\tLoss 0.3993 (0.3993)\tPrec@1 85.156 (85.156)\n","Epoch: [48][10/48]\tTime 0.556 (0.651)\tLoss 0.3611 (0.3878)\tPrec@1 85.547 (85.192)\n","Epoch: [48][20/48]\tTime 0.674 (0.614)\tLoss 0.4515 (0.3858)\tPrec@1 82.031 (85.603)\n","Epoch: [48][30/48]\tTime 0.681 (0.633)\tLoss 0.3631 (0.3829)\tPrec@1 89.062 (85.925)\n","Epoch: [48][40/48]\tTime 0.568 (0.644)\tLoss 0.3986 (0.3825)\tPrec@1 84.375 (85.842)\n","{'coverage': '2968 out of4096', 'system_accuracy': 86.0595703125, 'expert_accuracy': 82.80140375861636, 'classifier_accuracy': 87.29784072446628, 'alone_classifier': 80.17578125, 'validation_loss': 0.35762662068009377, 'n_experts': 2, 'expert_0': 82.80140375861636, 'expert_1': 0.0}\n","Saving the model with classifier accuracy 87.29784072446628\n","Epoch: [49][0/48]\tTime 0.602 (0.602)\tLoss 0.4702 (0.4702)\tPrec@1 80.469 (80.469)\n","Epoch: [49][10/48]\tTime 0.703 (0.611)\tLoss 0.3599 (0.3945)\tPrec@1 87.500 (85.795)\n","Epoch: [49][20/48]\tTime 0.704 (0.620)\tLoss 0.3399 (0.3850)\tPrec@1 84.766 (85.975)\n","Epoch: [49][30/48]\tTime 0.568 (0.611)\tLoss 0.4138 (0.3817)\tPrec@1 82.812 (85.811)\n","Epoch: [49][40/48]\tTime 0.698 (0.624)\tLoss 0.3700 (0.3787)\tPrec@1 85.938 (85.871)\n","{'coverage': '3143 out of4096', 'system_accuracy': 85.107421875, 'expert_accuracy': 80.06294227430384, 'classifier_accuracy': 86.63696829026509, 'alone_classifier': 80.078125, 'validation_loss': 0.3723494950681925, 'n_experts': 2, 'expert_0': 80.06294227430384, 'expert_1': 0.0}\n","Epoch: [50][0/48]\tTime 0.706 (0.706)\tLoss 0.3951 (0.3951)\tPrec@1 83.984 (83.984)\n","Epoch: [50][10/48]\tTime 0.579 (0.634)\tLoss 0.3703 (0.3902)\tPrec@1 85.938 (85.831)\n","Epoch: [50][20/48]\tTime 0.556 (0.610)\tLoss 0.3585 (0.3892)\tPrec@1 86.328 (85.584)\n","Epoch: [50][30/48]\tTime 0.563 (0.622)\tLoss 0.3984 (0.3842)\tPrec@1 85.547 (85.736)\n","Epoch: [50][40/48]\tTime 0.565 (0.623)\tLoss 0.3627 (0.3834)\tPrec@1 85.156 (85.718)\n","{'coverage': '3011 out of4096', 'system_accuracy': 85.7666015625, 'expert_accuracy': 81.75113700439871, 'classifier_accuracy': 87.21354741901203, 'alone_classifier': 79.8828125, 'validation_loss': 0.3631331864744425, 'n_experts': 2, 'expert_0': 81.75113700439871, 'expert_1': 0.0}\n","Epoch: [51][0/48]\tTime 0.580 (0.580)\tLoss 0.3940 (0.3940)\tPrec@1 89.062 (89.062)\n","Epoch: [51][10/48]\tTime 0.572 (0.598)\tLoss 0.3625 (0.3723)\tPrec@1 86.719 (86.435)\n","Epoch: [51][20/48]\tTime 0.691 (0.633)\tLoss 0.4324 (0.3713)\tPrec@1 84.766 (85.975)\n","Epoch: [51][30/48]\tTime 0.630 (0.623)\tLoss 0.3974 (0.3761)\tPrec@1 85.547 (86.001)\n","Epoch: [51][40/48]\tTime 0.712 (0.635)\tLoss 0.4001 (0.3781)\tPrec@1 85.547 (85.776)\n","{'coverage': '2857 out of4096', 'system_accuracy': 85.791015625, 'expert_accuracy': 81.35591907087667, 'classifier_accuracy': 87.71438264912906, 'alone_classifier': 79.931640625, 'validation_loss': 0.36627208068966866, 'n_experts': 2, 'expert_0': 81.35591907087667, 'expert_1': 0.0}\n","Epoch: [52][0/48]\tTime 0.584 (0.584)\tLoss 0.4011 (0.4011)\tPrec@1 85.156 (85.156)\n","Epoch: [52][10/48]\tTime 0.576 (0.638)\tLoss 0.4212 (0.4094)\tPrec@1 84.375 (85.724)\n","Epoch: [52][20/48]\tTime 0.635 (0.646)\tLoss 0.3204 (0.3853)\tPrec@1 87.109 (86.421)\n","Epoch: [52][30/48]\tTime 0.553 (0.644)\tLoss 0.3384 (0.3777)\tPrec@1 86.328 (86.303)\n","Epoch: [52][40/48]\tTime 0.692 (0.629)\tLoss 0.3940 (0.3843)\tPrec@1 86.328 (85.995)\n","{'coverage': '3840 out of4096', 'system_accuracy': 82.177734375, 'expert_accuracy': 79.2968130493648, 'classifier_accuracy': 82.36978952162006, 'alone_classifier': 80.2734375, 'validation_loss': 0.3680470250546932, 'n_experts': 2, 'expert_0': 79.2968130493648, 'expert_1': 0.0}\n","Epoch: [53][0/48]\tTime 0.584 (0.584)\tLoss 0.3630 (0.3630)\tPrec@1 84.766 (84.766)\n","Epoch: [53][10/48]\tTime 0.691 (0.613)\tLoss 0.3008 (0.3899)\tPrec@1 89.844 (86.080)\n","Epoch: [53][20/48]\tTime 0.713 (0.605)\tLoss 0.3707 (0.3803)\tPrec@1 85.156 (86.105)\n","Epoch: [53][30/48]\tTime 0.693 (0.603)\tLoss 0.3430 (0.3777)\tPrec@1 86.719 (85.938)\n","Epoch: [53][40/48]\tTime 0.698 (0.608)\tLoss 0.3513 (0.3808)\tPrec@1 89.062 (85.890)\n","{'coverage': '2555 out of4096', 'system_accuracy': 85.6201171875, 'expert_accuracy': 80.27253987377809, 'classifier_accuracy': 88.84539769685331, 'alone_classifier': 80.224609375, 'validation_loss': 0.37404358200728893, 'n_experts': 2, 'expert_0': 80.27253987377809, 'expert_1': 0.0}\n","Epoch: [54][0/48]\tTime 0.582 (0.582)\tLoss 0.3611 (0.3611)\tPrec@1 86.328 (86.328)\n","Epoch: [54][10/48]\tTime 0.576 (0.625)\tLoss 0.4021 (0.3784)\tPrec@1 85.938 (85.938)\n","Epoch: [54][20/48]\tTime 0.617 (0.617)\tLoss 0.3428 (0.3780)\tPrec@1 89.062 (85.863)\n","Epoch: [54][30/48]\tTime 0.557 (0.624)\tLoss 0.4091 (0.3808)\tPrec@1 83.984 (85.496)\n","Epoch: [54][40/48]\tTime 0.615 (0.619)\tLoss 0.3908 (0.3811)\tPrec@1 84.375 (85.499)\n","{'coverage': '2968 out of4096', 'system_accuracy': 85.3515625, 'expert_accuracy': 80.3191346951889, 'classifier_accuracy': 87.26414800322951, 'alone_classifier': 79.638671875, 'validation_loss': 0.36313957162201405, 'n_experts': 2, 'expert_0': 80.3191346951889, 'expert_1': 0.0}\n","Epoch: [55][0/48]\tTime 0.699 (0.699)\tLoss 0.4344 (0.4344)\tPrec@1 85.938 (85.938)\n","Epoch: [55][10/48]\tTime 0.580 (0.640)\tLoss 0.4278 (0.3982)\tPrec@1 84.766 (85.050)\n","Epoch: [55][20/48]\tTime 0.685 (0.639)\tLoss 0.3528 (0.3883)\tPrec@1 84.766 (85.435)\n","Epoch: [55][30/48]\tTime 0.636 (0.618)\tLoss 0.3571 (0.3805)\tPrec@1 85.938 (85.786)\n","Epoch: [55][40/48]\tTime 0.575 (0.622)\tLoss 0.3082 (0.3836)\tPrec@1 89.062 (85.938)\n","{'coverage': '2308 out of4096', 'system_accuracy': 86.1328125, 'expert_accuracy': 81.59954344524122, 'classifier_accuracy': 89.64471015404202, 'alone_classifier': 80.322265625, 'validation_loss': 0.37108880281448364, 'n_experts': 2, 'expert_0': 81.59954344524122, 'expert_1': 0.0}\n","Epoch: [56][0/48]\tTime 0.579 (0.579)\tLoss 0.2717 (0.2717)\tPrec@1 88.672 (88.672)\n","Epoch: [56][10/48]\tTime 0.705 (0.639)\tLoss 0.3818 (0.3811)\tPrec@1 84.375 (85.440)\n","Epoch: [56][20/48]\tTime 0.636 (0.647)\tLoss 0.3514 (0.3824)\tPrec@1 87.500 (85.658)\n","Epoch: [56][30/48]\tTime 0.561 (0.637)\tLoss 0.4477 (0.3800)\tPrec@1 82.422 (85.698)\n","Epoch: [56][40/48]\tTime 0.563 (0.623)\tLoss 0.4191 (0.3833)\tPrec@1 83.203 (85.680)\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-9696741b8161>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mincrease_experts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-11-ba838b869e19>\u001b[0m in \u001b[0;36mincrease_experts\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0mtrainD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHatespeechDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mvalD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHatespeechDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpert_fns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mpth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ckp_dir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'experiment_name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_log_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_seed_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-ba838b869e19>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataset, validation_dataset, expert_fns, config, seed)\u001b[0m\n\u001b[1;32m    275\u001b[0m                                         \u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                                         \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"alpha\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                                         config)\n\u001b[0m\u001b[1;32m    278\u001b[0m         metrics = evaluate(model,\n\u001b[1;32m    279\u001b[0m                            \u001b[0mexpert_fns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-ba838b869e19>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(iters, warmup_iters, lrate, train_loader, model, optimizer, scheduler, epoch, expert_fns, loss_fn, n_classes, alpha, config)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;31m# compute gradient and do SGD step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["increase_experts(config)"]},{"cell_type":"code","source":[],"metadata":{"id":"1cCJboWZwewO"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QMDAlKpl2D3Q"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}