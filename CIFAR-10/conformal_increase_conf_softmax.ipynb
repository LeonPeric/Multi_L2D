{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "87f62873-3ac6-4961-934b-3ac2722fc73d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b036bee9-457b-4c38-9681-f64fc6150c82",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Increase Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "e8b798ec-6d65-4770-945a-e930c29d1d41",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9216, 14])\n",
      "torch.Size([9216, 14])\n",
      "torch.Size([9216, 14])\n",
      "torch.Size([9216, 14])\n",
      "torch.Size([9216, 14])\n"
     ]
    }
   ],
   "source": [
    "# === Softmax ===\n",
    "n_classes = 10\n",
    "random_expert_idx = 0\n",
    "probs_softmax = []\n",
    "confs = []\n",
    "exps = []\n",
    "true = []\n",
    "path = \"softmax_increase_confidence/\"\n",
    "n_experts = 4\n",
    "p_experts = [0.2, 0.4, 0.6, 0.8, 0.95]\n",
    "for p in p_experts:\n",
    "    model_name = '_' + str(p) + '_confidence'\n",
    "    with open(path + 'confidence_multiple_experts' + model_name + '.txt', 'r') as f:\n",
    "        conf = json.loads(json.load(f))\n",
    "    with open(path + 'expert_predictions_multiple_experts' + model_name + '.txt', 'r') as f:\n",
    "        exp_pred = json.loads(json.load(f))\n",
    "    with open(path + 'true_label_multiple_experts' + model_name + '.txt', 'r') as f:\n",
    "        true_label = json.loads(json.load(f))\n",
    "    true.append(true_label['test'])\n",
    "    exps.append(exp_pred['test'])\n",
    "    c = torch.tensor(conf['test'])\n",
    "    print(c.shape)\n",
    "    # DANI Correction ===\n",
    "    c = c.softmax(dim=1)\n",
    "    probs_softmax.append(c)\n",
    "    # DANI Correction ===\n",
    "\n",
    "    temp = 0\n",
    "    for i in range(n_experts):\n",
    "        temp += c[:, (n_classes + n_experts) - (i + 1)]\n",
    "    prob = c / (1.0 - temp).unsqueeze(-1)\n",
    "    confs.append(prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e2067f-b673-4bde-834d-4ba7f33b4add",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Use c, not conf, because we do not apply temperature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "81174996-8914-402a-9cfc-e96ab19fcb88",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 1 expert rando, 3 with prob 0.8 correct\n",
    "probs = probs_softmax[-1]\n",
    "experts = exps[-1]\n",
    "# experts = experts[::-1]  # reverse order!\n",
    "y_true = true[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "probs[:5,10:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.array(experts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_true[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_val = int(0.8 * len(y_true))\n",
    "n_test = len(y_true) - n_val\n",
    "print(\"N val:{}\".format(n_val))\n",
    "print(\"N test:{}\".format(n_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "probs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Validation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## 2. get Q_hat\n",
    "\n",
    "n_classes_exp = n_classes + n_experts\n",
    "probs_val = probs[:n_val, 10:]\n",
    "\n",
    "# experts_val = experts[::-1]  # IMPORTANT! swap to match prob ordering\n",
    "experts_val = experts\n",
    "experts_val = [exp[:n_val] for exp in experts_val]\n",
    "\n",
    "y_true_val = y_true[:n_val]\n",
    "\n",
    "# === Only on deferred samples\n",
    "_, predicted = torch.max(probs[:n_val].data, 1)\n",
    "r = (predicted >= n_classes_exp - n_experts)\n",
    "\n",
    "# Filter \n",
    "probs_val = probs_val[r]\n",
    "experts_val = [np.array(exp)[r] for exp in experts_val]\n",
    "y_true_val = np.array(y_true_val)[r]\n",
    "\n",
    "# Model expert probs ===\n",
    "# Sort J model outputs for experts\n",
    "probs_experts = probs[:n_val, 10:]\n",
    "probs_experts = probs_experts[r]\n",
    "c, pi = probs_experts.sort(dim=1, descending=True)\n",
    "\n",
    "# Correctness experts ===\n",
    "# Check if experts are correct \n",
    "correct_exp = (np.array(experts_val) == np.array(y_true_val)).T\n",
    "# idx for correct experts: [[0,1,2], [1,2], [], ...]\n",
    "correct_exp_idx = [np.where(correct_exp_i)[0] for correct_exp_i in correct_exp]\n",
    "\n",
    "# obtain the last expert to be retrieved. If empty, then add all values.\n",
    "# indexes are not the real expert index, but the sorted indexes, e.g. [[1, 0 ,2],  [1,0], [], ...]\n",
    "pi_corr_exp = [probs_experts[i, corr_exp].sort(descending=True)[1] for i, corr_exp in enumerate(correct_exp)]\n",
    "pi_corr_exp_stop = [pi_corr_exp_i[-1] if len(pi_corr_exp_i)!=0 else -1 for pi_corr_exp_i in pi_corr_exp]  # last expert\n",
    "\n",
    "# obtain real expert index back, e.g. [2,1,-1,...]\n",
    "pi_stop = [correct_exp_idx[i][pi_corr_exp_stop_i] if len(correct_exp_idx[i])!=0 else -1 for i, pi_corr_exp_stop_i in enumerate(pi_corr_exp_stop)]\n",
    "\n",
    "\n",
    "# =========\n",
    "n_val = n_val\n",
    "alpha = 0.1\n",
    "scores = sort.cumsum(dim=1).gather(1, pi.argsort(1))[range(len(torch.tensor(pi_stop))), torch.tensor(pi_stop)]\n",
    "qhat = torch.quantile(scores, np.ceil((r.sum() + 1) * (1 - alpha)) / r.sum(), interpolation=\"higher\")\n",
    "\n",
    "qhat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "probs_val"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "probs[:,10:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sort.cumsum(dim=1).gather(1, pi.argsort(1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_true_val"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.array(experts_val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "n_experts = 4\n",
    "n_classes_exp = n_classes + n_experts\n",
    "\n",
    "probs_test = probs[n_val:, n_classes:]\n",
    "experts_test = [exp[n_val:] for exp in experts]\n",
    "y_true_test = y_true[n_val:]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "probs_test.sum(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# === Only on deferred samples\n",
    "_, predicted = torch.max(probs[n_val:].data, 1)\n",
    "r_test = (predicted >= n_classes_exp - n_experts)\n",
    "\n",
    "# Filter \n",
    "probs_test = probs_test[r_test]\n",
    "experts_test = [np.array(exp)[r_test] for exp in experts_test]\n",
    "y_true_test = np.array(y_true_test)[r_test]\n",
    "\n",
    "# Sort J model outputs for experts. sorted probs and sorted indexes\n",
    "sort_test, pi_test = probs_test.sort(dim=1, descending=True)\n",
    "# Get last sorted index to be below Q_hat\n",
    "pi_stop = (sort_test.cumsum(dim=1) <= qhat).sum(axis=1)\n",
    "\n",
    "# Prediction sets\n",
    "prediction_sets = [(pi_test[i][:(pi_stop[i])]).numpy() for i in range(pi_stop.shape[0])]  # not allow empty sets\n",
    "prediction_sets[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "r.sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = np.array([len(prediction_sets_i) for prediction_sets_i in prediction_sets])\n",
    "import seaborn as sns\n",
    "\n",
    "sns.histplot(a)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.array(experts_test)[:,:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Accuracy w/o Conformal on deferred samples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "correct = 0\n",
    "correct_sys = 0\n",
    "exp = 0\n",
    "exp_total = 0\n",
    "total = 0\n",
    "real_total = 0\n",
    "alone_correct = 0\n",
    "#  === Individual Expert Accuracies === #\n",
    "expert_correct_dic = {k: 0 for k in range(len(experts_test))}\n",
    "expert_total_dic = {k: 0 for k in range(len(experts_test))}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1 expert rando, 3 with prob 0.9 correct\n",
    "probs = probs_softmax[-1]\n",
    "experts = exps[-1]\n",
    "# experts = experts[::-1] \n",
    "y_true = true[-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "n_experts = 4\n",
    "n_classes_exp = n_classes + n_experts\n",
    "\n",
    "probs_test = probs[n_val:]\n",
    "experts_test = [exp[n_val:] for exp in experts]\n",
    "y_true_test = y_true[n_val:]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "probs.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Predicted value \n",
    "_, predicted = torch.max(probs_test.data, 1)\n",
    "# Classifier alone prediction\n",
    "_, prediction = torch.max(probs_test.data[:, :(n_classes_exp - n_experts)],1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### w Conformal Prediction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "probs.sum(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels = y_true_test\n",
    "\n",
    "# Predicted value \n",
    "_, predicted = torch.max(probs_test.data, 1)\n",
    "# Classifier alone prediction\n",
    "_, prediction = torch.max(probs_test.data[:, :(n_classes_exp - n_experts)],1)\n",
    "for i in range(0, n_test):\n",
    "    r = (predicted[i].item() >= n_classes_exp - len(experts_test))\n",
    "    alone_correct += (prediction[i] == labels[i]).item()\n",
    "    if r == 0:\n",
    "        total += 1\n",
    "        correct += (predicted[i] == labels[i]).item()\n",
    "        correct_sys += (predicted[i] == labels[i]).item()\n",
    "        \n",
    "    if r == 1:\n",
    "        # Conformal prediction ===        \n",
    "        # Sort J model outputs for experts. sorted probs and sorted indexes\n",
    "        sort_i, pi_i = probs_test[i,n_classes:].sort(descending=True)\n",
    "        # Get last sorted index to be below Q_hat\n",
    "        pi_stop_i = (sort_i.cumsum(dim=0) <= qhat).sum()\n",
    "\n",
    "        # Prediction sets\n",
    "        prediction_set_i = (pi_i[:(pi_stop_i)]).numpy()  # not allow empty sets        \n",
    "#         print(len(prediction_set_i))\n",
    "        ensemble_expert_pred_i = np.array(experts_test)[prediction_set_i][:, i]\n",
    "        exp_prediction = stats.mode(ensemble_expert_pred_i).mode\n",
    "        # Conformal prediction ===\n",
    "        \n",
    "        # Deferral accuracy: No matter expert ===\n",
    "        exp += (exp_prediction == labels[i])\n",
    "        exp_total += 1\n",
    "        # Individual Expert Accuracy ===\n",
    "        # expert_correct_dic[deferred_exp] += (exp_prediction == labels[i].item())\n",
    "        # expert_total_dic[deferred_exp] += 1\n",
    "        #\n",
    "        correct_sys += (exp_prediction == labels[i])\n",
    "    real_total += 1\n",
    "    \n",
    "#  ===  Coverage  === #    \n",
    "cov = str(total) + str(\" out of\") + str(real_total)\n",
    "\n",
    "#  === Individual Expert Accuracies === #\n",
    "expert_accuracies = {\"expert_{}\".format(str(k)): 100 * expert_correct_dic[k] / (expert_total_dic[k] + 0.0002) for k\n",
    "             in range(len(experts_test))}\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exp_prediction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sort_i"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Cov: {}\".format(100 * (total/real_total)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "expert_accuracies"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "100 * exp / (exp_total + 0.0002),"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exp_total"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "100 * correct_sys / real_total"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### w/o Conformal Prediction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "correct = 0\n",
    "correct_sys = 0\n",
    "exp = 0\n",
    "exp_total = 0\n",
    "total = 0\n",
    "real_total = 0\n",
    "alone_correct = 0\n",
    "#  === Individual Expert Accuracies === #\n",
    "expert_correct_dic = {k: 0 for k in range(len(experts_test))}\n",
    "expert_total_dic = {k: 0 for k in range(len(experts_test))}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1 expert rando, 3 with prob 0.9 correct\n",
    "probs = probs_softmax[-1]\n",
    "experts = exps[-1]\n",
    "# experts = experts[::-1] \n",
    "y_true = true[-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "n_experts = 4\n",
    "n_classes_exp = n_classes + n_experts\n",
    "\n",
    "probs_test = probs[n_val:]\n",
    "experts_test = [exp[n_val:] for exp in experts]\n",
    "y_true_test = y_true[n_val:]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Predicted value \n",
    "_, predicted = torch.max(probs_test.data, 1)\n",
    "# Classifier alone prediction\n",
    "_, prediction = torch.max(probs_test.data[:, :(n_classes_exp - n_experts)],1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels = y_true_test\n",
    "\n",
    "# Predicted value \n",
    "_, predicted = torch.max(probs_test.data, 1)\n",
    "# Classifier alone prediction\n",
    "_, prediction = torch.max(probs_test.data[:, :(n_classes_exp - n_experts)],1)\n",
    "for i in range(0, n_test):\n",
    "    r = (predicted[i].item() >= n_classes_exp - len(experts_test))\n",
    "    alone_correct += (prediction[i] == labels[i]).item()\n",
    "    if r == 0:\n",
    "        total += 1\n",
    "        correct += (predicted[i] == labels[i]).item()\n",
    "        correct_sys += (predicted[i] == labels[i]).item()\n",
    "        \n",
    "    if r == 1:\n",
    "        deferred_exp = (predicted[i] - n_classes).item()  # reverse order, as in loss function\n",
    "        # print(\"def exp: {}\".format(deferred_exp))\n",
    "        # deferred_exp = ((n_classes - 1) - predicted[i]).item()  # reverse order, as in loss function\n",
    "        exp_prediction = experts_test[deferred_exp][i]\n",
    "        # print(\"exp pred: {}\".format(exp_prediction))\n",
    "        #\n",
    "        # Deferral accuracy: No matter expert ===\n",
    "        exp += (exp_prediction == labels[i])\n",
    "        # print(\"label: {}\".format(labels[i]))\n",
    "\n",
    "        exp_total += 1\n",
    "        # Individual Expert Accuracy ===\n",
    "        expert_correct_dic[deferred_exp] += (exp_prediction == labels[i])\n",
    "        expert_total_dic[deferred_exp] += 1\n",
    "        #\n",
    "        correct_sys += (exp_prediction == labels[i])\n",
    "    real_total += 1\n",
    "    \n",
    "#  ===  Coverage  === #    \n",
    "cov = str(total) + str(\" out of\") + str(real_total)\n",
    "\n",
    "#  === Individual Expert Accuracies === #\n",
    "expert_accuracies = {\"expert_{}\".format(str(k)): 100 * expert_correct_dic[k] / (expert_total_dic[k] + 0.0002) for k\n",
    "             in range(len(experts_test))}\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(predicted[i] - n_classes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "c7d36257-d3b4-43b0-9d88-3fd57ec81388",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "n_experts = 4\n",
    "n_classes_exp = n_classes + n_experts\n",
    "\n",
    "probs_test = probs[n_val:]\n",
    "experts_test = [exp[n_val:] for exp in experts]\n",
    "y_true_test = y_true[n_val:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "8e98b807-81a5-4770-8082-04e7425c0d35",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Predicted value \n",
    "_, predicted = torch.max(probs_test.data, 1)\n",
    "# Classifier alone prediction\n",
    "_, prediction = torch.max(probs_test.data[:, :(n_classes_exp - n_experts)],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "ed437339-9d40-4840-b215-07ea9d22d527",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels = y_true_test\n",
    "\n",
    "# Predicted value \n",
    "_, predicted = torch.max(probs_test.data, 1)\n",
    "# Classifier alone prediction\n",
    "_, prediction = torch.max(probs_test.data[:, :(n_classes_exp - n_experts)],1)\n",
    "for i in range(0, n_test):\n",
    "    r = (predicted[i].item() >= n_classes_exp - len(experts_test))\n",
    "    alone_correct += (prediction[i] == labels[i]).item()\n",
    "    if r == 0:\n",
    "        total += 1\n",
    "        correct += (predicted[i] == labels[i]).item()\n",
    "        correct_sys += (predicted[i] == labels[i]).item()\n",
    "        \n",
    "    if r == 1:\n",
    "        deferred_exp = (predicted[i] - n_classes).item()  # reverse order, as in loss function\n",
    "        # print(\"def exp: {}\".format(deferred_exp))\n",
    "        # deferred_exp = ((n_classes - 1) - predicted[i]).item()  # reverse order, as in loss function\n",
    "        exp_prediction = experts_test[deferred_exp][i]\n",
    "        # print(\"exp pred: {}\".format(exp_prediction))\n",
    "        #\n",
    "        # Deferral accuracy: No matter expert ===\n",
    "        exp += (exp_prediction == labels[i])\n",
    "        # print(\"label: {}\".format(labels[i]))\n",
    "\n",
    "        exp_total += 1\n",
    "        # Individual Expert Accuracy ===\n",
    "        expert_correct_dic[deferred_exp] += (exp_prediction == labels[i])\n",
    "        expert_total_dic[deferred_exp] += 1\n",
    "        #\n",
    "        correct_sys += (exp_prediction == labels[i])\n",
    "    real_total += 1\n",
    "    \n",
    "#  ===  Coverage  === #    \n",
    "cov = str(total) + str(\" out of\") + str(real_total)\n",
    "\n",
    "#  === Individual Expert Accuracies === #\n",
    "expert_accuracies = {\"expert_{}\".format(str(k)): 100 * expert_correct_dic[k] / (expert_total_dic[k] + 0.0002) for k\n",
    "             in range(len(experts_test))}\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "ab7f3c98-c8da-4e97-81a2-c05104bdbd62",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-5)"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predicted[i] - n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "6f4fedcd-7758-4e86-863d-df79aa30c040",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'expert_0': 0.0,\n",
       " 'expert_1': 85.07449988880613,\n",
       " 'expert_2': 82.43220964267664,\n",
       " 'expert_3': 81.69931080640052}"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "8c2fc7b5-6ca1-4216-aa80-c7f0fd70b9b3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82.45874588943153,)"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * exp / (exp_total + 0.0002),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "80f9bea7-2375-49b8-8cf0-366717be2f15",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "550"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "73f51115-8afc-4372-ab5b-762b1fba5567",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.01518438177874"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * correct_sys / real_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8feaffe6-83ac-4604-9fa2-e701438e6e01",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Accuracy w Conformal on deferred samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6fb66168-32e0-4b89-9e5f-fec062ffac9e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4832)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d14b356-8707-4439-8365-364a4f751212",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9446, 0.9549, 0.9215, 0.1244],\n",
       "        [0.9760, 0.9769, 0.9756, 0.1037],\n",
       "        [0.9622, 0.9661, 0.9566, 0.1071],\n",
       "        ...,\n",
       "        [0.9315, 0.9366, 0.9419, 0.1079],\n",
       "        [0.2346, 0.2542, 0.2841, 0.1010],\n",
       "        [0.9251, 0.9364, 0.9127, 0.1279]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_test[:,10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f4975c-e7a6-4eb1-becc-068aaddbc0f6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}