{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1079aba8-2e21-41d4-85c6-aaf7fd030cc1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Conformal Experiment: Increase Confidence Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "87f62873-3ac6-4961-934b-3ac2722fc73d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8b798ec-6d65-4770-945a-e930c29d1d41",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9216, 14])\n",
      "torch.Size([9216, 14])\n",
      "torch.Size([9216, 14])\n",
      "torch.Size([9216, 14])\n",
      "torch.Size([9216, 14])\n"
     ]
    }
   ],
   "source": [
    "# === Softmax ===\n",
    "n_classes = 10\n",
    "random_expert_idx = 0\n",
    "probs_softmax = []\n",
    "confs = []\n",
    "exps = []\n",
    "true = []\n",
    "path = \"softmax_increase_confidence/\"\n",
    "n_experts = 4\n",
    "p_experts = [0.2, 0.4, 0.6, 0.8, 0.95]\n",
    "for p in p_experts:\n",
    "    model_name = '_' + str(p) + '_confidence'\n",
    "    with open(path + 'confidence_multiple_experts' + model_name + '.txt', 'r') as f:\n",
    "        conf = json.loads(json.load(f))\n",
    "    with open(path + 'expert_predictions_multiple_experts' + model_name + '.txt', 'r') as f:\n",
    "        exp_pred = json.loads(json.load(f))\n",
    "    with open(path + 'true_label_multiple_experts' + model_name + '.txt', 'r') as f:\n",
    "        true_label = json.loads(json.load(f))\n",
    "    true.append(true_label['test'])\n",
    "    exps.append(exp_pred['test'])\n",
    "    c = torch.tensor(conf['test'])\n",
    "    print(c.shape)\n",
    "    # DANI Correction ===\n",
    "    c = c.softmax(dim=1)\n",
    "    probs_softmax.append(c)\n",
    "    # DANI Correction ===\n",
    "\n",
    "    temp = 0\n",
    "    for i in range(n_experts):\n",
    "        temp += c[:, (n_classes + n_experts) - (i + 1)]\n",
    "    prob = c / (1.0 - temp).unsqueeze(-1)\n",
    "    confs.append(prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e2067f-b673-4bde-834d-4ba7f33b4add",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Use c, not conf, because we do not apply temperature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81174996-8914-402a-9cfc-e96ab19fcb88",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 1 expert rando, 3 with prob 0.8 correct\n",
    "probs = probs_softmax[-1]\n",
    "experts = exps[-1]\n",
    "# experts = experts[::-1]  # reverse order!\n",
    "y_true = true[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "373afd37",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0229, 0.2398, 0.2286, 0.2388],\n",
       "        [0.0531, 0.1710, 0.1525, 0.1687],\n",
       "        [0.0401, 0.1389, 0.1312, 0.1402],\n",
       "        [0.0262, 0.2352, 0.2380, 0.2364],\n",
       "        [0.0520, 0.1344, 0.1481, 0.1544]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[:5,10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fc16b42",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 6, 0, ..., 7, 5, 3],\n",
       "       [3, 5, 3, ..., 4, 9, 5],\n",
       "       [3, 8, 2, ..., 5, 0, 5],\n",
       "       [3, 2, 8, ..., 2, 5, 5]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(experts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92def1d7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 8, 8, 0, 6]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1ab0b64",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N val:7372\n",
      "N test:1844\n"
     ]
    }
   ],
   "source": [
    "n_val = int(0.8 * len(y_true))\n",
    "n_test = len(y_true) - n_val\n",
    "print(\"N val:{}\".format(n_val))\n",
    "print(\"N test:{}\".format(n_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e658f5b6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1831e-04, 2.8523e-04, 7.9228e-04,  ..., 2.3978e-01, 2.2855e-01,\n",
       "         2.3876e-01],\n",
       "        [2.9309e-04, 5.0115e-04, 3.2451e-05,  ..., 1.7100e-01, 1.5253e-01,\n",
       "         1.6869e-01],\n",
       "        [2.1325e-03, 6.9851e-03, 2.8766e-04,  ..., 1.3888e-01, 1.3124e-01,\n",
       "         1.4023e-01],\n",
       "        ...,\n",
       "        [1.0121e-03, 7.4800e-05, 3.5026e-01,  ..., 2.0158e-01, 2.0653e-01,\n",
       "         2.0776e-01],\n",
       "        [7.1184e-03, 3.3438e-03, 4.9556e-03,  ..., 2.0613e-01, 2.0641e-01,\n",
       "         2.1030e-01],\n",
       "        [2.6729e-07, 1.6294e-07, 4.7181e-06,  ..., 2.4467e-01, 2.3259e-01,\n",
       "         2.3115e-01]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f67c3f5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6043072",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7653)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 2. get Q_hat\n",
    "\n",
    "n_classes_exp = n_classes + n_experts\n",
    "probs_val = probs[:n_val, 10:]\n",
    "\n",
    "# experts_val = experts[::-1]  # IMPORTANT! swap to match prob ordering\n",
    "experts_val = experts\n",
    "experts_val = [exp[:n_val] for exp in experts_val]\n",
    "\n",
    "y_true_val = y_true[:n_val]\n",
    "\n",
    "# === Only on deferred samples\n",
    "_, predicted = torch.max(probs[:n_val].data, 1)\n",
    "r = (predicted >= n_classes_exp - n_experts)\n",
    "\n",
    "# Filter \n",
    "probs_val = probs_val[r]\n",
    "experts_val = [np.array(exp)[r] for exp in experts_val]\n",
    "y_true_val = np.array(y_true_val)[r]\n",
    "\n",
    "# Model expert probs ===\n",
    "# Sort J model outputs for experts\n",
    "probs_experts = probs[:n_val, 10:]\n",
    "probs_experts = probs_experts[r]\n",
    "sort, pi = probs_experts.sort(dim=1, descending=True)\n",
    "\n",
    "# Correctness experts ===\n",
    "# Check if experts are correct \n",
    "correct_exp = (np.array(experts_val) == np.array(y_true_val)).T\n",
    "# idx for correct experts: [[0,1,2], [1,2], [], ...]\n",
    "correct_exp_idx = [np.where(correct_exp_i)[0] for correct_exp_i in correct_exp]\n",
    "\n",
    "# obtain the last expert to be retrieved. If empty, then add all values.\n",
    "# indexes are not the real expert index, but the sorted indexes, e.g. [[1, 0 ,2],  [1,0], [], ...]\n",
    "pi_corr_exp = [probs_experts[i, corr_exp].sort(descending=True)[1] for i, corr_exp in enumerate(correct_exp)]\n",
    "pi_corr_exp_stop = [pi_corr_exp_i[-1] if len(pi_corr_exp_i)!=0 else -1 for pi_corr_exp_i in pi_corr_exp]  # last expert\n",
    "\n",
    "# obtain real expert index back, e.g. [2,1,-1,...]\n",
    "pi_stop = [correct_exp_idx[i][pi_corr_exp_stop_i] if len(correct_exp_idx[i])!=0 else -1 for i, pi_corr_exp_stop_i in enumerate(pi_corr_exp_stop)]\n",
    "\n",
    "\n",
    "# =========\n",
    "n_val = n_val\n",
    "alpha = 0.1\n",
    "scores = sort.cumsum(dim=1).gather(1, pi.argsort(1))[range(len(torch.tensor(pi_stop))), torch.tensor(pi_stop)]\n",
    "qhat = torch.quantile(scores, np.ceil((r.sum() + 1) * (1 - alpha)) / r.sum(), interpolation=\"higher\")\n",
    "\n",
    "qhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73574526",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0229, 0.2398, 0.2286, 0.2388],\n",
       "        [0.0338, 0.2394, 0.2383, 0.2411],\n",
       "        [0.0278, 0.2239, 0.2299, 0.2323],\n",
       "        ...,\n",
       "        [0.0278, 0.2555, 0.2535, 0.2674],\n",
       "        [0.0292, 0.2298, 0.2358, 0.2510],\n",
       "        [0.0301, 0.2586, 0.2611, 0.2581]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07fd06df",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0229, 0.2398, 0.2286, 0.2388],\n",
       "        [0.0531, 0.1710, 0.1525, 0.1687],\n",
       "        [0.0401, 0.1389, 0.1312, 0.1402],\n",
       "        ...,\n",
       "        [0.0255, 0.2016, 0.2065, 0.2078],\n",
       "        [0.0438, 0.2061, 0.2064, 0.2103],\n",
       "        [0.0207, 0.2447, 0.2326, 0.2311]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[:,10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9df13888",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7300, 0.2398, 0.7071, 0.4785],\n",
       "        [0.7527, 0.4806, 0.7188, 0.2411],\n",
       "        [0.7139, 0.6861, 0.4622, 0.2323],\n",
       "        ...,\n",
       "        [0.8041, 0.5229, 0.7763, 0.2674],\n",
       "        [0.7458, 0.7166, 0.4868, 0.2510],\n",
       "        [0.8079, 0.5197, 0.2611, 0.7778]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort.cumsum(dim=1).gather(1, pi.argsort(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a12fa0a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 6, ..., 0, 2, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7486e015",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 6, 4, ..., 0, 9, 8],\n",
       "       [3, 1, 6, ..., 0, 2, 3],\n",
       "       [3, 1, 9, ..., 0, 2, 3],\n",
       "       [3, 1, 8, ..., 0, 2, 3]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(experts_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67213e1b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "904c34c2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "n_experts = 4\n",
    "n_classes_exp = n_classes + n_experts\n",
    "\n",
    "probs_test = probs[n_val:, n_classes:]\n",
    "experts_test = [exp[n_val:] for exp in experts]\n",
    "y_true_test = y_true[n_val:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8fed5ce",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6833, 0.7459, 0.7966,  ..., 0.6414, 0.6666, 0.7291])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_test.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11d6f57f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([3, 2, 1, 0]),\n",
       " array([1, 3]),\n",
       " array([2, 3, 1, 0]),\n",
       " array([2, 1, 3, 0]),\n",
       " array([3, 1, 2, 0])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Only on deferred samples\n",
    "_, predicted = torch.max(probs[n_val:].data, 1)\n",
    "r_test = (predicted >= n_classes_exp - n_experts)\n",
    "\n",
    "# Filter \n",
    "probs_test = probs_test[r_test]\n",
    "experts_test = [np.array(exp)[r_test] for exp in experts_test]\n",
    "y_true_test = np.array(y_true_test)[r_test]\n",
    "\n",
    "# Sort J model outputs for experts. sorted probs and sorted indexes\n",
    "sort_test, pi_test = probs_test.sort(dim=1, descending=True)\n",
    "# Get last sorted index to be below Q_hat\n",
    "pi_stop = (sort_test.cumsum(dim=1) <= qhat).sum(axis=1)\n",
    "\n",
    "# Prediction sets\n",
    "prediction_sets = [(pi_test[i][:(pi_stop[i])]).numpy() for i in range(pi_stop.shape[0])]  # not allow empty sets\n",
    "prediction_sets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b71af58d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2632)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b1dfcc6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.array([len(prediction_sets_i) for prediction_sets_i in prediction_sets])\n",
    "import seaborn as sns\n",
    "\n",
    "sns.histplot(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7bfb7020",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 8, 1, 0, 0],\n",
       "       [0, 3, 2, 3, 4],\n",
       "       [0, 3, 2, 3, 4],\n",
       "       [0, 3, 2, 2, 4]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(experts_test)[:,:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acff0dc1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54291de",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Accuracy w/o Conformal on deferred samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b39b1316",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "correct_sys = 0\n",
    "exp = 0\n",
    "exp_total = 0\n",
    "total = 0\n",
    "real_total = 0\n",
    "alone_correct = 0\n",
    "#  === Individual Expert Accuracies === #\n",
    "expert_correct_dic = {k: 0 for k in range(len(experts_test))}\n",
    "expert_total_dic = {k: 0 for k in range(len(experts_test))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76c987b1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 1 expert rando, 3 with prob 0.9 correct\n",
    "probs = probs_softmax[-1]\n",
    "experts = exps[-1]\n",
    "# experts = experts[::-1] \n",
    "y_true = true[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6016944a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "n_experts = 4\n",
    "n_classes_exp = n_classes + n_experts\n",
    "\n",
    "probs_test = probs[n_val:]\n",
    "experts_test = [exp[n_val:] for exp in experts]\n",
    "y_true_test = y_true[n_val:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0610f1e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9216, 14])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc890fd7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Predicted value \n",
    "_, predicted = torch.max(probs_test.data, 1)\n",
    "# Classifier alone prediction\n",
    "_, prediction = torch.max(probs_test.data[:, :(n_classes_exp - n_experts)],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d55035",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### w Conformal Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91dd4a3c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77cdcb61",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels = y_true_test\n",
    "\n",
    "# Predicted value \n",
    "_, predicted = torch.max(probs_test.data, 1)\n",
    "# Classifier alone prediction\n",
    "_, prediction = torch.max(probs_test.data[:, :(n_classes_exp - n_experts)],1)\n",
    "for i in range(0, n_test):\n",
    "    r = (predicted[i].item() >= n_classes_exp - len(experts_test))\n",
    "    alone_correct += (prediction[i] == labels[i]).item()\n",
    "    if r == 0:\n",
    "        total += 1\n",
    "        correct += (predicted[i] == labels[i]).item()\n",
    "        correct_sys += (predicted[i] == labels[i]).item()\n",
    "        \n",
    "    if r == 1:\n",
    "        # Conformal prediction ===        \n",
    "        # Sort J model outputs for experts. sorted probs and sorted indexes\n",
    "        sort_i, pi_i = probs_test[i,n_classes:].sort(descending=True)\n",
    "        # Get last sorted index to be below Q_hat\n",
    "        pi_stop_i = (sort_i.cumsum(dim=0) <= qhat).sum()\n",
    "\n",
    "        # Prediction sets\n",
    "        prediction_set_i = (pi_i[:(pi_stop_i)]).numpy()  # not allow empty sets        \n",
    "#         print(len(prediction_set_i))\n",
    "        ensemble_expert_pred_i = np.array(experts_test)[prediction_set_i][:, i]\n",
    "        exp_prediction = stats.mode(ensemble_expert_pred_i).mode\n",
    "        # Conformal prediction ===\n",
    "        \n",
    "        # Deferral accuracy: No matter expert ===\n",
    "        exp += (exp_prediction == labels[i])\n",
    "        exp_total += 1\n",
    "        # Individual Expert Accuracy ===\n",
    "        # expert_correct_dic[deferred_exp] += (exp_prediction == labels[i].item())\n",
    "        # expert_total_dic[deferred_exp] += 1\n",
    "        #\n",
    "        correct_sys += (exp_prediction == labels[i])\n",
    "    real_total += 1\n",
    "    \n",
    "#  ===  Coverage  === #    \n",
    "cov = str(total) + str(\" out of\") + str(real_total)\n",
    "\n",
    "#  === Individual Expert Accuracies === #\n",
    "expert_accuracies = {\"expert_{}\".format(str(k)): 100 * expert_correct_dic[k] / (expert_total_dic[k] + 0.0002) for k\n",
    "             in range(len(experts_test))}\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2df3fab0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86a30d3e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2103, 0.2064, 0.2061, 0.0438])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c6ead75",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cov: 63.82863340563991\n"
     ]
    }
   ],
   "source": [
    "print(\"Cov: {}\".format(100 * (total/real_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c06a2101",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'expert_0': 0.0, 'expert_1': 0.0, 'expert_2': 0.0, 'expert_3': 0.0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "21379c55",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([86.2068707]),)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * exp / (exp_total + 0.0002),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b4b15bc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "667"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "83a0a247",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([89.37093275])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * correct_sys / real_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfa4ecc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### w/o Conformal Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9730e3f5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "correct_sys = 0\n",
    "exp = 0\n",
    "exp_total = 0\n",
    "total = 0\n",
    "real_total = 0\n",
    "alone_correct = 0\n",
    "#  === Individual Expert Accuracies === #\n",
    "expert_correct_dic = {k: 0 for k in range(len(experts_test))}\n",
    "expert_total_dic = {k: 0 for k in range(len(experts_test))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b956c882",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 1 expert rando, 3 with prob 0.9 correct\n",
    "probs = probs_softmax[-1]\n",
    "experts = exps[-1]\n",
    "# experts = experts[::-1] \n",
    "y_true = true[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "606fef61",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "n_experts = 4\n",
    "n_classes_exp = n_classes + n_experts\n",
    "\n",
    "probs_test = probs[n_val:]\n",
    "experts_test = [exp[n_val:] for exp in experts]\n",
    "y_true_test = y_true[n_val:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "082165d0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Predicted value \n",
    "_, predicted = torch.max(probs_test.data, 1)\n",
    "# Classifier alone prediction\n",
    "_, prediction = torch.max(probs_test.data[:, :(n_classes_exp - n_experts)],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0fc3fa22",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels = y_true_test\n",
    "\n",
    "# Predicted value \n",
    "_, predicted = torch.max(probs_test.data, 1)\n",
    "# Classifier alone prediction\n",
    "_, prediction = torch.max(probs_test.data[:, :(n_classes_exp - n_experts)],1)\n",
    "for i in range(0, n_test):\n",
    "    r = (predicted[i].item() >= n_classes_exp - len(experts_test))\n",
    "    alone_correct += (prediction[i] == labels[i]).item()\n",
    "    if r == 0:\n",
    "        total += 1\n",
    "        correct += (predicted[i] == labels[i]).item()\n",
    "        correct_sys += (predicted[i] == labels[i]).item()\n",
    "        \n",
    "    if r == 1:\n",
    "        deferred_exp = (predicted[i] - n_classes).item()  # reverse order, as in loss function\n",
    "        # print(\"def exp: {}\".format(deferred_exp))\n",
    "        # deferred_exp = ((n_classes - 1) - predicted[i]).item()  # reverse order, as in loss function\n",
    "        exp_prediction = experts_test[deferred_exp][i]\n",
    "        # print(\"exp pred: {}\".format(exp_prediction))\n",
    "        #\n",
    "        # Deferral accuracy: No matter expert ===\n",
    "        exp += (exp_prediction == labels[i])\n",
    "        # print(\"label: {}\".format(labels[i]))\n",
    "\n",
    "        exp_total += 1\n",
    "        # Individual Expert Accuracy ===\n",
    "        expert_correct_dic[deferred_exp] += (exp_prediction == labels[i])\n",
    "        expert_total_dic[deferred_exp] += 1\n",
    "        #\n",
    "        correct_sys += (exp_prediction == labels[i])\n",
    "    real_total += 1\n",
    "    \n",
    "#  ===  Coverage  === #    \n",
    "cov = str(total) + str(\" out of\") + str(real_total)\n",
    "\n",
    "#  === Individual Expert Accuracies === #\n",
    "expert_accuracies = {\"expert_{}\".format(str(k)): 100 * expert_correct_dic[k] / (expert_total_dic[k] + 0.0002) for k\n",
    "             in range(len(experts_test))}\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "de5f7ba6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-5)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predicted[i] - n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c7d36257-d3b4-43b0-9d88-3fd57ec81388",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "n_experts = 4\n",
    "n_classes_exp = n_classes + n_experts\n",
    "\n",
    "probs_test = probs[n_val:]\n",
    "experts_test = [exp[n_val:] for exp in experts]\n",
    "y_true_test = y_true[n_val:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8e98b807-81a5-4770-8082-04e7425c0d35",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Predicted value \n",
    "_, predicted = torch.max(probs_test.data, 1)\n",
    "# Classifier alone prediction\n",
    "_, prediction = torch.max(probs_test.data[:, :(n_classes_exp - n_experts)],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ed437339-9d40-4840-b215-07ea9d22d527",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels = y_true_test\n",
    "\n",
    "# Predicted value \n",
    "_, predicted = torch.max(probs_test.data, 1)\n",
    "# Classifier alone prediction\n",
    "_, prediction = torch.max(probs_test.data[:, :(n_classes_exp - n_experts)],1)\n",
    "for i in range(0, n_test):\n",
    "    r = (predicted[i].item() >= n_classes_exp - len(experts_test))\n",
    "    alone_correct += (prediction[i] == labels[i]).item()\n",
    "    if r == 0:\n",
    "        total += 1\n",
    "        correct += (predicted[i] == labels[i]).item()\n",
    "        correct_sys += (predicted[i] == labels[i]).item()\n",
    "        \n",
    "    if r == 1:\n",
    "        deferred_exp = (predicted[i] - n_classes).item()  # reverse order, as in loss function\n",
    "        # print(\"def exp: {}\".format(deferred_exp))\n",
    "        # deferred_exp = ((n_classes - 1) - predicted[i]).item()  # reverse order, as in loss function\n",
    "        exp_prediction = experts_test[deferred_exp][i]\n",
    "        # print(\"exp pred: {}\".format(exp_prediction))\n",
    "        #\n",
    "        # Deferral accuracy: No matter expert ===\n",
    "        exp += (exp_prediction == labels[i])\n",
    "        # print(\"label: {}\".format(labels[i]))\n",
    "\n",
    "        exp_total += 1\n",
    "        # Individual Expert Accuracy ===\n",
    "        expert_correct_dic[deferred_exp] += (exp_prediction == labels[i])\n",
    "        expert_total_dic[deferred_exp] += 1\n",
    "        #\n",
    "        correct_sys += (exp_prediction == labels[i])\n",
    "    real_total += 1\n",
    "    \n",
    "#  ===  Coverage  === #    \n",
    "cov = str(total) + str(\" out of\") + str(real_total)\n",
    "\n",
    "#  === Individual Expert Accuracies === #\n",
    "expert_accuracies = {\"expert_{}\".format(str(k)): 100 * expert_correct_dic[k] / (expert_total_dic[k] + 0.0002) for k\n",
    "             in range(len(experts_test))}\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ab7f3c98-c8da-4e97-81a2-c05104bdbd62",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-5)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predicted[i] - n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6f4fedcd-7758-4e86-863d-df79aa30c040",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'expert_0': 0.0,\n",
       " 'expert_1': 85.07456337719151,\n",
       " 'expert_2': 82.432321037404,\n",
       " 'expert_3': 81.69932860581076}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8c2fc7b5-6ca1-4216-aa80-c7f0fd70b9b3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82.45875825206024,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * exp / (exp_total + 0.0002),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "80f9bea7-2375-49b8-8cf0-366717be2f15",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1100"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73f51115-8afc-4372-ab5b-762b1fba5567",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.01518438177874"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * correct_sys / real_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8feaffe6-83ac-4604-9fa2-e701438e6e01",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Accuracy w Conformal on deferred samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6fb66168-32e0-4b89-9e5f-fec062ffac9e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7653)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2d14b356-8707-4439-8365-364a4f751212",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0179, 0.2281, 0.2137, 0.2235],\n",
       "        [0.0303, 0.2314, 0.2400, 0.2442],\n",
       "        [0.0207, 0.2643, 0.2536, 0.2581],\n",
       "        ...,\n",
       "        [0.0255, 0.2016, 0.2065, 0.2078],\n",
       "        [0.0438, 0.2061, 0.2064, 0.2103],\n",
       "        [0.0207, 0.2447, 0.2326, 0.2311]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_test[:,10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f4975c-e7a6-4eb1-becc-068aaddbc0f6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be5da882-a40e-41ae-9944-c74e2ae69b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1443)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "34f1505b-4b97-4321-809d-d444c55a1c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_expert_prediction(experts, prediction_set_i, method=\"voting\"):\n",
    "    ensemble_expert_pred_i = np.array(experts_test)[prediction_set_i][:, i]\n",
    "    if method == \"voting\":\n",
    "        exp_prediction = stats.mode(ensemble_expert_pred_i).mode\n",
    "        \n",
    "    if method == \"last\": \n",
    "        exp_prediction = ensemble_expert_pred_i[-1] if len(ensemble_expert_pred_i)!=0 else []\n",
    "        \n",
    "    if method == \"random\":\n",
    "        idx = np.random.randint(len(ensemble_expert_pred_i)) if len(ensemble_expert_pred_i)!=0 else []\n",
    "        exp_prediction = ensemble_expert_pred_i[idx] \n",
    "        \n",
    "    return exp_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3b0bbc8d-7afa-4b63-a8cc-b8def24bd7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: last\n",
      "\n",
      "Q_hat 0.2: 2.470168352127075\n",
      "{'coverage': 97.66811279826464, 'system_accuracy': 85.19522776572668, 'expert_accuracy': 25.581276366156438, 'classifier_accuracy': 86.61854044316821, 'alone_classifier': 85.84598698481562}\n",
      "Q_hat 0.4: 2.5496397018432617\n",
      "{'coverage': 95.33622559652929, 'system_accuracy': 86.00867678958785, 'expert_accuracy': 37.20921579252141, 'classifier_accuracy': 88.39589940865191, 'alone_classifier': 86.60520607375271}\n",
      "Q_hat 0.6: 3.337196111679077\n",
      "{'coverage': 86.60520607375271, 'system_accuracy': 86.44251626898048, 'expert_accuracy': 56.680116048489026, 'classifier_accuracy': 91.04570500653068, 'alone_classifier': 85.79175704989154}\n",
      "Q_hat 0.8: 3.5689847469329834\n",
      "{'coverage': 79.60954446854664, 'system_accuracy': 88.39479392624729, 'expert_accuracy': 70.74464322093445, 'classifier_accuracy': 92.91552500575443, 'alone_classifier': 85.73752711496746}\n",
      "Q_hat 0.95: 3.7372031211853027\n",
      "{'coverage': 63.82863340563991, 'system_accuracy': 87.14750542299349, 'expert_accuracy': 80.0599460090117, 'classifier_accuracy': 91.16396846525332, 'alone_classifier': 79.55531453362256}\n",
      "Method: random\n",
      "\n",
      "Q_hat 0.2: 2.470168352127075\n",
      "{'coverage': 97.66811279826464, 'system_accuracy': 85.24945770065077, 'expert_accuracy': 27.906846944897932, 'classifier_accuracy': 86.61854044316821, 'alone_classifier': 85.84598698481562}\n",
      "Q_hat 0.4: 2.5496397018432617\n",
      "{'coverage': 95.33622559652929, 'system_accuracy': array([], dtype=float64), 'expert_accuracy': array([], dtype=float64), 'classifier_accuracy': 88.39589940865191, 'alone_classifier': 86.60520607375271}\n",
      "Q_hat 0.6: 3.337196111679077\n",
      "{'coverage': 86.60520607375271, 'system_accuracy': 85.30368763557483, 'expert_accuracy': 48.178098641215676, 'classifier_accuracy': 91.04570500653068, 'alone_classifier': 85.79175704989154}\n",
      "Q_hat 0.8: 3.5689847469329834\n",
      "{'coverage': 79.60954446854664, 'system_accuracy': array([], dtype=float64), 'expert_accuracy': array([], dtype=float64), 'classifier_accuracy': 92.91552500575443, 'alone_classifier': 85.73752711496746}\n",
      "Q_hat 0.95: 3.7372031211853027\n",
      "{'coverage': 63.82863340563991, 'system_accuracy': 80.91106290672451, 'expert_accuracy': 62.818571868494196, 'classifier_accuracy': 91.16396846525332, 'alone_classifier': 79.55531453362256}\n",
      "Method: voting\n",
      "\n",
      "Q_hat 0.2: 2.470168352127075\n",
      "{'coverage': 97.66811279826464, 'system_accuracy': array([85.46637744]), 'expert_accuracy': array([37.20912926]), 'classifier_accuracy': 86.61854044316821, 'alone_classifier': 85.84598698481562}\n",
      "Q_hat 0.4: 2.5496397018432617\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (1,) doesn't match the broadcast shape (0,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sp/q319m69j3vq35gn_yjsn7snh0002nk/T/ipykernel_12523/1335353030.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;31m# Deferral accuracy: No matter expert ===\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                 \u001b[0mexp\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_prediction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m                 \u001b[0mexp_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;31m# Individual Expert Accuracy ===\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: non-broadcastable output operand with shape (1,) doesn't match the broadcast shape (0,)"
     ]
    }
   ],
   "source": [
    "# Method dict ===\n",
    "method_list = [\"last\", \"random\", \"voting\"]\n",
    "method_dict = {\"last\": [],\n",
    "               \"random\": [],\n",
    "               \"voting\": []}\n",
    "\n",
    "\n",
    "p_experts = [0.2, 0.4, 0.6, 0.8, 0.95]\n",
    "alpha = 0.1\n",
    "n_classes = 10\n",
    "n_experts = 4\n",
    "n_classes_exp = n_classes + n_experts\n",
    "\n",
    "for method in method_list:\n",
    "    \n",
    "    print(\"Method: {}\\n\".format(method))\n",
    "    for i, p_exp in enumerate(p_experts):\n",
    "        # =============\n",
    "        # = Get Probs =\n",
    "        # =============\n",
    "\n",
    "        probs = confs[i]\n",
    "        experts = exps[i]\n",
    "        experts = experts[::-1]  # reverse order!\n",
    "        y_true = true[-i]\n",
    "\n",
    "        # Val/Calibration ===\n",
    "        probs_val = probs[:n_val, n_classes:]\n",
    "        experts_val = [exp[:n_val] for exp in experts]\n",
    "        y_true_val = y_true[:n_val]\n",
    "\n",
    "        # Test ===\n",
    "        probs_test = probs[n_val:, n_classes:]\n",
    "        experts_test = [exp[n_val:] for exp in experts]\n",
    "        y_true_test = y_true[n_val:]\n",
    "\n",
    "\n",
    "        # =============\n",
    "        # = Conformal =\n",
    "        # =============\n",
    "\n",
    "        # Calculate Q_hat ===\n",
    "\n",
    "        # === Only on deferred samples\n",
    "        _, predicted = torch.max(probs[:n_val].data, 1)\n",
    "        r = (predicted >= n_classes_exp - n_experts)\n",
    "\n",
    "        # Filter \n",
    "        probs_experts = probs_val[r]\n",
    "        experts_val = [np.array(exp)[r] for exp in experts_val]\n",
    "        y_true_val = np.array(y_true_val)[r]\n",
    "\n",
    "        # Model expert probs ===\n",
    "        # Sort J model outputs for experts\n",
    "        sort, pi = probs_experts.sort(dim=1, descending=True)\n",
    "\n",
    "        # Correctness experts ===\n",
    "        # Check if experts are correct \n",
    "        correct_exp = (np.array(experts_val) == np.array(y_true_val)).T\n",
    "        # idx for correct experts: [[0,1,2], [1,2], [], ...]\n",
    "        correct_exp_idx = [np.where(correct_exp_i)[0] for correct_exp_i in correct_exp]\n",
    "\n",
    "        # obtain the last expert to be retrieved. If empty, then add all values.\n",
    "        # indexes are not the real expert index, but the sorted indexes, e.g. [[1, 0 ,2],  [1,0], [], ...]\n",
    "        pi_corr_exp = [probs_experts[i, corr_exp].sort(descending=True)[1] for i, corr_exp in enumerate(correct_exp)]\n",
    "        pi_corr_exp_stop = [pi_corr_exp_i[-1] if len(pi_corr_exp_i)!=0 else -1 for pi_corr_exp_i in pi_corr_exp]  # last expert\n",
    "\n",
    "        # obtain real expert index back, e.g. [2,1,-1,...]\n",
    "        pi_stop = [correct_exp_idx[i][pi_corr_exp_stop_i] if len(correct_exp_idx[i])!=0 else -1 for i, pi_corr_exp_stop_i in enumerate(pi_corr_exp_stop)]\n",
    "\n",
    "        scores = sort.cumsum(dim=1).gather(1, pi.argsort(1))[range(len(torch.tensor(pi_stop))), torch.tensor(pi_stop)]\n",
    "        n_quantile = r.sum()\n",
    "        qhat = torch.quantile(scores, np.ceil((n_quantile + 1) * (1 - alpha)) / n_quantile, interpolation=\"higher\")\n",
    "\n",
    "        print(\"Q_hat {}: {}\".format(p_exp, qhat))\n",
    "\n",
    "\n",
    "        # =============\n",
    "        # = Metrics =\n",
    "        # =============\n",
    "\n",
    "        # === Initalize ====\n",
    "\n",
    "        correct = 0\n",
    "        correct_sys = 0\n",
    "        exp = 0\n",
    "        exp_total = 0\n",
    "        total = 0\n",
    "        real_total = 0\n",
    "        alone_correct = 0\n",
    "\n",
    "        # Individual Expert Accuracies === #\n",
    "        expert_correct_dic = {k: 0 for k in range(len(experts_test))}\n",
    "        expert_total_dic = {k: 0 for k in range(len(experts_test))}\n",
    "\n",
    "        probs_test_exp = probs_test\n",
    "        probs_test_model = probs[n_val:]\n",
    "\n",
    "        # Predicted value \n",
    "        _, predicted = torch.max(probs_test_model.data, 1)\n",
    "\n",
    "        # Classifier alone prediction\n",
    "        _, prediction = torch.max(probs_test_model.data[:, :(n_classes_exp - n_experts)],1)\n",
    "\n",
    "        labels = y_true_test\n",
    "        for i in range(0, n_test):\n",
    "            r = (predicted[i].item() >= n_classes_exp - n_experts)\n",
    "            alone_correct += (prediction[i] == labels[i]).item()\n",
    "\n",
    "            # Non-deferred \n",
    "            if r == 0:\n",
    "                total += 1\n",
    "                correct += (predicted[i] == labels[i]).item()\n",
    "                correct_sys += (predicted[i] == labels[i]).item()\n",
    "\n",
    "            # Deferred \n",
    "            if r == 1:\n",
    "                # Conformal prediction ===        \n",
    "                # Sort J model outputs for experts. sorted probs and sorted indexes\n",
    "                sort_i, pi_i = probs_test_exp[i].sort(descending=True)\n",
    "                # Get last sorted index to be below Q_hat\n",
    "                pi_stop_i = (sort_i.cumsum(dim=0) <= qhat).sum()\n",
    "\n",
    "                # Prediction sets\n",
    "                prediction_set_i = (pi_i[:(pi_stop_i)]).numpy()  # not allow empty sets        \n",
    "\n",
    "\n",
    "\n",
    "                # - Get expert prediction depending on method\n",
    "                # ======\n",
    "                exp_prediction = get_expert_prediction(experts_test, prediction_set_i, method=method)\n",
    "                # ======\n",
    "\n",
    "\n",
    "\n",
    "                # Deferral accuracy: No matter expert ===\n",
    "                exp += (exp_prediction == labels[i])\n",
    "                exp_total += 1\n",
    "                # Individual Expert Accuracy ===\n",
    "                # expert_correct_dic[deferred_exp] += (exp_prediction == labels[i].item())\n",
    "                # expert_total_dic[deferred_exp] += 1\n",
    "                #\n",
    "                correct_sys += (exp_prediction == labels[i])\n",
    "\n",
    "            real_total += 1\n",
    "\n",
    "        #  ===  Coverage  === #    \n",
    "        cov = 100 * total / real_total\n",
    "\n",
    "        #  === Individual Expert Accuracies === #\n",
    "        expert_accuracies = {\"expert_{}\".format(str(k)): 100 * expert_correct_dic[k] / (expert_total_dic[k] + 0.0002) for k\n",
    "                     in range(len(experts_test))}\n",
    "\n",
    "        # Add expert accuracies dict\n",
    "        to_print = {\"coverage\": cov,\n",
    "                    \"system_accuracy\": 100 * correct_sys / real_total,\n",
    "                    \"expert_accuracy\": 100 * exp / (exp_total + 0.0002),\n",
    "                    \"classifier_accuracy\": 100 * correct / (total + 0.0001),\n",
    "                    \"alone_classifier\": 100 * alone_correct / real_total}\n",
    "        print(to_print, flush=True)\n",
    "\n",
    "        # Save to method dict === \n",
    "        method_dict[method].append(to_print)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f176ad7d-6f14-4cc1-8132-b78289b3aff2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
